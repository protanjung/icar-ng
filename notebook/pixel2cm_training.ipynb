{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was run on 02/01/2024 at 10:43:51.\n"
     ]
    }
   ],
   "source": [
    "print('This notebook was run on ' + time.strftime(\"%d/%m/%Y\") + ' at ' + time.strftime(\"%H:%M:%S\") + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /home/icar/icar-ng-data/dataset\n",
      "Dataset file: dataset.csv\n",
      "Dataset path: /home/icar/icar-ng-data/dataset/dataset.csv\n",
      "Model directory: /home/icar/icar-ng-data/model\n",
      "Model file: pixel2cm_model.pt\n",
      "Model path: /home/icar/icar-ng-data/model/pixel2cm_model.pt\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = os.path.join(os.getenv('HOME'), 'icar-ng-data', 'dataset')\n",
    "print('Dataset directory: {}'.format(dataset_directory))\n",
    "\n",
    "dataset_file = 'dataset.csv'\n",
    "print('Dataset file: {}'.format(dataset_file))\n",
    "\n",
    "dataset_path = os.path.join(dataset_directory, dataset_file)\n",
    "print('Dataset path: {}'.format(dataset_path))\n",
    "\n",
    "# ======================================\n",
    "\n",
    "model_directory = os.path.join(os.getenv('HOME'), 'icar-ng-data', 'model')\n",
    "print('Model directory: {}'.format(model_directory))\n",
    "\n",
    "model_file = 'pixel2cm_model.pt'\n",
    "print('Model file: {}'.format(model_file))\n",
    "\n",
    "model_path = os.path.join(model_directory, model_file)\n",
    "print('Model path: {}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether dataset file exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    print('Dataset file does not exist: {}'.format(dataset_path))\n",
    "    exit()\n",
    "\n",
    "# Check whether model directory exists\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "    print('Created model directory: {}'.format(model_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_x: tensor([ 30., 204.]), max_x: tensor([1272.,  692.])\n",
      "min_y: tensor([   0.0000, -848.5281]), max_y: tensor([1200.0000,  848.5281])\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(dataset_path)\n",
    "df_train = df_raw.sample(frac=0.8)\n",
    "df_test = df_raw.drop(df_train.index)\n",
    "\n",
    "min_x = np.min(df_train.iloc[:, 0:2].values, axis=0)\n",
    "min_x = torch.tensor(min_x, dtype=torch.float32)\n",
    "max_x = np.max(df_train.iloc[:, 0:2].values, axis=0)\n",
    "max_x = torch.tensor(max_x, dtype=torch.float32)\n",
    "min_y = np.min(df_train.iloc[:, 2:4].values, axis=0)\n",
    "min_y = torch.tensor(min_y, dtype=torch.float32)\n",
    "max_y = np.max(df_train.iloc[:, 2:4].values, axis=0)\n",
    "max_y = torch.tensor(max_y, dtype=torch.float32)\n",
    "\n",
    "print('min_x: {}, max_x: {}'.format(min_x, max_x))\n",
    "print('min_y: {}, max_y: {}'.format(min_y, max_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        x = self.dataframe.iloc[:, 0:2].values\n",
    "        y = self.dataframe.iloc[:, 2:4].values\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_train: 118\n",
      "dataset_test: 29\n"
     ]
    }
   ],
   "source": [
    "dataset_train = ForwardDataset(df_train)\n",
    "dataset_test = ForwardDataset(df_test)\n",
    "print('dataset_train: {}'.format(len(dataset_train)))\n",
    "print('dataset_test: {}'.format(len(dataset_test)))\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=64, shuffle=True, pin_memory=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=64, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size, output_size, min_x, max_x, min_y, max_y):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        self.min_x = min_x\n",
    "        self.max_x = max_x\n",
    "        self.min_y = min_y\n",
    "        self.max_y = max_y\n",
    "        self.fc1 = nn.Linear(input_size, 4)\n",
    "        self.fc2 = nn.Linear(4, 20)\n",
    "        self.fc3 = nn.Linear(20, 80)\n",
    "        self.fc4 = nn.Linear(80, 20)\n",
    "        self.fc5 = nn.Linear(20, 4)\n",
    "        self.fc6 = nn.Linear(4, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x - self.min_x) / (self.max_x - self.min_x)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        x = self.fc6(x)\n",
    "        x = x * (self.max_y - self.min_y) + self.min_y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: /home/icar/icar-ng-data/model/pixel2cm_model.pt\n",
      "Loaded model: /home/icar/icar-ng-data/model/pixel2cm_model.pt\n"
     ]
    }
   ],
   "source": [
    "model = MultiLayerPerceptron(2, 2, min_x.to(device), max_x.to(device), min_y.to(device), max_y.to(device)).to(device)\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    try:\n",
    "        print('Loading model: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print('Loaded model: {}'.format(model_path))\n",
    "    except BaseException as e:\n",
    "        print('Failed to load model: {}'.format(model_path))\n",
    "        print(e)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 3945.816895, test_loss: 2314.987061 (Saved)\n",
      "epoch: 100, train_loss: 704.166107, test_loss: 329.267181 (Saved)\n",
      "epoch: 200, train_loss: 283.765175, test_loss: 85.755081 (Saved)\n",
      "epoch: 300, train_loss: 179.790176, test_loss: 48.738979 (Saved)\n",
      "epoch: 400, train_loss: 136.734291, test_loss: 40.157810 (Saved)\n",
      "epoch: 500, train_loss: 118.565392, test_loss: 38.741936 (Saved)\n",
      "epoch: 600, train_loss: 102.830154, test_loss: 40.419411\n",
      "epoch: 700, train_loss: 98.633795, test_loss: 42.643429\n",
      "epoch: 800, train_loss: 89.884342, test_loss: 46.130032\n",
      "epoch: 900, train_loss: 84.570602, test_loss: 50.053238\n",
      "epoch: 1000, train_loss: 81.784767, test_loss: 54.204632\n",
      "epoch: 1100, train_loss: 79.177095, test_loss: 58.921471\n",
      "epoch: 1200, train_loss: 75.200230, test_loss: 63.083488\n",
      "epoch: 1300, train_loss: 74.460728, test_loss: 66.602211\n",
      "epoch: 1400, train_loss: 71.010170, test_loss: 69.175339\n",
      "epoch: 1500, train_loss: 70.212679, test_loss: 70.862679\n",
      "epoch: 1600, train_loss: 69.551517, test_loss: 73.242088\n",
      "epoch: 1700, train_loss: 67.931440, test_loss: 74.917328\n",
      "epoch: 1800, train_loss: 68.570440, test_loss: 76.702164\n",
      "epoch: 1900, train_loss: 67.376930, test_loss: 77.872101\n",
      "epoch: 2000, train_loss: 68.585365, test_loss: 77.934807\n",
      "epoch: 2100, train_loss: 63.845257, test_loss: 79.193497\n",
      "epoch: 2200, train_loss: 65.867308, test_loss: 79.395477\n",
      "epoch: 2300, train_loss: 63.979256, test_loss: 79.971550\n",
      "epoch: 2400, train_loss: 64.023129, test_loss: 80.320892\n",
      "epoch: 2500, train_loss: 64.322674, test_loss: 81.303619\n",
      "epoch: 2600, train_loss: 63.241562, test_loss: 81.501167\n",
      "epoch: 2700, train_loss: 62.448353, test_loss: 82.044952\n",
      "epoch: 2800, train_loss: 62.984980, test_loss: 81.000839\n",
      "epoch: 2900, train_loss: 60.171576, test_loss: 82.119057\n",
      "epoch: 3000, train_loss: 61.521532, test_loss: 82.644966\n",
      "epoch: 3100, train_loss: 61.022533, test_loss: 82.413261\n",
      "epoch: 3200, train_loss: 61.496788, test_loss: 83.115891\n",
      "epoch: 3300, train_loss: 58.967052, test_loss: 83.674568\n",
      "epoch: 3400, train_loss: 60.055901, test_loss: 83.578468\n",
      "epoch: 3500, train_loss: 57.586319, test_loss: 84.472412\n",
      "epoch: 3600, train_loss: 58.889759, test_loss: 85.161301\n",
      "epoch: 3700, train_loss: 58.044977, test_loss: 84.936783\n",
      "epoch: 3800, train_loss: 58.182827, test_loss: 84.518631\n",
      "epoch: 3900, train_loss: 57.481024, test_loss: 86.410004\n",
      "epoch: 4000, train_loss: 57.979532, test_loss: 87.221771\n",
      "epoch: 4100, train_loss: 58.355951, test_loss: 87.551888\n",
      "epoch: 4200, train_loss: 56.422661, test_loss: 87.429466\n",
      "epoch: 4300, train_loss: 56.651445, test_loss: 87.693886\n",
      "epoch: 4400, train_loss: 56.982428, test_loss: 88.775894\n",
      "epoch: 4500, train_loss: 55.830099, test_loss: 90.514961\n",
      "epoch: 4600, train_loss: 56.771481, test_loss: 89.921654\n",
      "epoch: 4700, train_loss: 56.379787, test_loss: 89.375259\n",
      "epoch: 4800, train_loss: 56.593645, test_loss: 90.012451\n",
      "epoch: 4900, train_loss: 56.442883, test_loss: 90.258453\n",
      "epoch: 5000, train_loss: 56.672388, test_loss: 90.625862\n",
      "epoch: 5100, train_loss: 54.789511, test_loss: 92.004379\n",
      "epoch: 5200, train_loss: 54.457401, test_loss: 91.662834\n",
      "epoch: 5300, train_loss: 55.294762, test_loss: 91.329323\n",
      "epoch: 5400, train_loss: 54.587755, test_loss: 91.976158\n",
      "epoch: 5500, train_loss: 53.553934, test_loss: 93.572319\n",
      "epoch: 5600, train_loss: 54.748714, test_loss: 94.436409\n",
      "epoch: 5700, train_loss: 55.951181, test_loss: 94.797379\n",
      "epoch: 5800, train_loss: 55.052313, test_loss: 96.711983\n",
      "epoch: 5900, train_loss: 55.106964, test_loss: 96.738396\n",
      "epoch: 6000, train_loss: 55.956951, test_loss: 97.278954\n",
      "epoch: 6100, train_loss: 55.174107, test_loss: 97.515114\n",
      "epoch: 6200, train_loss: 54.199368, test_loss: 98.040375\n",
      "epoch: 6300, train_loss: 54.466963, test_loss: 98.116211\n",
      "epoch: 6400, train_loss: 54.314344, test_loss: 98.687332\n",
      "epoch: 6500, train_loss: 53.904932, test_loss: 97.943527\n",
      "epoch: 6600, train_loss: 54.200977, test_loss: 99.266685\n",
      "epoch: 6700, train_loss: 54.590574, test_loss: 99.546806\n",
      "epoch: 6800, train_loss: 54.538858, test_loss: 100.160645\n",
      "epoch: 6900, train_loss: 54.103519, test_loss: 100.708717\n",
      "epoch: 7000, train_loss: 53.206844, test_loss: 100.684052\n",
      "epoch: 7100, train_loss: 53.468935, test_loss: 101.498962\n",
      "epoch: 7200, train_loss: 51.567039, test_loss: 101.164314\n",
      "epoch: 7300, train_loss: 52.578577, test_loss: 101.323227\n",
      "epoch: 7400, train_loss: 53.317425, test_loss: 101.316536\n",
      "epoch: 7500, train_loss: 54.866131, test_loss: 101.828072\n",
      "epoch: 7600, train_loss: 53.437334, test_loss: 101.729492\n",
      "epoch: 7700, train_loss: 53.086386, test_loss: 102.973198\n",
      "epoch: 7800, train_loss: 54.497116, test_loss: 103.141937\n",
      "epoch: 7900, train_loss: 52.821949, test_loss: 102.535515\n",
      "epoch: 8000, train_loss: 53.666187, test_loss: 102.434349\n",
      "epoch: 8100, train_loss: 53.865808, test_loss: 102.070076\n",
      "epoch: 8200, train_loss: 55.384834, test_loss: 101.869514\n",
      "epoch: 8300, train_loss: 53.273621, test_loss: 102.918800\n",
      "epoch: 8400, train_loss: 52.597477, test_loss: 104.875992\n",
      "epoch: 8500, train_loss: 52.980799, test_loss: 103.575394\n",
      "epoch: 8600, train_loss: 52.290506, test_loss: 103.792580\n",
      "epoch: 8700, train_loss: 53.220276, test_loss: 104.756866\n",
      "epoch: 8800, train_loss: 52.842155, test_loss: 103.873077\n",
      "epoch: 8900, train_loss: 51.571733, test_loss: 104.346130\n",
      "epoch: 9000, train_loss: 52.469170, test_loss: 103.898857\n",
      "epoch: 9100, train_loss: 53.648895, test_loss: 104.209610\n",
      "epoch: 9200, train_loss: 53.343721, test_loss: 103.765320\n",
      "epoch: 9300, train_loss: 51.720547, test_loss: 104.246376\n",
      "epoch: 9400, train_loss: 51.230925, test_loss: 103.976868\n",
      "epoch: 9500, train_loss: 53.035690, test_loss: 105.581085\n",
      "epoch: 9600, train_loss: 52.205589, test_loss: 103.442368\n",
      "epoch: 9700, train_loss: 53.474354, test_loss: 104.673996\n",
      "epoch: 9800, train_loss: 53.524269, test_loss: 104.017479\n",
      "epoch: 9900, train_loss: 53.380146, test_loss: 102.094383\n",
      "epoch: 10000, train_loss: 52.162506, test_loss: 102.309883\n",
      "epoch: 10100, train_loss: 52.401999, test_loss: 102.000984\n",
      "epoch: 10200, train_loss: 51.789673, test_loss: 101.838326\n",
      "epoch: 10300, train_loss: 53.081059, test_loss: 101.620857\n",
      "epoch: 10400, train_loss: 52.205109, test_loss: 100.852715\n",
      "epoch: 10500, train_loss: 52.284056, test_loss: 100.941727\n",
      "epoch: 10600, train_loss: 51.978664, test_loss: 102.277573\n",
      "epoch: 10700, train_loss: 52.478624, test_loss: 101.321053\n",
      "epoch: 10800, train_loss: 52.074400, test_loss: 101.161285\n",
      "epoch: 10900, train_loss: 50.806532, test_loss: 101.808022\n",
      "epoch: 11000, train_loss: 52.526182, test_loss: 102.535995\n",
      "epoch: 11100, train_loss: 50.589071, test_loss: 100.463516\n",
      "epoch: 11200, train_loss: 50.421230, test_loss: 100.886345\n",
      "epoch: 11300, train_loss: 50.730890, test_loss: 101.257996\n",
      "epoch: 11400, train_loss: 51.558367, test_loss: 102.492111\n",
      "epoch: 11500, train_loss: 51.589842, test_loss: 102.338478\n",
      "epoch: 11600, train_loss: 50.583969, test_loss: 101.951347\n",
      "epoch: 11700, train_loss: 50.958727, test_loss: 102.016487\n",
      "epoch: 11800, train_loss: 51.414064, test_loss: 102.393501\n",
      "epoch: 11900, train_loss: 52.145294, test_loss: 102.540985\n",
      "epoch: 12000, train_loss: 51.095613, test_loss: 101.679062\n",
      "epoch: 12100, train_loss: 50.437666, test_loss: 103.289558\n",
      "epoch: 12200, train_loss: 50.469433, test_loss: 103.057152\n",
      "epoch: 12300, train_loss: 52.354351, test_loss: 102.669388\n",
      "epoch: 12400, train_loss: 50.707882, test_loss: 103.518379\n",
      "epoch: 12500, train_loss: 52.155365, test_loss: 102.279106\n",
      "epoch: 12600, train_loss: 51.649679, test_loss: 102.211578\n",
      "epoch: 12700, train_loss: 49.749046, test_loss: 102.676468\n",
      "epoch: 12800, train_loss: 50.258493, test_loss: 103.528984\n",
      "epoch: 12900, train_loss: 50.920864, test_loss: 103.331932\n",
      "epoch: 13000, train_loss: 52.034613, test_loss: 102.387062\n",
      "epoch: 13100, train_loss: 50.118849, test_loss: 102.686920\n",
      "epoch: 13200, train_loss: 49.998325, test_loss: 102.508820\n",
      "epoch: 13300, train_loss: 48.970515, test_loss: 103.447937\n",
      "epoch: 13400, train_loss: 49.821882, test_loss: 102.861137\n",
      "epoch: 13500, train_loss: 50.646648, test_loss: 102.255028\n",
      "epoch: 13600, train_loss: 50.062027, test_loss: 102.672089\n",
      "epoch: 13700, train_loss: 49.941677, test_loss: 103.247498\n",
      "epoch: 13800, train_loss: 50.457516, test_loss: 103.597008\n",
      "epoch: 13900, train_loss: 50.433270, test_loss: 102.733231\n",
      "epoch: 14000, train_loss: 49.983376, test_loss: 102.009926\n",
      "epoch: 14100, train_loss: 48.893333, test_loss: 102.336494\n",
      "epoch: 14200, train_loss: 51.219419, test_loss: 102.385765\n",
      "epoch: 14300, train_loss: 49.620176, test_loss: 102.178085\n",
      "epoch: 14400, train_loss: 51.720051, test_loss: 102.029282\n",
      "epoch: 14500, train_loss: 51.283087, test_loss: 102.390694\n",
      "epoch: 14600, train_loss: 50.688692, test_loss: 102.345657\n",
      "epoch: 14700, train_loss: 49.116966, test_loss: 102.476532\n",
      "epoch: 14800, train_loss: 50.269985, test_loss: 102.704811\n",
      "epoch: 14900, train_loss: 49.554466, test_loss: 103.175758\n",
      "epoch: 15000, train_loss: 50.490440, test_loss: 102.474091\n",
      "epoch: 15100, train_loss: 50.568432, test_loss: 102.474861\n",
      "epoch: 15200, train_loss: 50.355022, test_loss: 102.366562\n",
      "epoch: 15300, train_loss: 49.080975, test_loss: 103.195343\n",
      "epoch: 15400, train_loss: 50.703369, test_loss: 103.175873\n",
      "epoch: 15500, train_loss: 49.763756, test_loss: 102.339455\n",
      "epoch: 15600, train_loss: 48.342706, test_loss: 102.376923\n",
      "epoch: 15700, train_loss: 50.642925, test_loss: 102.738022\n",
      "epoch: 15800, train_loss: 48.033685, test_loss: 102.924103\n",
      "epoch: 15900, train_loss: 48.965549, test_loss: 103.488716\n",
      "epoch: 16000, train_loss: 51.159985, test_loss: 103.175362\n",
      "epoch: 16100, train_loss: 50.708813, test_loss: 103.182709\n",
      "epoch: 16200, train_loss: 49.593092, test_loss: 102.532669\n",
      "epoch: 16300, train_loss: 49.453196, test_loss: 103.180634\n",
      "epoch: 16400, train_loss: 49.072355, test_loss: 103.383095\n",
      "epoch: 16500, train_loss: 49.720058, test_loss: 102.249443\n",
      "epoch: 16600, train_loss: 49.901276, test_loss: 102.376938\n",
      "epoch: 16700, train_loss: 48.540771, test_loss: 102.976219\n",
      "epoch: 16800, train_loss: 49.203674, test_loss: 103.120026\n",
      "epoch: 16900, train_loss: 49.099131, test_loss: 102.432716\n",
      "epoch: 17000, train_loss: 50.717503, test_loss: 102.185616\n",
      "epoch: 17100, train_loss: 48.921679, test_loss: 102.413116\n",
      "epoch: 17200, train_loss: 49.390650, test_loss: 102.584656\n",
      "epoch: 17300, train_loss: 50.375599, test_loss: 101.961372\n",
      "epoch: 17400, train_loss: 50.905678, test_loss: 103.299072\n",
      "epoch: 17500, train_loss: 49.452374, test_loss: 102.887932\n",
      "epoch: 17600, train_loss: 48.398010, test_loss: 102.661301\n",
      "epoch: 17700, train_loss: 50.038712, test_loss: 104.430550\n",
      "epoch: 17800, train_loss: 50.321045, test_loss: 104.242691\n",
      "epoch: 17900, train_loss: 49.234203, test_loss: 103.387726\n",
      "epoch: 18000, train_loss: 49.563114, test_loss: 103.750870\n",
      "epoch: 18100, train_loss: 48.205229, test_loss: 103.387558\n",
      "epoch: 18200, train_loss: 48.810387, test_loss: 103.298729\n",
      "epoch: 18300, train_loss: 48.652243, test_loss: 103.768578\n",
      "epoch: 18400, train_loss: 51.044135, test_loss: 103.417435\n",
      "epoch: 18500, train_loss: 49.455797, test_loss: 103.936554\n",
      "epoch: 18600, train_loss: 49.443483, test_loss: 103.164413\n",
      "epoch: 18700, train_loss: 50.047005, test_loss: 104.603844\n",
      "epoch: 18800, train_loss: 49.317947, test_loss: 103.972427\n",
      "epoch: 18900, train_loss: 48.166416, test_loss: 104.034462\n",
      "epoch: 19000, train_loss: 48.914484, test_loss: 104.714554\n",
      "epoch: 19100, train_loss: 49.493200, test_loss: 104.961708\n",
      "epoch: 19200, train_loss: 48.456701, test_loss: 104.626663\n",
      "epoch: 19300, train_loss: 48.322212, test_loss: 104.275673\n",
      "epoch: 19400, train_loss: 48.519562, test_loss: 105.867195\n",
      "epoch: 19500, train_loss: 50.953499, test_loss: 105.228607\n",
      "epoch: 19600, train_loss: 48.866344, test_loss: 104.724007\n",
      "epoch: 19700, train_loss: 50.160439, test_loss: 105.217377\n",
      "epoch: 19800, train_loss: 49.690586, test_loss: 104.788307\n",
      "epoch: 19900, train_loss: 47.099174, test_loss: 106.301689\n",
      "epoch: 20000, train_loss: 50.490084, test_loss: 103.974861\n",
      "epoch: 20100, train_loss: 49.703506, test_loss: 105.314590\n",
      "epoch: 20200, train_loss: 48.044039, test_loss: 105.780197\n",
      "epoch: 20300, train_loss: 48.758718, test_loss: 105.979683\n",
      "epoch: 20400, train_loss: 49.852118, test_loss: 105.999741\n",
      "epoch: 20500, train_loss: 47.441318, test_loss: 106.024010\n",
      "epoch: 20600, train_loss: 48.325819, test_loss: 106.316689\n",
      "epoch: 20700, train_loss: 49.634268, test_loss: 105.428528\n",
      "epoch: 20800, train_loss: 48.919250, test_loss: 106.308762\n",
      "epoch: 20900, train_loss: 50.658024, test_loss: 105.808273\n",
      "epoch: 21000, train_loss: 49.009315, test_loss: 106.561058\n",
      "epoch: 21100, train_loss: 49.585363, test_loss: 106.554855\n",
      "epoch: 21200, train_loss: 49.414850, test_loss: 106.993340\n",
      "epoch: 21300, train_loss: 48.494373, test_loss: 106.934219\n",
      "epoch: 21400, train_loss: 47.845453, test_loss: 106.774483\n",
      "epoch: 21500, train_loss: 48.570024, test_loss: 106.713882\n",
      "epoch: 21600, train_loss: 48.771467, test_loss: 107.424255\n",
      "epoch: 21700, train_loss: 47.656412, test_loss: 107.916573\n",
      "epoch: 21800, train_loss: 47.793221, test_loss: 107.414803\n",
      "epoch: 21900, train_loss: 50.768343, test_loss: 107.278473\n",
      "epoch: 22000, train_loss: 48.518064, test_loss: 107.608826\n",
      "epoch: 22100, train_loss: 48.844915, test_loss: 107.072807\n",
      "epoch: 22200, train_loss: 48.168745, test_loss: 107.495132\n",
      "epoch: 22300, train_loss: 48.014683, test_loss: 107.519478\n",
      "epoch: 22400, train_loss: 48.485353, test_loss: 108.025024\n",
      "epoch: 22500, train_loss: 47.226738, test_loss: 107.372185\n",
      "epoch: 22600, train_loss: 48.758596, test_loss: 108.487099\n",
      "epoch: 22700, train_loss: 49.246969, test_loss: 107.396378\n",
      "epoch: 22800, train_loss: 47.609623, test_loss: 107.050552\n",
      "epoch: 22900, train_loss: 48.613134, test_loss: 107.610977\n",
      "epoch: 23000, train_loss: 48.246733, test_loss: 107.654007\n",
      "epoch: 23100, train_loss: 47.503633, test_loss: 108.686249\n",
      "epoch: 23200, train_loss: 46.756502, test_loss: 107.455048\n",
      "epoch: 23300, train_loss: 48.882423, test_loss: 108.097794\n",
      "epoch: 23400, train_loss: 48.668926, test_loss: 107.521797\n",
      "epoch: 23500, train_loss: 48.705925, test_loss: 108.079727\n",
      "epoch: 23600, train_loss: 48.086271, test_loss: 108.367981\n",
      "epoch: 23700, train_loss: 47.288240, test_loss: 107.681381\n",
      "epoch: 23800, train_loss: 46.262830, test_loss: 108.526756\n",
      "epoch: 23900, train_loss: 48.314157, test_loss: 108.096672\n",
      "epoch: 24000, train_loss: 48.152937, test_loss: 109.199440\n",
      "epoch: 24100, train_loss: 47.335758, test_loss: 108.504150\n",
      "epoch: 24200, train_loss: 48.289085, test_loss: 109.073364\n",
      "epoch: 24300, train_loss: 48.318542, test_loss: 109.179787\n",
      "epoch: 24400, train_loss: 46.460590, test_loss: 110.220009\n",
      "epoch: 24500, train_loss: 47.609764, test_loss: 110.432686\n",
      "epoch: 24600, train_loss: 48.581686, test_loss: 109.269394\n",
      "epoch: 24700, train_loss: 46.023281, test_loss: 109.004143\n",
      "epoch: 24800, train_loss: 46.975262, test_loss: 110.785133\n",
      "epoch: 24900, train_loss: 47.168816, test_loss: 109.279175\n",
      "epoch: 25000, train_loss: 47.891373, test_loss: 110.387772\n",
      "epoch: 25100, train_loss: 47.555998, test_loss: 109.733063\n",
      "epoch: 25200, train_loss: 48.492615, test_loss: 111.072601\n",
      "epoch: 25300, train_loss: 47.594202, test_loss: 110.459137\n",
      "epoch: 25400, train_loss: 49.199099, test_loss: 110.664650\n",
      "epoch: 25500, train_loss: 48.323338, test_loss: 110.725006\n",
      "epoch: 25600, train_loss: 48.283867, test_loss: 110.665695\n",
      "epoch: 25700, train_loss: 47.607681, test_loss: 110.841995\n",
      "epoch: 25800, train_loss: 47.702909, test_loss: 111.634338\n",
      "epoch: 25900, train_loss: 47.863295, test_loss: 111.178421\n",
      "epoch: 26000, train_loss: 46.840374, test_loss: 111.575127\n",
      "epoch: 26100, train_loss: 48.120216, test_loss: 111.975655\n",
      "epoch: 26200, train_loss: 47.455246, test_loss: 111.945717\n",
      "epoch: 26300, train_loss: 48.339678, test_loss: 111.693581\n",
      "epoch: 26400, train_loss: 47.979549, test_loss: 111.709541\n",
      "epoch: 26500, train_loss: 48.250021, test_loss: 112.740456\n",
      "epoch: 26600, train_loss: 47.742792, test_loss: 112.766273\n",
      "epoch: 26700, train_loss: 47.488258, test_loss: 111.837555\n",
      "epoch: 26800, train_loss: 47.511549, test_loss: 112.798477\n",
      "epoch: 26900, train_loss: 46.022974, test_loss: 113.540268\n",
      "epoch: 27000, train_loss: 46.939411, test_loss: 113.141747\n",
      "epoch: 27100, train_loss: 47.146839, test_loss: 113.532646\n",
      "epoch: 27200, train_loss: 47.439896, test_loss: 112.563866\n",
      "epoch: 27300, train_loss: 49.038370, test_loss: 112.329002\n",
      "epoch: 27400, train_loss: 47.835880, test_loss: 112.969734\n",
      "epoch: 27500, train_loss: 46.218637, test_loss: 112.881645\n",
      "epoch: 27600, train_loss: 47.360312, test_loss: 113.756615\n",
      "epoch: 27700, train_loss: 46.249380, test_loss: 113.250282\n",
      "epoch: 27800, train_loss: 47.027821, test_loss: 114.302635\n",
      "epoch: 27900, train_loss: 46.356674, test_loss: 113.805321\n",
      "epoch: 28000, train_loss: 45.436829, test_loss: 114.256950\n",
      "epoch: 28100, train_loss: 47.884094, test_loss: 113.826675\n",
      "epoch: 28200, train_loss: 45.656375, test_loss: 114.416687\n",
      "epoch: 28300, train_loss: 48.847702, test_loss: 113.651024\n",
      "epoch: 28400, train_loss: 47.807930, test_loss: 114.269768\n",
      "epoch: 28500, train_loss: 48.263382, test_loss: 114.950279\n",
      "epoch: 28600, train_loss: 47.857088, test_loss: 114.763184\n",
      "epoch: 28700, train_loss: 47.620277, test_loss: 115.115517\n",
      "epoch: 28800, train_loss: 46.986082, test_loss: 115.161949\n",
      "epoch: 28900, train_loss: 47.598900, test_loss: 114.375549\n",
      "epoch: 29000, train_loss: 46.470678, test_loss: 114.911163\n",
      "epoch: 29100, train_loss: 46.153074, test_loss: 116.106422\n",
      "epoch: 29200, train_loss: 46.453554, test_loss: 116.613022\n",
      "epoch: 29300, train_loss: 48.026480, test_loss: 116.486092\n",
      "epoch: 29400, train_loss: 46.315802, test_loss: 116.000160\n",
      "epoch: 29500, train_loss: 45.779558, test_loss: 116.335632\n",
      "epoch: 29600, train_loss: 47.811352, test_loss: 116.567879\n",
      "epoch: 29700, train_loss: 47.305351, test_loss: 116.671356\n",
      "epoch: 29800, train_loss: 46.286184, test_loss: 116.461517\n",
      "epoch: 29900, train_loss: 46.704096, test_loss: 116.683838\n",
      "epoch: 30000, train_loss: 46.557646, test_loss: 117.111145\n",
      "epoch: 30100, train_loss: 47.026867, test_loss: 117.003670\n",
      "epoch: 30200, train_loss: 47.380087, test_loss: 116.715775\n",
      "epoch: 30300, train_loss: 45.825228, test_loss: 116.860603\n",
      "epoch: 30400, train_loss: 47.639055, test_loss: 117.394463\n",
      "epoch: 30500, train_loss: 45.863283, test_loss: 116.469810\n",
      "epoch: 30600, train_loss: 48.835683, test_loss: 116.483162\n",
      "epoch: 30700, train_loss: 45.896584, test_loss: 117.136253\n",
      "epoch: 30800, train_loss: 46.500900, test_loss: 117.204857\n",
      "epoch: 30900, train_loss: 45.713474, test_loss: 117.971359\n",
      "epoch: 31000, train_loss: 45.363525, test_loss: 118.040627\n",
      "epoch: 31100, train_loss: 47.020065, test_loss: 117.911964\n",
      "epoch: 31200, train_loss: 45.152153, test_loss: 118.413521\n",
      "epoch: 31300, train_loss: 47.892597, test_loss: 117.817276\n",
      "epoch: 31400, train_loss: 46.318150, test_loss: 118.851944\n",
      "epoch: 31500, train_loss: 45.377006, test_loss: 118.933792\n",
      "epoch: 31600, train_loss: 46.768646, test_loss: 118.313103\n",
      "epoch: 31700, train_loss: 46.154919, test_loss: 118.424835\n",
      "epoch: 31800, train_loss: 48.133545, test_loss: 118.879616\n",
      "epoch: 31900, train_loss: 45.839811, test_loss: 118.096390\n",
      "epoch: 32000, train_loss: 47.055588, test_loss: 118.477898\n",
      "epoch: 32100, train_loss: 47.066858, test_loss: 118.625549\n",
      "epoch: 32200, train_loss: 46.069201, test_loss: 118.259415\n",
      "epoch: 32300, train_loss: 46.772083, test_loss: 119.214340\n",
      "epoch: 32400, train_loss: 47.657541, test_loss: 118.206268\n",
      "epoch: 32500, train_loss: 45.403666, test_loss: 118.540840\n",
      "epoch: 32600, train_loss: 46.173809, test_loss: 119.478760\n",
      "epoch: 32700, train_loss: 45.984976, test_loss: 119.314957\n",
      "epoch: 32800, train_loss: 46.804192, test_loss: 118.325554\n",
      "epoch: 32900, train_loss: 46.609358, test_loss: 119.496292\n",
      "epoch: 33000, train_loss: 46.576372, test_loss: 119.652405\n",
      "epoch: 33100, train_loss: 46.085615, test_loss: 119.543999\n",
      "epoch: 33200, train_loss: 44.081971, test_loss: 118.840385\n",
      "epoch: 33300, train_loss: 46.581833, test_loss: 119.553741\n",
      "epoch: 33400, train_loss: 47.065132, test_loss: 119.379692\n",
      "epoch: 33500, train_loss: 47.008789, test_loss: 118.801331\n",
      "epoch: 33600, train_loss: 46.060324, test_loss: 119.988419\n",
      "epoch: 33700, train_loss: 46.131578, test_loss: 119.635315\n",
      "epoch: 33800, train_loss: 45.809013, test_loss: 119.065125\n",
      "epoch: 33900, train_loss: 45.616796, test_loss: 120.838448\n",
      "epoch: 34000, train_loss: 45.850351, test_loss: 120.244705\n",
      "epoch: 34100, train_loss: 45.504761, test_loss: 120.251961\n",
      "epoch: 34200, train_loss: 44.837619, test_loss: 119.862244\n",
      "epoch: 34300, train_loss: 46.041405, test_loss: 120.252007\n",
      "epoch: 34400, train_loss: 45.751265, test_loss: 120.370125\n",
      "epoch: 34500, train_loss: 45.922689, test_loss: 119.139481\n",
      "epoch: 34600, train_loss: 45.707882, test_loss: 119.730095\n",
      "epoch: 34700, train_loss: 45.010265, test_loss: 120.154297\n",
      "epoch: 34800, train_loss: 46.036386, test_loss: 120.567871\n",
      "epoch: 34900, train_loss: 45.424232, test_loss: 119.455261\n",
      "epoch: 35000, train_loss: 46.540232, test_loss: 120.630188\n",
      "epoch: 35100, train_loss: 45.707708, test_loss: 120.517334\n",
      "epoch: 35200, train_loss: 45.754827, test_loss: 120.880424\n",
      "epoch: 35300, train_loss: 44.960033, test_loss: 120.001701\n",
      "epoch: 35400, train_loss: 47.017387, test_loss: 119.872177\n",
      "epoch: 35500, train_loss: 46.668985, test_loss: 120.910713\n",
      "epoch: 35600, train_loss: 46.687227, test_loss: 120.926895\n",
      "epoch: 35700, train_loss: 45.371885, test_loss: 121.010925\n",
      "epoch: 35800, train_loss: 44.627158, test_loss: 119.958466\n",
      "epoch: 35900, train_loss: 45.979399, test_loss: 120.765221\n",
      "epoch: 36000, train_loss: 45.464558, test_loss: 120.116798\n",
      "epoch: 36100, train_loss: 46.563990, test_loss: 119.860878\n",
      "epoch: 36200, train_loss: 46.417833, test_loss: 120.217804\n",
      "epoch: 36300, train_loss: 45.249998, test_loss: 120.219360\n",
      "epoch: 36400, train_loss: 45.024763, test_loss: 119.727554\n",
      "epoch: 36500, train_loss: 45.243082, test_loss: 120.145851\n",
      "epoch: 36600, train_loss: 47.971285, test_loss: 119.582092\n",
      "epoch: 36700, train_loss: 44.927856, test_loss: 118.731560\n",
      "epoch: 36800, train_loss: 46.672718, test_loss: 119.740601\n",
      "epoch: 36900, train_loss: 45.289629, test_loss: 119.832779\n",
      "epoch: 37000, train_loss: 45.907104, test_loss: 119.999664\n",
      "epoch: 37100, train_loss: 45.363087, test_loss: 119.821144\n",
      "epoch: 37200, train_loss: 46.316872, test_loss: 119.442711\n",
      "epoch: 37300, train_loss: 46.810236, test_loss: 119.258499\n",
      "epoch: 37400, train_loss: 46.985691, test_loss: 118.963440\n",
      "epoch: 37500, train_loss: 45.348625, test_loss: 119.300110\n",
      "epoch: 37600, train_loss: 45.248041, test_loss: 118.968170\n",
      "epoch: 37700, train_loss: 45.607891, test_loss: 118.363007\n",
      "epoch: 37800, train_loss: 45.397457, test_loss: 118.513443\n",
      "epoch: 37900, train_loss: 46.148647, test_loss: 118.303223\n",
      "epoch: 38000, train_loss: 44.842306, test_loss: 118.935379\n",
      "epoch: 38100, train_loss: 45.157024, test_loss: 118.307533\n",
      "epoch: 38200, train_loss: 46.089228, test_loss: 118.791214\n",
      "epoch: 38300, train_loss: 44.509459, test_loss: 119.651505\n",
      "epoch: 38400, train_loss: 44.791576, test_loss: 119.496681\n",
      "epoch: 38500, train_loss: 44.547368, test_loss: 117.495537\n",
      "epoch: 38600, train_loss: 46.920866, test_loss: 118.078110\n",
      "epoch: 38700, train_loss: 46.240810, test_loss: 118.568176\n",
      "epoch: 38800, train_loss: 46.080898, test_loss: 118.145409\n",
      "epoch: 38900, train_loss: 44.908373, test_loss: 118.139465\n",
      "epoch: 39000, train_loss: 45.026363, test_loss: 117.773331\n",
      "epoch: 39100, train_loss: 47.289100, test_loss: 117.432365\n",
      "epoch: 39200, train_loss: 45.446230, test_loss: 117.762833\n",
      "epoch: 39300, train_loss: 44.455082, test_loss: 118.458595\n",
      "epoch: 39400, train_loss: 45.315796, test_loss: 118.039833\n",
      "epoch: 39500, train_loss: 46.661767, test_loss: 117.754868\n",
      "epoch: 39600, train_loss: 44.667282, test_loss: 117.767685\n",
      "epoch: 39700, train_loss: 45.342113, test_loss: 118.153320\n",
      "epoch: 39800, train_loss: 44.482306, test_loss: 117.946190\n",
      "epoch: 39900, train_loss: 45.299528, test_loss: 118.587685\n",
      "epoch: 40000, train_loss: 45.240736, test_loss: 117.645546\n",
      "epoch: 40100, train_loss: 45.070507, test_loss: 118.118088\n",
      "epoch: 40200, train_loss: 45.364578, test_loss: 116.946098\n",
      "epoch: 40300, train_loss: 46.087988, test_loss: 118.015656\n",
      "epoch: 40400, train_loss: 45.229904, test_loss: 116.865944\n",
      "epoch: 40500, train_loss: 44.949984, test_loss: 117.561874\n",
      "epoch: 40600, train_loss: 46.496258, test_loss: 117.162338\n",
      "epoch: 40700, train_loss: 46.912820, test_loss: 117.012184\n",
      "epoch: 40800, train_loss: 45.926470, test_loss: 116.910759\n",
      "epoch: 40900, train_loss: 44.017731, test_loss: 116.906044\n",
      "epoch: 41000, train_loss: 46.672227, test_loss: 120.211746\n",
      "epoch: 41100, train_loss: 43.591028, test_loss: 119.334862\n",
      "epoch: 41200, train_loss: 43.971827, test_loss: 120.082504\n",
      "epoch: 41300, train_loss: 44.504772, test_loss: 120.012527\n",
      "epoch: 41400, train_loss: 44.298388, test_loss: 121.231972\n",
      "epoch: 41500, train_loss: 44.545353, test_loss: 121.402573\n",
      "epoch: 41600, train_loss: 46.732429, test_loss: 122.586449\n",
      "epoch: 41700, train_loss: 44.028666, test_loss: 121.504242\n",
      "epoch: 41800, train_loss: 44.176233, test_loss: 122.689995\n",
      "epoch: 41900, train_loss: 44.736967, test_loss: 122.212624\n",
      "epoch: 42000, train_loss: 44.405991, test_loss: 123.420036\n",
      "epoch: 42100, train_loss: 43.968668, test_loss: 122.869774\n",
      "epoch: 42200, train_loss: 45.687788, test_loss: 122.051407\n",
      "epoch: 42300, train_loss: 44.888367, test_loss: 122.255775\n",
      "epoch: 42400, train_loss: 44.177053, test_loss: 122.808205\n",
      "epoch: 42500, train_loss: 42.805868, test_loss: 122.744507\n",
      "epoch: 42600, train_loss: 43.081148, test_loss: 122.338982\n",
      "epoch: 42700, train_loss: 44.627834, test_loss: 122.191299\n",
      "epoch: 42800, train_loss: 44.206945, test_loss: 122.699356\n",
      "epoch: 42900, train_loss: 44.188976, test_loss: 122.982979\n",
      "epoch: 43000, train_loss: 45.177891, test_loss: 122.564682\n",
      "epoch: 43100, train_loss: 42.831915, test_loss: 122.878723\n",
      "epoch: 43200, train_loss: 44.639378, test_loss: 122.538261\n",
      "epoch: 43300, train_loss: 44.200922, test_loss: 121.948830\n",
      "epoch: 43400, train_loss: 43.654190, test_loss: 122.516670\n",
      "epoch: 43500, train_loss: 43.709623, test_loss: 122.483917\n",
      "epoch: 43600, train_loss: 44.643631, test_loss: 122.053139\n",
      "epoch: 43700, train_loss: 45.299074, test_loss: 123.246323\n",
      "epoch: 43800, train_loss: 43.633598, test_loss: 121.590317\n",
      "epoch: 43900, train_loss: 42.684527, test_loss: 122.346626\n",
      "epoch: 44000, train_loss: 44.949808, test_loss: 121.777443\n",
      "epoch: 44100, train_loss: 45.178102, test_loss: 121.868561\n",
      "epoch: 44200, train_loss: 44.388231, test_loss: 122.223770\n",
      "epoch: 44300, train_loss: 42.906642, test_loss: 122.185173\n",
      "epoch: 44400, train_loss: 45.204617, test_loss: 122.360741\n",
      "epoch: 44500, train_loss: 44.473993, test_loss: 121.993317\n",
      "epoch: 44600, train_loss: 44.444546, test_loss: 122.065048\n",
      "epoch: 44700, train_loss: 45.277403, test_loss: 122.330780\n",
      "epoch: 44800, train_loss: 43.892433, test_loss: 123.336136\n",
      "epoch: 44900, train_loss: 43.159534, test_loss: 122.091827\n",
      "epoch: 45000, train_loss: 43.497744, test_loss: 122.333633\n",
      "epoch: 45100, train_loss: 42.702729, test_loss: 122.647057\n",
      "epoch: 45200, train_loss: 43.527447, test_loss: 121.498672\n",
      "epoch: 45300, train_loss: 45.229006, test_loss: 121.909081\n",
      "epoch: 45400, train_loss: 43.153473, test_loss: 122.613335\n",
      "epoch: 45500, train_loss: 44.039684, test_loss: 121.557281\n",
      "epoch: 45600, train_loss: 44.130293, test_loss: 122.682953\n",
      "epoch: 45700, train_loss: 44.024225, test_loss: 122.886620\n",
      "epoch: 45800, train_loss: 44.004671, test_loss: 121.820381\n",
      "epoch: 45900, train_loss: 43.965038, test_loss: 121.266930\n",
      "epoch: 46000, train_loss: 44.393747, test_loss: 121.342476\n",
      "epoch: 46100, train_loss: 43.622879, test_loss: 121.133034\n",
      "epoch: 46200, train_loss: 42.774810, test_loss: 120.838058\n",
      "epoch: 46300, train_loss: 43.617868, test_loss: 121.225807\n",
      "epoch: 46400, train_loss: 45.548311, test_loss: 122.341698\n",
      "epoch: 46500, train_loss: 45.232800, test_loss: 121.425697\n",
      "epoch: 46600, train_loss: 44.961292, test_loss: 121.172699\n",
      "epoch: 46700, train_loss: 44.722286, test_loss: 119.805412\n",
      "epoch: 46800, train_loss: 44.976130, test_loss: 121.031441\n",
      "epoch: 46900, train_loss: 42.815965, test_loss: 120.742905\n",
      "epoch: 47000, train_loss: 43.150297, test_loss: 120.465637\n",
      "epoch: 47100, train_loss: 45.453114, test_loss: 120.742622\n",
      "epoch: 47200, train_loss: 44.768574, test_loss: 120.112335\n",
      "epoch: 47300, train_loss: 42.532302, test_loss: 120.433563\n",
      "epoch: 47400, train_loss: 44.262079, test_loss: 120.758713\n",
      "epoch: 47500, train_loss: 45.165035, test_loss: 120.207260\n",
      "epoch: 47600, train_loss: 44.525333, test_loss: 120.643806\n",
      "epoch: 47700, train_loss: 43.016438, test_loss: 119.996315\n",
      "epoch: 47800, train_loss: 44.129704, test_loss: 119.768066\n",
      "epoch: 47900, train_loss: 44.660767, test_loss: 119.646805\n",
      "epoch: 48000, train_loss: 43.525457, test_loss: 120.172531\n",
      "epoch: 48100, train_loss: 43.553892, test_loss: 120.080414\n",
      "epoch: 48200, train_loss: 43.605019, test_loss: 119.198242\n",
      "epoch: 48300, train_loss: 43.407179, test_loss: 119.255714\n",
      "epoch: 48400, train_loss: 43.759022, test_loss: 119.803459\n",
      "epoch: 48500, train_loss: 43.993452, test_loss: 119.234215\n",
      "epoch: 48600, train_loss: 43.744253, test_loss: 119.338387\n",
      "epoch: 48700, train_loss: 44.564230, test_loss: 119.749504\n",
      "epoch: 48800, train_loss: 43.327948, test_loss: 119.754372\n",
      "epoch: 48900, train_loss: 45.671960, test_loss: 119.811981\n",
      "epoch: 49000, train_loss: 45.343883, test_loss: 120.570824\n",
      "epoch: 49100, train_loss: 44.268040, test_loss: 118.915894\n",
      "epoch: 49200, train_loss: 43.543886, test_loss: 118.579895\n",
      "epoch: 49300, train_loss: 43.603264, test_loss: 118.569725\n",
      "epoch: 49400, train_loss: 43.596390, test_loss: 118.480553\n",
      "epoch: 49500, train_loss: 43.354240, test_loss: 118.510414\n",
      "epoch: 49600, train_loss: 43.915718, test_loss: 119.745216\n",
      "epoch: 49700, train_loss: 42.381248, test_loss: 119.273994\n",
      "epoch: 49800, train_loss: 43.695896, test_loss: 119.305786\n",
      "epoch: 49900, train_loss: 43.360806, test_loss: 119.395821\n",
      "epoch: 50000, train_loss: 43.773245, test_loss: 118.216530\n",
      "epoch: 50100, train_loss: 44.378487, test_loss: 118.440628\n",
      "epoch: 50200, train_loss: 44.153080, test_loss: 118.486732\n",
      "epoch: 50300, train_loss: 45.452688, test_loss: 118.162384\n",
      "epoch: 50400, train_loss: 42.256416, test_loss: 117.813293\n",
      "epoch: 50500, train_loss: 42.786182, test_loss: 118.537819\n",
      "epoch: 50600, train_loss: 43.967615, test_loss: 118.728905\n",
      "epoch: 50700, train_loss: 44.636600, test_loss: 117.514557\n",
      "epoch: 50800, train_loss: 43.797937, test_loss: 118.687614\n",
      "epoch: 50900, train_loss: 43.761513, test_loss: 118.044716\n",
      "epoch: 51000, train_loss: 44.118811, test_loss: 118.204926\n",
      "epoch: 51100, train_loss: 43.550892, test_loss: 117.830399\n",
      "epoch: 51200, train_loss: 43.832773, test_loss: 118.148064\n",
      "epoch: 51300, train_loss: 43.364918, test_loss: 118.658951\n",
      "epoch: 51400, train_loss: 42.067384, test_loss: 118.096046\n",
      "epoch: 51500, train_loss: 41.923480, test_loss: 117.746727\n",
      "epoch: 51600, train_loss: 43.037666, test_loss: 117.467377\n",
      "epoch: 51700, train_loss: 44.895960, test_loss: 118.049011\n",
      "epoch: 51800, train_loss: 44.650084, test_loss: 117.550949\n",
      "epoch: 51900, train_loss: 42.516734, test_loss: 117.492264\n",
      "epoch: 52000, train_loss: 42.712362, test_loss: 117.351685\n",
      "epoch: 52100, train_loss: 43.696711, test_loss: 117.420761\n",
      "epoch: 52200, train_loss: 42.216218, test_loss: 117.569771\n",
      "epoch: 52300, train_loss: 45.036070, test_loss: 117.590485\n",
      "epoch: 52400, train_loss: 44.018600, test_loss: 117.805367\n",
      "epoch: 52500, train_loss: 43.474016, test_loss: 117.136002\n",
      "epoch: 52600, train_loss: 44.070715, test_loss: 117.578239\n",
      "epoch: 52700, train_loss: 41.945159, test_loss: 117.658203\n",
      "epoch: 52800, train_loss: 43.109997, test_loss: 117.213684\n",
      "epoch: 52900, train_loss: 43.482843, test_loss: 118.386353\n",
      "epoch: 53000, train_loss: 43.626135, test_loss: 118.158203\n",
      "epoch: 53100, train_loss: 44.830884, test_loss: 118.160950\n",
      "epoch: 53200, train_loss: 43.467018, test_loss: 117.468239\n",
      "epoch: 53300, train_loss: 43.137360, test_loss: 117.471329\n",
      "epoch: 53400, train_loss: 43.094175, test_loss: 117.071373\n",
      "epoch: 53500, train_loss: 44.095392, test_loss: 116.704002\n",
      "epoch: 53600, train_loss: 42.871168, test_loss: 117.519989\n",
      "epoch: 53700, train_loss: 42.866690, test_loss: 117.041695\n",
      "epoch: 53800, train_loss: 43.463169, test_loss: 116.624931\n",
      "epoch: 53900, train_loss: 42.803640, test_loss: 116.534599\n",
      "epoch: 54000, train_loss: 42.425568, test_loss: 116.763588\n",
      "epoch: 54100, train_loss: 44.485647, test_loss: 117.417084\n",
      "epoch: 54200, train_loss: 44.416315, test_loss: 117.164421\n",
      "epoch: 54300, train_loss: 43.461119, test_loss: 117.467590\n",
      "epoch: 54400, train_loss: 44.853395, test_loss: 117.742859\n",
      "epoch: 54500, train_loss: 44.064795, test_loss: 117.199516\n",
      "epoch: 54600, train_loss: 43.830841, test_loss: 116.986473\n",
      "epoch: 54700, train_loss: 44.182337, test_loss: 118.045021\n",
      "epoch: 54800, train_loss: 43.809111, test_loss: 117.475479\n",
      "epoch: 54900, train_loss: 43.180126, test_loss: 117.444405\n",
      "epoch: 55000, train_loss: 43.504168, test_loss: 117.394531\n",
      "epoch: 55100, train_loss: 43.306538, test_loss: 117.062592\n",
      "epoch: 55200, train_loss: 42.783472, test_loss: 117.554222\n",
      "epoch: 55300, train_loss: 43.746021, test_loss: 117.659363\n",
      "epoch: 55400, train_loss: 45.864187, test_loss: 117.192200\n",
      "epoch: 55500, train_loss: 44.229330, test_loss: 117.820305\n",
      "epoch: 55600, train_loss: 41.982704, test_loss: 117.684471\n",
      "epoch: 55700, train_loss: 43.321890, test_loss: 117.188568\n",
      "epoch: 55800, train_loss: 44.636381, test_loss: 117.126564\n",
      "epoch: 55900, train_loss: 44.163248, test_loss: 117.581940\n",
      "epoch: 56000, train_loss: 43.474611, test_loss: 117.332001\n",
      "epoch: 56100, train_loss: 44.036415, test_loss: 117.665504\n",
      "epoch: 56200, train_loss: 45.246655, test_loss: 117.362541\n",
      "epoch: 56300, train_loss: 43.193949, test_loss: 117.091217\n",
      "epoch: 56400, train_loss: 41.832057, test_loss: 118.112137\n",
      "epoch: 56500, train_loss: 41.961721, test_loss: 117.366310\n",
      "epoch: 56600, train_loss: 42.588310, test_loss: 117.440437\n",
      "epoch: 56700, train_loss: 44.723355, test_loss: 117.755814\n",
      "epoch: 56800, train_loss: 42.934702, test_loss: 118.560936\n",
      "epoch: 56900, train_loss: 44.279827, test_loss: 118.373352\n",
      "epoch: 57000, train_loss: 44.030588, test_loss: 117.577988\n",
      "epoch: 57100, train_loss: 44.375690, test_loss: 117.570999\n",
      "epoch: 57200, train_loss: 42.774374, test_loss: 117.962257\n",
      "epoch: 57300, train_loss: 42.788027, test_loss: 117.417534\n",
      "epoch: 57400, train_loss: 43.704666, test_loss: 117.418022\n",
      "epoch: 57500, train_loss: 43.887922, test_loss: 117.670982\n",
      "epoch: 57600, train_loss: 43.703081, test_loss: 117.526054\n",
      "epoch: 57700, train_loss: 44.439486, test_loss: 116.778465\n",
      "epoch: 57800, train_loss: 42.602110, test_loss: 118.161415\n",
      "epoch: 57900, train_loss: 42.964525, test_loss: 117.823914\n",
      "epoch: 58000, train_loss: 42.916042, test_loss: 118.518265\n",
      "epoch: 58100, train_loss: 43.287407, test_loss: 118.212921\n",
      "epoch: 58200, train_loss: 43.794781, test_loss: 118.326447\n",
      "epoch: 58300, train_loss: 44.128374, test_loss: 118.346748\n",
      "epoch: 58400, train_loss: 43.251530, test_loss: 117.887810\n",
      "epoch: 58500, train_loss: 43.878065, test_loss: 117.784523\n",
      "epoch: 58600, train_loss: 42.362807, test_loss: 118.027527\n",
      "epoch: 58700, train_loss: 44.392067, test_loss: 117.583397\n",
      "epoch: 58800, train_loss: 43.672304, test_loss: 117.460274\n",
      "epoch: 58900, train_loss: 45.491556, test_loss: 117.899353\n",
      "epoch: 59000, train_loss: 44.231525, test_loss: 118.353546\n",
      "epoch: 59100, train_loss: 42.865744, test_loss: 117.479546\n",
      "epoch: 59200, train_loss: 43.992891, test_loss: 118.278778\n",
      "epoch: 59300, train_loss: 42.937508, test_loss: 119.003601\n",
      "epoch: 59400, train_loss: 42.324059, test_loss: 117.891212\n",
      "epoch: 59500, train_loss: 43.651989, test_loss: 117.822334\n",
      "epoch: 59600, train_loss: 43.611610, test_loss: 117.922615\n",
      "epoch: 59700, train_loss: 42.838285, test_loss: 118.420883\n",
      "epoch: 59800, train_loss: 42.975569, test_loss: 117.850189\n",
      "epoch: 59900, train_loss: 44.393105, test_loss: 118.169167\n",
      "epoch: 60000, train_loss: 44.702062, test_loss: 117.644630\n",
      "epoch: 60100, train_loss: 42.649521, test_loss: 117.787567\n",
      "epoch: 60200, train_loss: 43.670353, test_loss: 117.773224\n",
      "epoch: 60300, train_loss: 42.935335, test_loss: 117.924301\n",
      "epoch: 60400, train_loss: 43.671179, test_loss: 117.921181\n",
      "epoch: 60500, train_loss: 43.385782, test_loss: 118.376770\n",
      "epoch: 60600, train_loss: 43.612547, test_loss: 118.106499\n",
      "epoch: 60700, train_loss: 45.648451, test_loss: 118.045174\n",
      "epoch: 60800, train_loss: 44.781503, test_loss: 118.066437\n",
      "epoch: 60900, train_loss: 44.333181, test_loss: 118.026337\n",
      "epoch: 61000, train_loss: 44.036829, test_loss: 118.014175\n",
      "epoch: 61100, train_loss: 44.759178, test_loss: 118.543190\n",
      "epoch: 61200, train_loss: 42.707897, test_loss: 117.752640\n",
      "epoch: 61300, train_loss: 43.033545, test_loss: 117.651787\n",
      "epoch: 61400, train_loss: 43.007713, test_loss: 117.943588\n",
      "epoch: 61500, train_loss: 43.460007, test_loss: 118.512207\n",
      "epoch: 61600, train_loss: 44.792020, test_loss: 118.854965\n",
      "epoch: 61700, train_loss: 43.093874, test_loss: 117.676575\n",
      "epoch: 61800, train_loss: 43.215630, test_loss: 118.713516\n",
      "epoch: 61900, train_loss: 44.518431, test_loss: 118.399490\n",
      "epoch: 62000, train_loss: 43.424881, test_loss: 118.422195\n",
      "epoch: 62100, train_loss: 43.520266, test_loss: 118.575760\n",
      "epoch: 62200, train_loss: 44.524096, test_loss: 118.069908\n",
      "epoch: 62300, train_loss: 44.565890, test_loss: 117.634850\n",
      "epoch: 62400, train_loss: 42.485748, test_loss: 118.140450\n",
      "epoch: 62500, train_loss: 41.132791, test_loss: 118.502342\n",
      "epoch: 62600, train_loss: 43.707273, test_loss: 118.542549\n",
      "epoch: 62700, train_loss: 42.741590, test_loss: 118.434013\n",
      "epoch: 62800, train_loss: 43.115114, test_loss: 118.446548\n",
      "epoch: 62900, train_loss: 43.584120, test_loss: 119.443970\n",
      "epoch: 63000, train_loss: 45.057215, test_loss: 118.439728\n",
      "epoch: 63100, train_loss: 43.536629, test_loss: 118.788551\n",
      "epoch: 63200, train_loss: 44.231041, test_loss: 118.586098\n",
      "epoch: 63300, train_loss: 41.678964, test_loss: 119.135132\n",
      "epoch: 63400, train_loss: 44.950579, test_loss: 118.291962\n",
      "epoch: 63500, train_loss: 44.103642, test_loss: 119.393364\n",
      "epoch: 63600, train_loss: 42.602407, test_loss: 117.997070\n",
      "epoch: 63700, train_loss: 42.773165, test_loss: 119.348991\n",
      "epoch: 63800, train_loss: 42.494230, test_loss: 118.985405\n",
      "epoch: 63900, train_loss: 43.771151, test_loss: 118.766548\n",
      "epoch: 64000, train_loss: 44.503903, test_loss: 118.102859\n",
      "epoch: 64100, train_loss: 44.830121, test_loss: 118.873734\n",
      "epoch: 64200, train_loss: 42.820602, test_loss: 118.951019\n",
      "epoch: 64300, train_loss: 42.327118, test_loss: 119.114243\n",
      "epoch: 64400, train_loss: 42.551575, test_loss: 117.858582\n",
      "epoch: 64500, train_loss: 42.588152, test_loss: 118.754868\n",
      "epoch: 64600, train_loss: 43.153339, test_loss: 118.574356\n",
      "epoch: 64700, train_loss: 43.923294, test_loss: 118.641212\n",
      "epoch: 64800, train_loss: 42.315740, test_loss: 118.072296\n",
      "epoch: 64900, train_loss: 43.276196, test_loss: 118.834175\n",
      "epoch: 65000, train_loss: 42.573294, test_loss: 118.439064\n",
      "epoch: 65100, train_loss: 43.152037, test_loss: 118.432281\n",
      "epoch: 65200, train_loss: 43.003872, test_loss: 118.543846\n",
      "epoch: 65300, train_loss: 44.913900, test_loss: 118.366959\n",
      "epoch: 65400, train_loss: 43.371706, test_loss: 118.439651\n",
      "epoch: 65500, train_loss: 42.994083, test_loss: 117.900040\n",
      "epoch: 65600, train_loss: 43.139429, test_loss: 119.043083\n",
      "epoch: 65700, train_loss: 42.391935, test_loss: 118.464760\n",
      "epoch: 65800, train_loss: 43.752798, test_loss: 119.161438\n",
      "epoch: 65900, train_loss: 44.546969, test_loss: 118.397499\n",
      "epoch: 66000, train_loss: 44.002254, test_loss: 118.930885\n",
      "epoch: 66100, train_loss: 43.943361, test_loss: 119.031326\n",
      "epoch: 66200, train_loss: 42.619499, test_loss: 118.972061\n",
      "epoch: 66300, train_loss: 42.833048, test_loss: 118.350708\n",
      "epoch: 66400, train_loss: 43.593510, test_loss: 118.654129\n",
      "epoch: 66500, train_loss: 42.418642, test_loss: 118.769768\n",
      "epoch: 66600, train_loss: 43.327993, test_loss: 118.506660\n",
      "epoch: 66700, train_loss: 42.810114, test_loss: 118.529160\n",
      "epoch: 66800, train_loss: 42.911179, test_loss: 119.053955\n",
      "epoch: 66900, train_loss: 42.914419, test_loss: 118.573479\n",
      "epoch: 67000, train_loss: 43.904341, test_loss: 119.542557\n",
      "epoch: 67100, train_loss: 42.474438, test_loss: 119.420990\n",
      "epoch: 67200, train_loss: 42.838032, test_loss: 118.528931\n",
      "epoch: 67300, train_loss: 43.744099, test_loss: 119.389069\n",
      "epoch: 67400, train_loss: 43.156334, test_loss: 118.794579\n",
      "epoch: 67500, train_loss: 43.239098, test_loss: 119.432671\n",
      "epoch: 67600, train_loss: 43.256788, test_loss: 118.889709\n",
      "epoch: 67700, train_loss: 43.529848, test_loss: 118.868286\n",
      "epoch: 67800, train_loss: 42.941458, test_loss: 118.689850\n",
      "epoch: 67900, train_loss: 44.507067, test_loss: 119.388916\n",
      "epoch: 68000, train_loss: 42.194535, test_loss: 119.045158\n",
      "epoch: 68100, train_loss: 42.635521, test_loss: 119.002617\n",
      "epoch: 68200, train_loss: 42.813221, test_loss: 119.055077\n",
      "epoch: 68300, train_loss: 43.142462, test_loss: 119.189819\n",
      "epoch: 68400, train_loss: 43.527233, test_loss: 118.505554\n",
      "epoch: 68500, train_loss: 43.564569, test_loss: 119.256828\n",
      "epoch: 68600, train_loss: 43.681787, test_loss: 118.804031\n",
      "epoch: 68700, train_loss: 43.444664, test_loss: 118.553169\n",
      "epoch: 68800, train_loss: 42.314808, test_loss: 118.845459\n",
      "epoch: 68900, train_loss: 43.013477, test_loss: 118.859436\n",
      "epoch: 69000, train_loss: 43.885334, test_loss: 118.711464\n",
      "epoch: 69100, train_loss: 43.255987, test_loss: 119.331032\n",
      "epoch: 69200, train_loss: 43.345083, test_loss: 119.249519\n",
      "epoch: 69300, train_loss: 43.021231, test_loss: 118.545776\n",
      "epoch: 69400, train_loss: 43.911039, test_loss: 119.605751\n",
      "epoch: 69500, train_loss: 44.606472, test_loss: 119.604904\n",
      "epoch: 69600, train_loss: 43.491314, test_loss: 119.747650\n",
      "epoch: 69700, train_loss: 43.159805, test_loss: 118.953186\n",
      "epoch: 69800, train_loss: 42.481976, test_loss: 119.040970\n",
      "epoch: 69900, train_loss: 45.567455, test_loss: 119.249092\n",
      "epoch: 70000, train_loss: 42.791660, test_loss: 119.306709\n",
      "epoch: 70100, train_loss: 43.226080, test_loss: 118.456779\n",
      "epoch: 70200, train_loss: 44.179146, test_loss: 118.978729\n",
      "epoch: 70300, train_loss: 42.705505, test_loss: 119.140678\n",
      "epoch: 70400, train_loss: 43.825575, test_loss: 119.246201\n",
      "epoch: 70500, train_loss: 43.525723, test_loss: 119.472656\n",
      "epoch: 70600, train_loss: 43.171410, test_loss: 118.862335\n",
      "epoch: 70700, train_loss: 42.826275, test_loss: 119.090126\n",
      "epoch: 70800, train_loss: 42.306034, test_loss: 119.483131\n",
      "epoch: 70900, train_loss: 42.986340, test_loss: 119.188446\n",
      "epoch: 71000, train_loss: 42.388683, test_loss: 119.204895\n",
      "epoch: 71100, train_loss: 42.241480, test_loss: 119.164818\n",
      "epoch: 71200, train_loss: 43.926355, test_loss: 119.293152\n",
      "epoch: 71300, train_loss: 43.000315, test_loss: 119.609001\n",
      "epoch: 71400, train_loss: 42.221178, test_loss: 119.748108\n",
      "epoch: 71500, train_loss: 44.631786, test_loss: 120.000893\n",
      "epoch: 71600, train_loss: 42.698112, test_loss: 120.222626\n",
      "epoch: 71700, train_loss: 42.801159, test_loss: 120.152344\n",
      "epoch: 71800, train_loss: 43.975243, test_loss: 119.101746\n",
      "epoch: 71900, train_loss: 42.829561, test_loss: 118.668526\n",
      "epoch: 72000, train_loss: 43.778362, test_loss: 119.894829\n",
      "epoch: 72100, train_loss: 43.043051, test_loss: 119.989845\n",
      "epoch: 72200, train_loss: 42.778902, test_loss: 120.292244\n",
      "epoch: 72300, train_loss: 43.897062, test_loss: 119.812294\n",
      "epoch: 72400, train_loss: 44.701981, test_loss: 119.392929\n",
      "epoch: 72500, train_loss: 42.571638, test_loss: 119.823624\n",
      "epoch: 72600, train_loss: 44.685900, test_loss: 120.062813\n",
      "epoch: 72700, train_loss: 42.974998, test_loss: 119.654541\n",
      "epoch: 72800, train_loss: 44.037340, test_loss: 118.923164\n",
      "epoch: 72900, train_loss: 42.156329, test_loss: 119.711037\n",
      "epoch: 73000, train_loss: 43.502897, test_loss: 120.182106\n",
      "epoch: 73100, train_loss: 42.399237, test_loss: 120.427109\n",
      "epoch: 73200, train_loss: 42.287800, test_loss: 119.682541\n",
      "epoch: 73300, train_loss: 43.277241, test_loss: 119.577332\n",
      "epoch: 73400, train_loss: 43.391468, test_loss: 119.667572\n",
      "epoch: 73500, train_loss: 42.879930, test_loss: 119.664833\n",
      "epoch: 73600, train_loss: 42.704573, test_loss: 120.257057\n",
      "epoch: 73700, train_loss: 43.712698, test_loss: 119.185768\n",
      "epoch: 73800, train_loss: 43.482277, test_loss: 120.255440\n",
      "epoch: 73900, train_loss: 43.681618, test_loss: 120.356560\n",
      "epoch: 74000, train_loss: 42.593767, test_loss: 120.101318\n",
      "epoch: 74100, train_loss: 42.379910, test_loss: 119.616730\n",
      "epoch: 74200, train_loss: 42.933502, test_loss: 119.809433\n",
      "epoch: 74300, train_loss: 42.955513, test_loss: 119.519409\n",
      "epoch: 74400, train_loss: 41.947424, test_loss: 119.690025\n",
      "epoch: 74500, train_loss: 42.076123, test_loss: 120.261864\n",
      "epoch: 74600, train_loss: 43.407309, test_loss: 119.659439\n",
      "epoch: 74700, train_loss: 42.514774, test_loss: 120.925240\n",
      "epoch: 74800, train_loss: 42.985844, test_loss: 120.144897\n",
      "epoch: 74900, train_loss: 42.444387, test_loss: 120.111122\n",
      "epoch: 75000, train_loss: 44.312788, test_loss: 119.747490\n",
      "epoch: 75100, train_loss: 43.389732, test_loss: 119.925385\n",
      "epoch: 75200, train_loss: 43.744162, test_loss: 119.853165\n",
      "epoch: 75300, train_loss: 43.498655, test_loss: 119.751366\n",
      "epoch: 75400, train_loss: 42.790421, test_loss: 119.851028\n",
      "epoch: 75500, train_loss: 43.878340, test_loss: 120.304619\n",
      "epoch: 75600, train_loss: 43.313780, test_loss: 119.400848\n",
      "epoch: 75700, train_loss: 43.167343, test_loss: 119.368683\n",
      "epoch: 75800, train_loss: 43.418579, test_loss: 119.983719\n",
      "epoch: 75900, train_loss: 42.241316, test_loss: 119.997459\n",
      "epoch: 76000, train_loss: 43.338055, test_loss: 120.663017\n",
      "epoch: 76100, train_loss: 43.748152, test_loss: 119.986816\n",
      "epoch: 76200, train_loss: 42.803293, test_loss: 120.645531\n",
      "epoch: 76300, train_loss: 42.744297, test_loss: 119.845062\n",
      "epoch: 76400, train_loss: 41.543247, test_loss: 120.490623\n",
      "epoch: 76500, train_loss: 44.041285, test_loss: 120.114410\n",
      "epoch: 76600, train_loss: 43.074865, test_loss: 119.928123\n",
      "epoch: 76700, train_loss: 43.416714, test_loss: 120.065681\n",
      "epoch: 76800, train_loss: 44.199518, test_loss: 120.065155\n",
      "epoch: 76900, train_loss: 43.381285, test_loss: 120.136383\n",
      "epoch: 77000, train_loss: 44.191490, test_loss: 120.159920\n",
      "epoch: 77100, train_loss: 43.392645, test_loss: 120.100655\n",
      "epoch: 77200, train_loss: 41.672726, test_loss: 120.125465\n",
      "epoch: 77300, train_loss: 42.179969, test_loss: 119.931976\n",
      "epoch: 77400, train_loss: 41.963684, test_loss: 120.181427\n",
      "epoch: 77500, train_loss: 41.651196, test_loss: 119.820473\n",
      "epoch: 77600, train_loss: 42.218996, test_loss: 119.852959\n",
      "epoch: 77700, train_loss: 44.145939, test_loss: 119.513100\n",
      "epoch: 77800, train_loss: 43.047432, test_loss: 120.523743\n",
      "epoch: 77900, train_loss: 45.026596, test_loss: 120.056862\n",
      "epoch: 78000, train_loss: 42.164375, test_loss: 120.328522\n",
      "epoch: 78100, train_loss: 44.324813, test_loss: 119.799538\n",
      "epoch: 78200, train_loss: 42.123716, test_loss: 120.303642\n",
      "epoch: 78300, train_loss: 44.763517, test_loss: 119.925865\n",
      "epoch: 78400, train_loss: 43.379110, test_loss: 119.940735\n",
      "epoch: 78500, train_loss: 44.825739, test_loss: 120.482254\n",
      "epoch: 78600, train_loss: 43.113869, test_loss: 120.075745\n",
      "epoch: 78700, train_loss: 45.205589, test_loss: 120.520004\n",
      "epoch: 78800, train_loss: 41.871472, test_loss: 120.998505\n",
      "epoch: 78900, train_loss: 43.874538, test_loss: 120.495117\n",
      "epoch: 79000, train_loss: 42.724421, test_loss: 121.614594\n",
      "epoch: 79100, train_loss: 43.621902, test_loss: 120.649315\n",
      "epoch: 79200, train_loss: 42.094045, test_loss: 120.627274\n",
      "epoch: 79300, train_loss: 43.777086, test_loss: 120.497292\n",
      "epoch: 79400, train_loss: 43.261068, test_loss: 120.279495\n",
      "epoch: 79500, train_loss: 43.939547, test_loss: 120.176598\n",
      "epoch: 79600, train_loss: 42.774881, test_loss: 120.768509\n",
      "epoch: 79700, train_loss: 44.494481, test_loss: 121.074005\n",
      "epoch: 79800, train_loss: 43.734743, test_loss: 120.590515\n",
      "epoch: 79900, train_loss: 43.757845, test_loss: 119.841324\n",
      "epoch: 80000, train_loss: 41.854370, test_loss: 120.754517\n",
      "epoch: 80100, train_loss: 44.098469, test_loss: 120.258659\n",
      "epoch: 80200, train_loss: 43.768681, test_loss: 120.277176\n",
      "epoch: 80300, train_loss: 43.394812, test_loss: 120.503197\n",
      "epoch: 80400, train_loss: 44.045319, test_loss: 120.333374\n",
      "epoch: 80500, train_loss: 43.189596, test_loss: 120.500488\n",
      "epoch: 80600, train_loss: 42.430683, test_loss: 120.693459\n",
      "epoch: 80700, train_loss: 43.838282, test_loss: 120.825462\n",
      "epoch: 80800, train_loss: 42.693655, test_loss: 120.929321\n",
      "epoch: 80900, train_loss: 42.711300, test_loss: 120.848495\n",
      "epoch: 81000, train_loss: 44.378294, test_loss: 120.318665\n",
      "epoch: 81100, train_loss: 42.906305, test_loss: 121.015503\n",
      "epoch: 81200, train_loss: 41.942075, test_loss: 121.116302\n",
      "epoch: 81300, train_loss: 43.366098, test_loss: 120.384041\n",
      "epoch: 81400, train_loss: 41.628353, test_loss: 120.309982\n",
      "epoch: 81500, train_loss: 42.431395, test_loss: 120.549614\n",
      "epoch: 81600, train_loss: 43.726383, test_loss: 121.208038\n",
      "epoch: 81700, train_loss: 42.889748, test_loss: 121.309753\n",
      "epoch: 81800, train_loss: 42.355251, test_loss: 121.011353\n",
      "epoch: 81900, train_loss: 42.471931, test_loss: 121.328850\n",
      "epoch: 82000, train_loss: 42.046076, test_loss: 121.202011\n",
      "epoch: 82100, train_loss: 42.914688, test_loss: 121.399208\n",
      "epoch: 82200, train_loss: 41.604980, test_loss: 122.052116\n",
      "epoch: 82300, train_loss: 42.324936, test_loss: 120.863701\n",
      "epoch: 82400, train_loss: 43.245842, test_loss: 121.307152\n",
      "epoch: 82500, train_loss: 43.893175, test_loss: 121.615349\n",
      "epoch: 82600, train_loss: 43.118711, test_loss: 121.100578\n",
      "epoch: 82700, train_loss: 42.694944, test_loss: 120.554024\n",
      "epoch: 82800, train_loss: 44.713699, test_loss: 121.171158\n",
      "epoch: 82900, train_loss: 42.482311, test_loss: 121.262993\n",
      "epoch: 83000, train_loss: 43.824852, test_loss: 120.687759\n",
      "epoch: 83100, train_loss: 42.867529, test_loss: 120.923111\n",
      "epoch: 83200, train_loss: 41.562166, test_loss: 121.214050\n",
      "epoch: 83300, train_loss: 41.753786, test_loss: 121.276245\n",
      "epoch: 83400, train_loss: 42.426361, test_loss: 121.207993\n",
      "epoch: 83500, train_loss: 41.872297, test_loss: 121.377113\n",
      "epoch: 83600, train_loss: 42.179533, test_loss: 120.589424\n",
      "epoch: 83700, train_loss: 44.627763, test_loss: 120.913612\n",
      "epoch: 83800, train_loss: 42.558847, test_loss: 120.963676\n",
      "epoch: 83900, train_loss: 41.810106, test_loss: 121.690994\n",
      "epoch: 84000, train_loss: 40.773404, test_loss: 121.207115\n",
      "epoch: 84100, train_loss: 44.232046, test_loss: 121.878456\n",
      "epoch: 84200, train_loss: 42.977758, test_loss: 120.920494\n",
      "epoch: 84300, train_loss: 42.432211, test_loss: 121.141098\n",
      "epoch: 84400, train_loss: 41.988358, test_loss: 121.416153\n",
      "epoch: 84500, train_loss: 43.513042, test_loss: 121.406822\n",
      "epoch: 84600, train_loss: 43.173265, test_loss: 121.616005\n",
      "epoch: 84700, train_loss: 43.285419, test_loss: 121.800728\n",
      "epoch: 84800, train_loss: 43.266850, test_loss: 120.871178\n",
      "epoch: 84900, train_loss: 43.010544, test_loss: 121.516739\n",
      "epoch: 85000, train_loss: 43.906389, test_loss: 121.089119\n",
      "epoch: 85100, train_loss: 42.848028, test_loss: 121.121498\n",
      "epoch: 85200, train_loss: 42.299088, test_loss: 121.139870\n",
      "epoch: 85300, train_loss: 41.412555, test_loss: 120.967705\n",
      "epoch: 85400, train_loss: 42.032415, test_loss: 120.396980\n",
      "epoch: 85500, train_loss: 43.544363, test_loss: 121.326431\n",
      "epoch: 85600, train_loss: 41.371408, test_loss: 122.078232\n",
      "epoch: 85700, train_loss: 43.686481, test_loss: 121.329033\n",
      "epoch: 85800, train_loss: 42.926741, test_loss: 121.011833\n",
      "epoch: 85900, train_loss: 43.206484, test_loss: 121.236816\n",
      "epoch: 86000, train_loss: 42.469740, test_loss: 121.123291\n",
      "epoch: 86100, train_loss: 42.726856, test_loss: 121.137665\n",
      "epoch: 86200, train_loss: 41.968296, test_loss: 121.460548\n",
      "epoch: 86300, train_loss: 42.532890, test_loss: 121.589912\n",
      "epoch: 86400, train_loss: 43.425402, test_loss: 120.668037\n",
      "epoch: 86500, train_loss: 40.998104, test_loss: 121.119049\n",
      "epoch: 86600, train_loss: 44.118218, test_loss: 122.046608\n",
      "epoch: 86700, train_loss: 42.728630, test_loss: 121.121864\n",
      "epoch: 86800, train_loss: 42.014706, test_loss: 120.895607\n",
      "epoch: 86900, train_loss: 43.657764, test_loss: 121.464325\n",
      "epoch: 87000, train_loss: 43.688555, test_loss: 121.433899\n",
      "epoch: 87100, train_loss: 42.990614, test_loss: 121.727768\n",
      "epoch: 87200, train_loss: 43.411469, test_loss: 121.798370\n",
      "epoch: 87300, train_loss: 43.141251, test_loss: 120.932976\n",
      "epoch: 87400, train_loss: 42.387449, test_loss: 121.053001\n",
      "epoch: 87500, train_loss: 43.971878, test_loss: 121.382423\n",
      "epoch: 87600, train_loss: 42.883095, test_loss: 121.783585\n",
      "epoch: 87700, train_loss: 42.714737, test_loss: 121.422379\n",
      "epoch: 87800, train_loss: 43.513973, test_loss: 122.322350\n",
      "epoch: 87900, train_loss: 43.149324, test_loss: 121.730202\n",
      "epoch: 88000, train_loss: 43.566282, test_loss: 120.980637\n",
      "epoch: 88100, train_loss: 42.360966, test_loss: 122.357849\n",
      "epoch: 88200, train_loss: 42.608746, test_loss: 121.431328\n",
      "epoch: 88300, train_loss: 44.371307, test_loss: 120.880493\n",
      "epoch: 88400, train_loss: 42.930792, test_loss: 120.884796\n",
      "epoch: 88500, train_loss: 43.407087, test_loss: 121.845863\n",
      "epoch: 88600, train_loss: 42.725836, test_loss: 121.685883\n",
      "epoch: 88700, train_loss: 43.399921, test_loss: 121.317284\n",
      "epoch: 88800, train_loss: 43.269852, test_loss: 121.395851\n",
      "epoch: 88900, train_loss: 43.361425, test_loss: 121.596222\n",
      "epoch: 89000, train_loss: 42.673075, test_loss: 120.678436\n",
      "epoch: 89100, train_loss: 43.320551, test_loss: 120.914398\n",
      "epoch: 89200, train_loss: 42.540325, test_loss: 122.525040\n",
      "epoch: 89300, train_loss: 44.029671, test_loss: 121.083801\n",
      "epoch: 89400, train_loss: 41.880955, test_loss: 122.295265\n",
      "epoch: 89500, train_loss: 42.650978, test_loss: 121.882713\n",
      "epoch: 89600, train_loss: 44.385521, test_loss: 121.963638\n",
      "epoch: 89700, train_loss: 43.685802, test_loss: 121.450859\n",
      "epoch: 89800, train_loss: 43.303476, test_loss: 121.329437\n",
      "epoch: 89900, train_loss: 42.517788, test_loss: 121.071198\n",
      "epoch: 90000, train_loss: 43.234896, test_loss: 120.223305\n",
      "epoch: 90100, train_loss: 42.356216, test_loss: 120.982506\n",
      "epoch: 90200, train_loss: 42.658022, test_loss: 121.546494\n",
      "epoch: 90300, train_loss: 41.810331, test_loss: 121.863586\n",
      "epoch: 90400, train_loss: 43.820070, test_loss: 122.730858\n",
      "epoch: 90500, train_loss: 43.693558, test_loss: 121.372505\n",
      "epoch: 90600, train_loss: 42.826254, test_loss: 121.718697\n",
      "epoch: 90700, train_loss: 42.718615, test_loss: 122.340233\n",
      "epoch: 90800, train_loss: 43.711784, test_loss: 121.285370\n",
      "epoch: 90900, train_loss: 43.150187, test_loss: 123.017563\n",
      "epoch: 91000, train_loss: 42.367638, test_loss: 121.293724\n",
      "epoch: 91100, train_loss: 41.402895, test_loss: 121.553505\n",
      "epoch: 91200, train_loss: 42.042807, test_loss: 122.007118\n",
      "epoch: 91300, train_loss: 43.024055, test_loss: 123.009003\n",
      "epoch: 91400, train_loss: 42.655176, test_loss: 121.133385\n",
      "epoch: 91500, train_loss: 43.936317, test_loss: 121.257896\n",
      "epoch: 91600, train_loss: 42.321577, test_loss: 122.087738\n",
      "epoch: 91700, train_loss: 43.203320, test_loss: 122.092102\n",
      "epoch: 91800, train_loss: 41.821058, test_loss: 121.500053\n",
      "epoch: 91900, train_loss: 42.564423, test_loss: 122.148994\n",
      "epoch: 92000, train_loss: 42.302149, test_loss: 121.493523\n",
      "epoch: 92100, train_loss: 42.901499, test_loss: 121.912361\n",
      "epoch: 92200, train_loss: 42.772697, test_loss: 121.727242\n",
      "epoch: 92300, train_loss: 42.214792, test_loss: 121.446884\n",
      "epoch: 92400, train_loss: 43.536640, test_loss: 122.213608\n",
      "epoch: 92500, train_loss: 42.108118, test_loss: 122.448967\n",
      "epoch: 92600, train_loss: 43.205278, test_loss: 121.311432\n",
      "epoch: 92700, train_loss: 43.979525, test_loss: 121.626259\n",
      "epoch: 92800, train_loss: 43.513479, test_loss: 121.603195\n",
      "epoch: 92900, train_loss: 43.020477, test_loss: 122.159790\n",
      "epoch: 93000, train_loss: 42.783772, test_loss: 121.932899\n",
      "epoch: 93100, train_loss: 43.452856, test_loss: 122.449150\n",
      "epoch: 93200, train_loss: 42.925621, test_loss: 121.817215\n",
      "epoch: 93300, train_loss: 41.929852, test_loss: 121.625404\n",
      "epoch: 93400, train_loss: 43.434250, test_loss: 121.236748\n",
      "epoch: 93500, train_loss: 41.464012, test_loss: 121.629639\n",
      "epoch: 93600, train_loss: 43.087240, test_loss: 122.155212\n",
      "epoch: 93700, train_loss: 44.108978, test_loss: 122.054832\n",
      "epoch: 93800, train_loss: 42.780043, test_loss: 121.373871\n",
      "epoch: 93900, train_loss: 42.837891, test_loss: 121.940674\n",
      "epoch: 94000, train_loss: 41.871402, test_loss: 121.927010\n",
      "epoch: 94100, train_loss: 42.668928, test_loss: 121.407043\n",
      "epoch: 94200, train_loss: 41.575538, test_loss: 122.003273\n",
      "epoch: 94300, train_loss: 42.221127, test_loss: 122.102203\n",
      "epoch: 94400, train_loss: 42.194666, test_loss: 122.134476\n",
      "epoch: 94500, train_loss: 42.766741, test_loss: 121.592911\n",
      "epoch: 94600, train_loss: 43.218046, test_loss: 121.729424\n",
      "epoch: 94700, train_loss: 42.375740, test_loss: 121.953735\n",
      "epoch: 94800, train_loss: 42.555696, test_loss: 121.970772\n",
      "epoch: 94900, train_loss: 41.886982, test_loss: 122.104393\n",
      "epoch: 95000, train_loss: 41.882454, test_loss: 121.831604\n",
      "epoch: 95100, train_loss: 42.105076, test_loss: 121.493744\n",
      "epoch: 95200, train_loss: 42.636219, test_loss: 120.751541\n",
      "epoch: 95300, train_loss: 44.335514, test_loss: 122.003357\n",
      "epoch: 95400, train_loss: 42.942049, test_loss: 121.942680\n",
      "epoch: 95500, train_loss: 44.131507, test_loss: 122.232903\n",
      "epoch: 95600, train_loss: 42.740568, test_loss: 121.786125\n",
      "epoch: 95700, train_loss: 42.807264, test_loss: 121.459488\n",
      "epoch: 95800, train_loss: 43.253910, test_loss: 121.659096\n",
      "epoch: 95900, train_loss: 42.861366, test_loss: 121.027336\n",
      "epoch: 96000, train_loss: 44.101743, test_loss: 122.972404\n",
      "epoch: 96100, train_loss: 41.635326, test_loss: 122.246361\n",
      "epoch: 96200, train_loss: 43.415751, test_loss: 121.955727\n",
      "epoch: 96300, train_loss: 42.926580, test_loss: 121.341446\n",
      "epoch: 96400, train_loss: 41.059434, test_loss: 121.172531\n",
      "epoch: 96500, train_loss: 42.359253, test_loss: 121.681458\n",
      "epoch: 96600, train_loss: 41.544542, test_loss: 122.259598\n",
      "epoch: 96700, train_loss: 43.626345, test_loss: 122.697235\n",
      "epoch: 96800, train_loss: 42.541853, test_loss: 122.042938\n",
      "epoch: 96900, train_loss: 42.964083, test_loss: 122.798088\n",
      "epoch: 97000, train_loss: 42.489937, test_loss: 121.907700\n",
      "epoch: 97100, train_loss: 41.126978, test_loss: 122.082458\n",
      "epoch: 97200, train_loss: 43.343264, test_loss: 121.081291\n",
      "epoch: 97300, train_loss: 42.518856, test_loss: 121.891876\n",
      "epoch: 97400, train_loss: 42.672447, test_loss: 121.679871\n",
      "epoch: 97500, train_loss: 43.277208, test_loss: 122.046120\n",
      "epoch: 97600, train_loss: 42.974758, test_loss: 122.189705\n",
      "epoch: 97700, train_loss: 43.818805, test_loss: 122.669243\n",
      "epoch: 97800, train_loss: 41.752060, test_loss: 121.723312\n",
      "epoch: 97900, train_loss: 42.709089, test_loss: 122.497101\n",
      "epoch: 98000, train_loss: 41.685494, test_loss: 122.337433\n",
      "epoch: 98100, train_loss: 41.795004, test_loss: 122.126534\n",
      "epoch: 98200, train_loss: 42.427217, test_loss: 121.586655\n",
      "epoch: 98300, train_loss: 42.112730, test_loss: 122.787880\n",
      "epoch: 98400, train_loss: 43.845375, test_loss: 122.998672\n",
      "epoch: 98500, train_loss: 41.750517, test_loss: 121.921570\n",
      "epoch: 98600, train_loss: 41.752549, test_loss: 121.705994\n",
      "epoch: 98700, train_loss: 41.137807, test_loss: 121.892372\n",
      "epoch: 98800, train_loss: 41.775885, test_loss: 121.157715\n",
      "epoch: 98900, train_loss: 42.905830, test_loss: 121.890137\n",
      "epoch: 99000, train_loss: 44.220322, test_loss: 121.535187\n",
      "epoch: 99100, train_loss: 42.972406, test_loss: 121.891045\n",
      "epoch: 99200, train_loss: 41.951984, test_loss: 121.811676\n",
      "epoch: 99300, train_loss: 41.234015, test_loss: 122.089539\n",
      "epoch: 99400, train_loss: 43.368420, test_loss: 121.831879\n",
      "epoch: 99500, train_loss: 42.407244, test_loss: 122.293800\n",
      "epoch: 99600, train_loss: 44.359629, test_loss: 122.302834\n",
      "epoch: 99700, train_loss: 43.328667, test_loss: 121.611526\n",
      "epoch: 99800, train_loss: 43.662073, test_loss: 121.103531\n",
      "epoch: 99900, train_loss: 42.982258, test_loss: 122.356049\n"
     ]
    }
   ],
   "source": [
    "min_test_loss = np.inf\n",
    "\n",
    "for epoch in range(100000):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (x, y) in enumerate(dataloader_train):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        for i, (x, y) in enumerate(dataloader_test):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "        save_model = False\n",
    "        if test_loss < min_test_loss:\n",
    "            min_test_loss = test_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            save_model = True\n",
    "\n",
    "        if save_model:\n",
    "            print('epoch: {}, train_loss: {:.6f}, test_loss: {:.6f} (Saved)'.format(epoch, train_loss, test_loss))\n",
    "        else:\n",
    "            print('epoch: {}, train_loss: {:.6f}, test_loss: {:.6f}'.format(epoch, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX path: /home/icar/icar-ng-data/model/pixel2cm_model.onnx\n",
      "Saving ONNX model: /home/icar/icar-ng-data/model/pixel2cm_model.onnx\n",
      "Exported graph: graph(%onnx::Sub_0 : Float(1, 2, strides=[2, 1], requires_grad=0, device=cuda:0),\n",
      "      %fc1.weight : Float(4, 2, strides=[2, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc1.bias : Float(4, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc2.weight : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc2.bias : Float(20, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc3.weight : Float(80, 20, strides=[20, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc3.bias : Float(80, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc4.weight : Float(20, 80, strides=[80, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc4.bias : Float(20, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc5.weight : Float(4, 20, strides=[20, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc5.bias : Float(4, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc6.weight : Float(2, 4, strides=[4, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc6.bias : Float(2, strides=[1], requires_grad=1, device=cuda:0)):\n",
      "  %/Constant_output_0 : Float(2, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=  30  204 [ CUDAFloatType{2} ], onnx_name=\"/Constant\"](), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_40533/1725647797.py:16:0\n",
      "  %/Sub_output_0 : Float(1, 2, strides=[2, 1], requires_grad=0, device=cuda:0) = onnx::Sub[onnx_name=\"/Sub\"](%onnx::Sub_0, %/Constant_output_0), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_40533/1725647797.py:16:0\n",
      "  %/Constant_1_output_0 : Float(2, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value= 1242   488 [ CUDAFloatType{2} ], onnx_name=\"/Constant_1\"](), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_40533/1725647797.py:16:0\n",
      "  %/Div_output_0 : Float(1, 2, strides=[2, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name=\"/Div\"](%/Sub_output_0, %/Constant_1_output_0), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_40533/1725647797.py:16:0\n",
      "  %/fc1/Gemm_output_0 : Float(1, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc1/Gemm\"](%/Div_output_0, %fc1.weight, %fc1.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc1 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Tanh_output_0 : Float(1, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Tanh[onnx_name=\"/Tanh\"](%/fc1/Gemm_output_0), scope: __main__.MultiLayerPerceptron:: # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:1971:0\n",
      "  %/fc2/Gemm_output_0 : Float(1, 20, strides=[20, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc2/Gemm\"](%/Tanh_output_0, %fc2.weight, %fc2.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc2 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Tanh_1_output_0 : Float(1, 20, strides=[20, 1], requires_grad=1, device=cuda:0) = onnx::Tanh[onnx_name=\"/Tanh_1\"](%/fc2/Gemm_output_0), scope: __main__.MultiLayerPerceptron:: # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:1971:0\n",
      "  %/fc3/Gemm_output_0 : Float(1, 80, strides=[80, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc3/Gemm\"](%/Tanh_1_output_0, %fc3.weight, %fc3.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc3 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Relu_output_0 : Float(1, 80, strides=[80, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/Relu\"](%/fc3/Gemm_output_0), scope: __main__.MultiLayerPerceptron:: # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/fc4/Gemm_output_0 : Float(1, 20, strides=[20, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc4/Gemm\"](%/Relu_output_0, %fc4.weight, %fc4.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc4 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Relu_1_output_0 : Float(1, 20, strides=[20, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/Relu_1\"](%/fc4/Gemm_output_0), scope: __main__.MultiLayerPerceptron:: # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/fc5/Gemm_output_0 : Float(1, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc5/Gemm\"](%/Relu_1_output_0, %fc5.weight, %fc5.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc5 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/fc6/Gemm_output_0 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc6/Gemm\"](%/fc5/Gemm_output_0, %fc6.weight, %fc6.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc6 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Constant_2_output_0 : Float(2, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value= 1200.0000  1697.0563 [ CUDAFloatType{2} ], onnx_name=\"/Constant_2\"](), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_40533/1725647797.py:23:0\n",
      "  %/Mul_output_0 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cuda:0) = onnx::Mul[onnx_name=\"/Mul\"](%/fc6/Gemm_output_0, %/Constant_2_output_0), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_40533/1725647797.py:23:0\n",
      "  %/Constant_3_output_0 : Float(2, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value= 0.0000 -848.5281 [ CUDAFloatType{2} ], onnx_name=\"/Constant_3\"](), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_40533/1725647797.py:23:0\n",
      "  %30 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cuda:0) = onnx::Add[onnx_name=\"/Add\"](%/Mul_output_0, %/Constant_3_output_0), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_40533/1725647797.py:23:0\n",
      "  return (%30)\n",
      "\n",
      "Saved ONNX model: /home/icar/icar-ng-data/model/pixel2cm_model.onnx\n"
     ]
    }
   ],
   "source": [
    "onnx_path = os.path.join(model_directory, 'pixel2cm_model.onnx')\n",
    "print('ONNX path: {}'.format(onnx_path))\n",
    "\n",
    "try:\n",
    "    print('Saving ONNX model: {}'.format(onnx_path))\n",
    "    torch.onnx.export(model, torch.randn(1, 2).to(device), onnx_path, verbose=True)\n",
    "    print('Saved ONNX model: {}'.format(onnx_path))\n",
    "except BaseException as e:\n",
    "    print('Failed to save ONNX model: {}'.format(onnx_path))\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "tensor([[ 542.,  228.],\n",
      "        [ 938.,  524.],\n",
      "        [ 984.,  474.],\n",
      "        [ 150.,  300.],\n",
      "        [ 450.,  232.],\n",
      "        [ 746.,  352.],\n",
      "        [ 716.,  442.],\n",
      "        [1058.,  344.],\n",
      "        [ 642.,  534.],\n",
      "        [ 552.,  328.],\n",
      "        [ 524.,  268.],\n",
      "        [ 354.,  236.],\n",
      "        [ 332.,  358.],\n",
      "        [ 926.,  230.],\n",
      "        [1014.,  382.],\n",
      "        [ 934.,  260.],\n",
      "        [ 832.,  226.],\n",
      "        [ 300.,  486.],\n",
      "        [ 852.,  286.],\n",
      "        [ 432.,  294.],\n",
      "        [ 264.,  452.],\n",
      "        [1000.,  324.],\n",
      "        [ 362.,  296.],\n",
      "        [1164.,  342.],\n",
      "        [ 642.,  264.],\n",
      "        [ 100.,  256.],\n",
      "        [ 246.,  220.],\n",
      "        [ 756.,  262.],\n",
      "        [  46.,  452.]], device='cuda:0')\n",
      "y\n",
      "tensor([[ 789.1151,  131.5192],\n",
      "        [  50.0000,  -75.0000],\n",
      "        [  75.0000, -100.0000],\n",
      "        [ 353.5534,  353.5534],\n",
      "        [ 758.9467,  252.9822],\n",
      "        [ 200.0000,  -50.0000],\n",
      "        [ 100.0000,  -25.0000],\n",
      "        [ 200.0000, -200.0000],\n",
      "        [  50.0000,    0.0000],\n",
      "        [ 250.0000,   50.0000],\n",
      "        [ 450.0000,  100.0000],\n",
      "        [ 715.5417,  357.7709],\n",
      "        [ 200.0000,  150.0000],\n",
      "        [ 715.5417, -357.7709],\n",
      "        [ 150.0000, -150.0000],\n",
      "        [ 450.0000, -250.0000],\n",
      "        [ 758.9467, -252.9822],\n",
      "        [  75.0000,  100.0000],\n",
      "        [ 350.0000, -150.0000],\n",
      "        [ 350.0000,  150.0000],\n",
      "        [ 100.0000,  125.0000],\n",
      "        [ 250.0000, -200.0000],\n",
      "        [ 350.0000,  200.0000],\n",
      "        [ 200.0000, -250.0000],\n",
      "        [ 450.0000,    0.0000],\n",
      "        [ 565.6854,  565.6854],\n",
      "        [ 998.4603,  665.6403],\n",
      "        [ 450.0000, -100.0000],\n",
      "        [ 100.0000,  200.0000]], device='cuda:0')\n",
      "y_pred\n",
      "tensor([[ 7.7422e+02,  1.3473e+02],\n",
      "        [ 5.0258e+01, -7.5123e+01],\n",
      "        [ 7.6141e+01, -9.9745e+01],\n",
      "        [ 3.4711e+02,  3.6358e+02],\n",
      "        [ 7.4920e+02,  2.6878e+02],\n",
      "        [ 1.9904e+02, -4.7088e+01],\n",
      "        [ 1.0143e+02, -2.3666e+01],\n",
      "        [ 1.9875e+02, -1.9910e+02],\n",
      "        [ 4.8506e+01,  7.6392e-01],\n",
      "        [ 2.4877e+02,  4.4052e+01],\n",
      "        [ 4.5852e+02,  9.9365e+01],\n",
      "        [ 7.3279e+02,  3.8128e+02],\n",
      "        [ 2.0418e+02,  1.5632e+02],\n",
      "        [ 6.9974e+02, -3.5189e+02],\n",
      "        [ 1.5142e+02, -1.4443e+02],\n",
      "        [ 4.5536e+02, -2.5262e+02],\n",
      "        [ 7.5078e+02, -2.5869e+02],\n",
      "        [ 7.6098e+01,  1.0033e+02],\n",
      "        [ 3.4737e+02, -1.4815e+02],\n",
      "        [ 3.5109e+02,  1.4189e+02],\n",
      "        [ 1.0054e+02,  1.2800e+02],\n",
      "        [ 2.4379e+02, -1.9386e+02],\n",
      "        [ 3.4861e+02,  1.8889e+02],\n",
      "        [ 2.0360e+02, -2.4636e+02],\n",
      "        [ 4.6406e+02, -1.4689e+00],\n",
      "        [ 6.1626e+02,  5.9626e+02],\n",
      "        [ 9.7297e+02,  6.5639e+02],\n",
      "        [ 4.6187e+02, -1.0139e+02],\n",
      "        [ 1.0254e+02,  2.0324e+02]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "y - y_pred\n",
      "tensor([[ 14.8983,  -3.2110],\n",
      "        [ -0.2576,   0.1230],\n",
      "        [ -1.1409,  -0.2546],\n",
      "        [  6.4397, -10.0265],\n",
      "        [  9.7425, -15.7970],\n",
      "        [  0.9556,  -2.9119],\n",
      "        [ -1.4326,  -1.3342],\n",
      "        [  1.2504,  -0.9008],\n",
      "        [  1.4943,  -0.7639],\n",
      "        [  1.2323,   5.9475],\n",
      "        [ -8.5201,   0.6345],\n",
      "        [-17.2505, -23.5060],\n",
      "        [ -4.1774,  -6.3226],\n",
      "        [ 15.8043,  -5.8824],\n",
      "        [ -1.4209,  -5.5695],\n",
      "        [ -5.3605,   2.6208],\n",
      "        [  8.1673,   5.7071],\n",
      "        [ -1.0978,  -0.3341],\n",
      "        [  2.6297,  -1.8519],\n",
      "        [ -1.0857,   8.1054],\n",
      "        [ -0.5428,  -2.9963],\n",
      "        [  6.2126,  -6.1401],\n",
      "        [  1.3888,  11.1092],\n",
      "        [ -3.5965,  -3.6422],\n",
      "        [-14.0619,   1.4689],\n",
      "        [-50.5763, -30.5701],\n",
      "        [ 25.4887,   9.2509],\n",
      "        [-11.8681,   1.3892],\n",
      "        [ -2.5409,  -3.2393]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "rmse: 11.072910\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, (x, y) in enumerate(dataloader_test):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_pred = model(x)\n",
    "    rmse = torch.sqrt(torch.mean(torch.square(y - y_pred)))\n",
    "    \n",
    "    print('x\\n{}'.format(x))\n",
    "    print('y\\n{}'.format(y))\n",
    "    print('y_pred\\n{}'.format(y_pred))\n",
    "    print('y - y_pred\\n{}'.format(y - y_pred))\n",
    "    print('rmse: {:.6f}'.format(rmse))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pixel_x  pixel_y         cm_x        cm_y\n",
      "62       502      692     0.000000   25.000000\n",
      "87       276      398   150.000000  150.000000\n",
      "90       538      356   200.000000   50.000000\n",
      "53       996      280   350.000000 -250.000000\n",
      "48       642      290   350.000000    0.000000\n",
      "6        874      594    25.000000  -50.000000\n",
      "26      1184      432   100.000000 -175.000000\n",
      "132      730      260   493.196962  -82.199494\n",
      "82       194      452   100.000000  150.000000\n",
      "63       364      688     0.000000   50.000000\n",
      "69       444      532    50.000000   50.000000\n",
      "102      570      290   350.000000   50.000000\n",
      "52       924      284   350.000000 -200.000000\n",
      "49       710      288   350.000000  -50.000000\n",
      "9        740      530    50.000000  -25.000000\n",
      "111      410      270   450.000000  200.000000\n",
      "140      940      206  1073.312629 -536.656315\n",
      "99       286      332   250.000000  200.000000\n",
      "86       396      394   150.000000  100.000000\n",
      "95        30      362   200.000000  300.000000\n",
      "74       472      484    75.000000   50.000000\n",
      "47      1188      314   250.000000 -300.000000\n",
      "64       226      690     0.000000   75.000000\n",
      "113      298      272   450.000000  300.000000\n",
      "5        640      598    25.000000    0.000000\n",
      "37       954      348   200.000000 -150.000000\n",
      "141      986      272   416.025147 -277.350098\n",
      "59       872      260   450.000000 -200.000000\n",
      "144     1132      286   353.553391 -353.553391\n",
      "108      582      268   450.000000   50.000000\n",
      "88       158      398   150.000000  200.000000\n",
      "103      500      292   350.000000  100.000000\n",
      "79       416      446   100.000000   75.000000\n",
      "110      466      270   450.000000  150.000000\n",
      "12      1040      522    50.000000 -100.000000\n",
      "97       462      328   250.000000  100.000000\n",
      "21       794      440   100.000000  -50.000000\n",
      "42       730      324   250.000000  -50.000000\n",
      "1        780      690     0.000000  -25.000000\n",
      "66       412      598    25.000000   50.000000\n",
      "143     1032      208   998.460353 -665.640235\n",
      "27      1258      430   100.000000 -200.000000\n",
      "4       1212      678     0.000000 -100.000000\n",
      "19       642      444   100.000000    0.000000\n",
      "115      640      224   800.000000    0.000000\n",
      "13      1144      520    50.000000 -125.000000\n",
      "119      536      206  1183.672709  197.278785\n",
      "28       642      390   150.000000    0.000000\n",
      "14      1244      520    50.000000 -150.000000\n",
      "83       122      452   100.000000  175.000000\n",
      "68       542      532    50.000000   25.000000\n",
      "72       158      532    50.000000  125.000000\n",
      "33      1268      376   150.000000 -250.000000\n",
      "0        642      690     0.000000    0.000000\n",
      "134      738      204  1183.672709 -197.278785\n",
      "40      1272      342   200.000000 -300.000000\n",
      "145     1180      244   565.685425 -565.685425\n",
      "101      110      336   250.000000  300.000000\n",
      "112      354      272   450.000000  250.000000\n",
      "10       838      528    50.000000  -50.000000\n",
      "30       888      386   150.000000 -100.000000\n",
      "85       520      394   150.000000   50.000000\n",
      "73        60      534    50.000000  150.000000\n",
      "16       816      478    75.000000  -50.000000\n",
      "135      818      262   474.341649 -158.113883\n",
      "7       1110      584    25.000000 -100.000000\n",
      "77       562      446   100.000000   25.000000\n",
      "125      338      214  1073.312629  536.656315\n",
      "137      840      204  1138.419958 -379.473319\n",
      "117      552      264   493.196962   82.199494\n",
      "67       186      598    25.000000  100.000000\n",
      "36       852      348   200.000000 -100.000000\n",
      "146     1220      214   848.528137 -848.528137\n",
      "56       698      262   450.000000  -50.000000\n",
      "120      464      270   474.341649  158.113883\n",
      "91       434      358   200.000000  100.000000\n",
      "61       990      260   450.000000 -300.000000\n",
      "122      438      210  1138.419958  379.473319\n",
      "54      1064      278   350.000000 -300.000000\n",
      "93       234      362   200.000000  200.000000\n",
      "98       374      332   250.000000  150.000000\n",
      "100      204      336   250.000000  250.000000\n",
      "44       910      324   250.000000 -150.000000\n",
      "43       822      324   250.000000 -100.000000\n",
      "65        90      690     0.000000  100.000000\n",
      "80       340      448   100.000000  100.000000\n",
      "22       872      442   100.000000  -75.000000\n",
      "116      640      204  1200.000000    0.000000\n",
      "127      270      246   665.640235  443.760157\n",
      "46      1092      318   250.000000 -250.000000\n",
      "131       64      230   848.528137  848.528137\n",
      "76       138      488    75.000000  150.000000\n",
      "106      292      298   350.000000  250.000000\n",
      "126      298      284   416.025147  277.350098\n",
      "29       768      386   150.000000  -50.000000\n",
      "34       642      354   200.000000    0.000000\n",
      "50       782      286   350.000000 -100.000000\n",
      "24      1024      432   100.000000 -125.000000\n",
      "107      222      298   350.000000  300.000000\n",
      "3       1066      684     0.000000  -75.000000\n",
      "133      736      224   789.115139 -131.519190\n",
      "41       642      326   250.000000    0.000000\n",
      "2        922      688     0.000000  -50.000000\n",
      "23       948      438   100.000000 -100.000000\n",
      "123      378      274   447.213595  223.606798\n",
      "142     1014      232   665.640235 -443.760157\n",
      "58       816      260   450.000000 -150.000000\n",
      "114      638      258   500.000000    0.000000\n",
      "138      904      266   447.213595 -223.606798\n",
      "25      1098      434   100.000000 -150.000000\n",
      "32      1138      378   150.000000 -200.000000\n",
      "15       640      482    75.000000    0.000000\n",
      "71       252      532    50.000000  100.000000\n",
      "89        36      400   150.000000  250.000000\n",
      "18      1164      470    75.000000 -150.000000\n",
      "94       132      362   200.000000  250.000000\n",
      "78       488      446   100.000000   50.000000\n",
      "70       346      534    50.000000   75.000000\n"
     ]
    }
   ],
   "source": [
    "# Show all training data as table\n",
    "pd.set_option('display.max_rows', len(df_train))\n",
    "print(df_train)\n",
    "# Export training data as CSV file\n",
    "df_train.to_csv(os.path.join(model_directory, 'dataset_train_pixel2cm.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pixel_x  pixel_y        cm_x        cm_y\n",
      "8        642      534   50.000000    0.000000\n",
      "11       938      524   50.000000  -75.000000\n",
      "17       984      474   75.000000 -100.000000\n",
      "20       716      442  100.000000  -25.000000\n",
      "31      1014      382  150.000000 -150.000000\n",
      "35       746      352  200.000000  -50.000000\n",
      "38      1058      344  200.000000 -200.000000\n",
      "39      1164      342  200.000000 -250.000000\n",
      "45      1000      324  250.000000 -200.000000\n",
      "51       852      286  350.000000 -150.000000\n",
      "55       642      264  450.000000    0.000000\n",
      "57       756      262  450.000000 -100.000000\n",
      "60       934      260  450.000000 -250.000000\n",
      "75       300      486   75.000000  100.000000\n",
      "81       264      452  100.000000  125.000000\n",
      "84        46      452  100.000000  200.000000\n",
      "92       332      358  200.000000  150.000000\n",
      "96       552      328  250.000000   50.000000\n",
      "104      432      294  350.000000  150.000000\n",
      "105      362      296  350.000000  200.000000\n",
      "109      524      268  450.000000  100.000000\n",
      "118      542      228  789.115139  131.519190\n",
      "121      450      232  758.946638  252.982213\n",
      "124      354      236  715.541753  357.770876\n",
      "128      246      220  998.460353  665.640235\n",
      "129      150      300  353.553391  353.553391\n",
      "130      100      256  565.685425  565.685425\n",
      "136      832      226  758.946638 -252.982213\n",
      "139      926      230  715.541753 -357.770876\n"
     ]
    }
   ],
   "source": [
    "# Show all test data as table\n",
    "pd.set_option('display.max_rows', len(df_test))\n",
    "print(df_test)\n",
    "# Export test data as CSV file\n",
    "df_test.to_csv(os.path.join(model_directory, 'dataset_test_pixel2cm.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
