{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was run on 06/11/2023 at 22:13:21.\n"
     ]
    }
   ],
   "source": [
    "print('This notebook was run on ' + time.strftime(\"%d/%m/%Y\") + ' at ' + time.strftime(\"%H:%M:%S\") + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /home/icar/icar-ng-data/dataset\n",
      "Dataset file: dataset.csv\n",
      "Dataset path: /home/icar/icar-ng-data/dataset/dataset.csv\n",
      "Model directory: /home/icar/icar-ng-data/model\n",
      "Model file: pixel2cm_model.pt\n",
      "Model path: /home/icar/icar-ng-data/model/pixel2cm_model.pt\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = os.path.join(os.getenv('HOME'), 'icar-ng-data', 'dataset')\n",
    "print('Dataset directory: {}'.format(dataset_directory))\n",
    "\n",
    "dataset_file = 'dataset.csv'\n",
    "print('Dataset file: {}'.format(dataset_file))\n",
    "\n",
    "dataset_path = os.path.join(dataset_directory, dataset_file)\n",
    "print('Dataset path: {}'.format(dataset_path))\n",
    "\n",
    "# ======================================\n",
    "\n",
    "model_directory = os.path.join(os.getenv('HOME'), 'icar-ng-data', 'model')\n",
    "print('Model directory: {}'.format(model_directory))\n",
    "\n",
    "model_file = 'pixel2cm_model.pt'\n",
    "print('Model file: {}'.format(model_file))\n",
    "\n",
    "model_path = os.path.join(model_directory, model_file)\n",
    "print('Model path: {}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether dataset file exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    print('Dataset file does not exist: {}'.format(dataset_path))\n",
    "    exit()\n",
    "\n",
    "# Check whether model directory exists\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "    print('Created model directory: {}'.format(model_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_x: tensor([ 36., 204.]), max_x: tensor([1272.,  692.])\n",
      "min_y: tensor([   0.0000, -848.5281]), max_y: tensor([1200.0000,  665.6403])\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(dataset_path)\n",
    "df_train = df_raw.sample(frac=0.8)\n",
    "df_test = df_raw.drop(df_train.index)\n",
    "\n",
    "min_x = np.min(df_train.iloc[:, 0:2].values, axis=0)\n",
    "min_x = torch.tensor(min_x, dtype=torch.float32)\n",
    "max_x = np.max(df_train.iloc[:, 0:2].values, axis=0)\n",
    "max_x = torch.tensor(max_x, dtype=torch.float32)\n",
    "min_y = np.min(df_train.iloc[:, 2:4].values, axis=0)\n",
    "min_y = torch.tensor(min_y, dtype=torch.float32)\n",
    "max_y = np.max(df_train.iloc[:, 2:4].values, axis=0)\n",
    "max_y = torch.tensor(max_y, dtype=torch.float32)\n",
    "\n",
    "print('min_x: {}, max_x: {}'.format(min_x, max_x))\n",
    "print('min_y: {}, max_y: {}'.format(min_y, max_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        x = self.dataframe.iloc[:, 0:2].values\n",
    "        y = self.dataframe.iloc[:, 2:4].values\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_train: 118\n",
      "dataset_test: 29\n"
     ]
    }
   ],
   "source": [
    "dataset_train = ForwardDataset(df_train)\n",
    "dataset_test = ForwardDataset(df_test)\n",
    "print('dataset_train: {}'.format(len(dataset_train)))\n",
    "print('dataset_test: {}'.format(len(dataset_test)))\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=64, shuffle=True, pin_memory=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=64, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size, output_size, min_x, max_x, min_y, max_y):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        self.min_x = min_x\n",
    "        self.max_x = max_x\n",
    "        self.min_y = min_y\n",
    "        self.max_y = max_y\n",
    "        self.fc1 = nn.Linear(input_size, 4)\n",
    "        self.fc2 = nn.Linear(4, 20)\n",
    "        self.fc3 = nn.Linear(20, 80)\n",
    "        self.fc4 = nn.Linear(80, 20)\n",
    "        self.fc5 = nn.Linear(20, 4)\n",
    "        self.fc6 = nn.Linear(4, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x - self.min_x) / (self.max_x - self.min_x)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        x = self.fc6(x)\n",
    "        x = x * (self.max_y - self.min_y) + self.min_y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: /home/icar/icar-ng-data/model/pixel2cm_model.pt\n",
      "Loaded model: /home/icar/icar-ng-data/model/pixel2cm_model.pt\n"
     ]
    }
   ],
   "source": [
    "model = MultiLayerPerceptron(2, 2, min_x.to(device), max_x.to(device), min_y.to(device), max_y.to(device)).to(device)\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    try:\n",
    "        print('Loading model: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print('Loaded model: {}'.format(model_path))\n",
    "    except BaseException as e:\n",
    "        print('Failed to load model: {}'.format(model_path))\n",
    "        print(e)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 8465.131348, test_loss: 3859.531738 (Saved)\n",
      "epoch: 100, train_loss: 316.217422, test_loss: 300.953003 (Saved)\n",
      "epoch: 200, train_loss: 195.563137, test_loss: 193.872849 (Saved)\n",
      "epoch: 300, train_loss: 158.398849, test_loss: 162.671524 (Saved)\n",
      "epoch: 400, train_loss: 140.784531, test_loss: 146.263641 (Saved)\n",
      "epoch: 500, train_loss: 140.092484, test_loss: 134.042313 (Saved)\n",
      "epoch: 600, train_loss: 125.729469, test_loss: 122.778793 (Saved)\n",
      "epoch: 700, train_loss: 118.658775, test_loss: 113.960686 (Saved)\n",
      "epoch: 800, train_loss: 110.672901, test_loss: 106.110535 (Saved)\n",
      "epoch: 900, train_loss: 108.582554, test_loss: 100.490738 (Saved)\n",
      "epoch: 1000, train_loss: 103.387959, test_loss: 96.260269 (Saved)\n",
      "epoch: 1100, train_loss: 98.661835, test_loss: 92.786003 (Saved)\n",
      "epoch: 1200, train_loss: 93.353802, test_loss: 90.111900 (Saved)\n",
      "epoch: 1300, train_loss: 92.210577, test_loss: 87.896317 (Saved)\n",
      "epoch: 1400, train_loss: 97.560425, test_loss: 85.498055 (Saved)\n",
      "epoch: 1500, train_loss: 89.936264, test_loss: 83.786835 (Saved)\n",
      "epoch: 1600, train_loss: 90.666466, test_loss: 82.742249 (Saved)\n",
      "epoch: 1700, train_loss: 87.626987, test_loss: 81.889229 (Saved)\n",
      "epoch: 1800, train_loss: 88.930923, test_loss: 80.245430 (Saved)\n",
      "epoch: 1900, train_loss: 86.824711, test_loss: 78.762428 (Saved)\n",
      "epoch: 2000, train_loss: 84.574177, test_loss: 77.100266 (Saved)\n",
      "epoch: 2100, train_loss: 80.285572, test_loss: 76.434998 (Saved)\n",
      "epoch: 2200, train_loss: 83.366186, test_loss: 75.203529 (Saved)\n",
      "epoch: 2300, train_loss: 80.334145, test_loss: 74.387581 (Saved)\n",
      "epoch: 2400, train_loss: 80.799068, test_loss: 73.928177 (Saved)\n",
      "epoch: 2500, train_loss: 75.442749, test_loss: 72.961800 (Saved)\n",
      "epoch: 2600, train_loss: 78.053114, test_loss: 71.527916 (Saved)\n",
      "epoch: 2700, train_loss: 74.944187, test_loss: 71.498428 (Saved)\n",
      "epoch: 2800, train_loss: 74.933411, test_loss: 70.641144 (Saved)\n",
      "epoch: 2900, train_loss: 71.380468, test_loss: 70.066124 (Saved)\n",
      "epoch: 3000, train_loss: 73.517738, test_loss: 69.399437 (Saved)\n",
      "epoch: 3100, train_loss: 74.572647, test_loss: 69.867889\n",
      "epoch: 3200, train_loss: 72.936424, test_loss: 69.320091 (Saved)\n",
      "epoch: 3300, train_loss: 67.515358, test_loss: 69.052773 (Saved)\n",
      "epoch: 3400, train_loss: 69.125721, test_loss: 68.843933 (Saved)\n",
      "epoch: 3500, train_loss: 69.576216, test_loss: 69.256020\n",
      "epoch: 3600, train_loss: 68.861645, test_loss: 68.811699 (Saved)\n",
      "epoch: 3700, train_loss: 66.672993, test_loss: 69.138542\n",
      "epoch: 3800, train_loss: 67.168388, test_loss: 69.374878\n",
      "epoch: 3900, train_loss: 65.328188, test_loss: 69.438774\n",
      "epoch: 4000, train_loss: 65.709801, test_loss: 69.818497\n",
      "epoch: 4100, train_loss: 63.582628, test_loss: 69.721375\n",
      "epoch: 4200, train_loss: 63.668690, test_loss: 70.030228\n",
      "epoch: 4300, train_loss: 61.740402, test_loss: 70.217308\n",
      "epoch: 4400, train_loss: 61.614555, test_loss: 70.253120\n",
      "epoch: 4500, train_loss: 61.799179, test_loss: 70.672211\n",
      "epoch: 4600, train_loss: 62.348654, test_loss: 71.121689\n",
      "epoch: 4700, train_loss: 61.398581, test_loss: 70.995354\n",
      "epoch: 4800, train_loss: 62.452330, test_loss: 70.612320\n",
      "epoch: 4900, train_loss: 60.765425, test_loss: 71.559540\n",
      "epoch: 5000, train_loss: 60.697502, test_loss: 71.360176\n",
      "epoch: 5100, train_loss: 60.518608, test_loss: 71.671478\n",
      "epoch: 5200, train_loss: 59.246849, test_loss: 71.412178\n",
      "epoch: 5300, train_loss: 61.021416, test_loss: 72.693275\n",
      "epoch: 5400, train_loss: 58.703329, test_loss: 72.649200\n",
      "epoch: 5500, train_loss: 58.608109, test_loss: 73.028358\n",
      "epoch: 5600, train_loss: 55.410542, test_loss: 72.996964\n",
      "epoch: 5700, train_loss: 57.170008, test_loss: 73.594742\n",
      "epoch: 5800, train_loss: 56.447409, test_loss: 73.776596\n",
      "epoch: 5900, train_loss: 58.055965, test_loss: 73.600533\n",
      "epoch: 6000, train_loss: 56.985491, test_loss: 74.085892\n",
      "epoch: 6100, train_loss: 57.873650, test_loss: 74.269211\n",
      "epoch: 6200, train_loss: 55.880299, test_loss: 74.692802\n",
      "epoch: 6300, train_loss: 56.111723, test_loss: 74.978027\n",
      "epoch: 6400, train_loss: 55.615807, test_loss: 75.332436\n",
      "epoch: 6500, train_loss: 55.285696, test_loss: 75.874413\n",
      "epoch: 6600, train_loss: 57.293081, test_loss: 76.271217\n",
      "epoch: 6700, train_loss: 55.199965, test_loss: 76.739021\n",
      "epoch: 6800, train_loss: 56.437164, test_loss: 76.766045\n",
      "epoch: 6900, train_loss: 55.163898, test_loss: 76.906921\n",
      "epoch: 7000, train_loss: 55.399632, test_loss: 77.336777\n",
      "epoch: 7100, train_loss: 56.061621, test_loss: 77.412796\n",
      "epoch: 7200, train_loss: 54.466297, test_loss: 78.054085\n",
      "epoch: 7300, train_loss: 55.703470, test_loss: 78.111717\n",
      "epoch: 7400, train_loss: 53.581705, test_loss: 78.663445\n",
      "epoch: 7500, train_loss: 55.377855, test_loss: 78.914711\n",
      "epoch: 7600, train_loss: 53.881502, test_loss: 79.013596\n",
      "epoch: 7700, train_loss: 55.251888, test_loss: 79.533829\n",
      "epoch: 7800, train_loss: 52.242327, test_loss: 80.076454\n",
      "epoch: 7900, train_loss: 54.979519, test_loss: 80.483292\n",
      "epoch: 8000, train_loss: 54.190603, test_loss: 80.560295\n",
      "epoch: 8100, train_loss: 53.823990, test_loss: 80.684052\n",
      "epoch: 8200, train_loss: 53.501543, test_loss: 81.437210\n",
      "epoch: 8300, train_loss: 53.522633, test_loss: 81.762749\n",
      "epoch: 8400, train_loss: 54.459740, test_loss: 81.370995\n",
      "epoch: 8500, train_loss: 53.757786, test_loss: 82.481018\n",
      "epoch: 8600, train_loss: 53.528309, test_loss: 82.439850\n",
      "epoch: 8700, train_loss: 52.375320, test_loss: 82.739899\n",
      "epoch: 8800, train_loss: 53.457354, test_loss: 82.662125\n",
      "epoch: 8900, train_loss: 52.243002, test_loss: 83.577034\n",
      "epoch: 9000, train_loss: 52.650318, test_loss: 83.223717\n",
      "epoch: 9100, train_loss: 52.695257, test_loss: 83.831642\n",
      "epoch: 9200, train_loss: 53.870609, test_loss: 83.915199\n",
      "epoch: 9300, train_loss: 54.506292, test_loss: 84.079559\n",
      "epoch: 9400, train_loss: 53.022797, test_loss: 84.416321\n",
      "epoch: 9500, train_loss: 52.795116, test_loss: 84.980698\n",
      "epoch: 9600, train_loss: 51.605566, test_loss: 85.186165\n",
      "epoch: 9700, train_loss: 52.228331, test_loss: 85.239937\n",
      "epoch: 9800, train_loss: 51.593266, test_loss: 84.767685\n",
      "epoch: 9900, train_loss: 51.910036, test_loss: 85.622208\n",
      "epoch: 10000, train_loss: 50.732056, test_loss: 85.520592\n",
      "epoch: 10100, train_loss: 52.347803, test_loss: 86.119156\n",
      "epoch: 10200, train_loss: 52.742754, test_loss: 86.008865\n",
      "epoch: 10300, train_loss: 50.000797, test_loss: 86.451492\n",
      "epoch: 10400, train_loss: 52.874517, test_loss: 86.559723\n",
      "epoch: 10500, train_loss: 50.947300, test_loss: 87.159378\n",
      "epoch: 10600, train_loss: 51.857605, test_loss: 87.452370\n",
      "epoch: 10700, train_loss: 53.174118, test_loss: 87.677483\n",
      "epoch: 10800, train_loss: 50.617563, test_loss: 87.493919\n",
      "epoch: 10900, train_loss: 51.542692, test_loss: 88.020416\n",
      "epoch: 11000, train_loss: 51.347202, test_loss: 87.771667\n",
      "epoch: 11100, train_loss: 53.306751, test_loss: 88.632454\n",
      "epoch: 11200, train_loss: 51.064466, test_loss: 88.576477\n",
      "epoch: 11300, train_loss: 52.480419, test_loss: 89.059570\n",
      "epoch: 11400, train_loss: 51.447384, test_loss: 88.811371\n",
      "epoch: 11500, train_loss: 50.528072, test_loss: 89.179268\n",
      "epoch: 11600, train_loss: 51.248388, test_loss: 89.355934\n",
      "epoch: 11700, train_loss: 51.821825, test_loss: 89.363518\n",
      "epoch: 11800, train_loss: 52.010393, test_loss: 89.969894\n",
      "epoch: 11900, train_loss: 53.468222, test_loss: 89.608170\n",
      "epoch: 12000, train_loss: 48.624899, test_loss: 90.034294\n",
      "epoch: 12100, train_loss: 50.145552, test_loss: 90.447670\n",
      "epoch: 12200, train_loss: 50.590466, test_loss: 90.190804\n",
      "epoch: 12300, train_loss: 50.443544, test_loss: 90.808777\n",
      "epoch: 12400, train_loss: 51.032333, test_loss: 90.992447\n",
      "epoch: 12500, train_loss: 51.619608, test_loss: 91.084473\n",
      "epoch: 12600, train_loss: 52.261097, test_loss: 91.419403\n",
      "epoch: 12700, train_loss: 51.178482, test_loss: 92.178299\n",
      "epoch: 12800, train_loss: 51.752214, test_loss: 91.540100\n",
      "epoch: 12900, train_loss: 50.378326, test_loss: 91.560280\n",
      "epoch: 13000, train_loss: 49.373804, test_loss: 92.801826\n",
      "epoch: 13100, train_loss: 50.239622, test_loss: 92.747612\n",
      "epoch: 13200, train_loss: 51.379234, test_loss: 93.061493\n",
      "epoch: 13300, train_loss: 50.066330, test_loss: 92.435883\n",
      "epoch: 13400, train_loss: 50.557009, test_loss: 93.237495\n",
      "epoch: 13500, train_loss: 50.699976, test_loss: 92.911674\n",
      "epoch: 13600, train_loss: 49.012995, test_loss: 93.404213\n",
      "epoch: 13700, train_loss: 49.089354, test_loss: 93.418510\n",
      "epoch: 13800, train_loss: 49.527515, test_loss: 94.164986\n",
      "epoch: 13900, train_loss: 51.837002, test_loss: 93.351997\n",
      "epoch: 14000, train_loss: 49.847197, test_loss: 93.778572\n",
      "epoch: 14100, train_loss: 49.934515, test_loss: 93.871475\n",
      "epoch: 14200, train_loss: 50.022770, test_loss: 94.131165\n",
      "epoch: 14300, train_loss: 49.866524, test_loss: 94.680038\n",
      "epoch: 14400, train_loss: 49.273882, test_loss: 94.737740\n",
      "epoch: 14500, train_loss: 50.209354, test_loss: 95.216042\n",
      "epoch: 14600, train_loss: 48.645342, test_loss: 95.027161\n",
      "epoch: 14700, train_loss: 51.505762, test_loss: 95.084961\n",
      "epoch: 14800, train_loss: 50.059471, test_loss: 95.802971\n",
      "epoch: 14900, train_loss: 50.749012, test_loss: 95.284615\n",
      "epoch: 15000, train_loss: 49.340498, test_loss: 95.611298\n",
      "epoch: 15100, train_loss: 48.147036, test_loss: 95.537766\n",
      "epoch: 15200, train_loss: 49.178392, test_loss: 95.951057\n",
      "epoch: 15300, train_loss: 49.561071, test_loss: 96.495537\n",
      "epoch: 15400, train_loss: 50.068624, test_loss: 96.730690\n",
      "epoch: 15500, train_loss: 48.710770, test_loss: 96.696144\n",
      "epoch: 15600, train_loss: 48.176981, test_loss: 97.209564\n",
      "epoch: 15700, train_loss: 50.111542, test_loss: 97.021248\n",
      "epoch: 15800, train_loss: 48.611301, test_loss: 97.269241\n",
      "epoch: 15900, train_loss: 49.452435, test_loss: 97.297821\n",
      "epoch: 16000, train_loss: 49.574358, test_loss: 97.830643\n",
      "epoch: 16100, train_loss: 48.600370, test_loss: 98.711525\n",
      "epoch: 16200, train_loss: 48.188797, test_loss: 98.474495\n",
      "epoch: 16300, train_loss: 49.095657, test_loss: 99.127945\n",
      "epoch: 16400, train_loss: 47.695429, test_loss: 99.680191\n",
      "epoch: 16500, train_loss: 48.041597, test_loss: 99.327057\n",
      "epoch: 16600, train_loss: 48.292961, test_loss: 99.740807\n",
      "epoch: 16700, train_loss: 48.204683, test_loss: 100.162109\n",
      "epoch: 16800, train_loss: 47.871157, test_loss: 99.723686\n",
      "epoch: 16900, train_loss: 48.452591, test_loss: 100.089676\n",
      "epoch: 17000, train_loss: 47.670197, test_loss: 101.035187\n",
      "epoch: 17100, train_loss: 48.262815, test_loss: 99.881210\n",
      "epoch: 17200, train_loss: 49.150955, test_loss: 101.081200\n",
      "epoch: 17300, train_loss: 48.909010, test_loss: 101.205147\n",
      "epoch: 17400, train_loss: 48.315939, test_loss: 101.167297\n",
      "epoch: 17500, train_loss: 47.949291, test_loss: 101.534927\n",
      "epoch: 17600, train_loss: 47.977753, test_loss: 101.485893\n",
      "epoch: 17700, train_loss: 47.520239, test_loss: 101.552788\n",
      "epoch: 17800, train_loss: 48.218685, test_loss: 101.885925\n",
      "epoch: 17900, train_loss: 47.012882, test_loss: 102.043892\n",
      "epoch: 18000, train_loss: 46.799419, test_loss: 101.860825\n",
      "epoch: 18100, train_loss: 47.975031, test_loss: 102.512444\n",
      "epoch: 18200, train_loss: 47.967817, test_loss: 102.695244\n",
      "epoch: 18300, train_loss: 46.855669, test_loss: 103.019836\n",
      "epoch: 18400, train_loss: 47.706394, test_loss: 102.713318\n",
      "epoch: 18500, train_loss: 46.812965, test_loss: 102.955276\n",
      "epoch: 18600, train_loss: 48.774929, test_loss: 103.127304\n",
      "epoch: 18700, train_loss: 47.441936, test_loss: 102.993462\n",
      "epoch: 18800, train_loss: 47.364559, test_loss: 103.465652\n",
      "epoch: 18900, train_loss: 47.858732, test_loss: 103.752518\n",
      "epoch: 19000, train_loss: 46.611576, test_loss: 103.568550\n",
      "epoch: 19100, train_loss: 47.391979, test_loss: 103.383652\n",
      "epoch: 19200, train_loss: 46.750484, test_loss: 103.971489\n",
      "epoch: 19300, train_loss: 48.105680, test_loss: 103.986763\n",
      "epoch: 19400, train_loss: 48.754763, test_loss: 104.050247\n",
      "epoch: 19500, train_loss: 46.450644, test_loss: 104.489296\n",
      "epoch: 19600, train_loss: 47.791573, test_loss: 104.172012\n",
      "epoch: 19700, train_loss: 45.801944, test_loss: 104.367371\n",
      "epoch: 19800, train_loss: 46.469797, test_loss: 104.335197\n",
      "epoch: 19900, train_loss: 47.089973, test_loss: 104.775581\n",
      "epoch: 20000, train_loss: 47.236530, test_loss: 104.284523\n",
      "epoch: 20100, train_loss: 46.102980, test_loss: 105.028099\n",
      "epoch: 20200, train_loss: 47.317644, test_loss: 104.589668\n",
      "epoch: 20300, train_loss: 45.295906, test_loss: 104.385368\n",
      "epoch: 20400, train_loss: 45.912323, test_loss: 104.472351\n",
      "epoch: 20500, train_loss: 47.770500, test_loss: 105.034271\n",
      "epoch: 20600, train_loss: 47.213139, test_loss: 104.851891\n",
      "epoch: 20700, train_loss: 45.999430, test_loss: 104.690460\n",
      "epoch: 20800, train_loss: 46.796022, test_loss: 104.789383\n",
      "epoch: 20900, train_loss: 46.297247, test_loss: 104.734138\n",
      "epoch: 21000, train_loss: 45.732063, test_loss: 104.603920\n",
      "epoch: 21100, train_loss: 45.303207, test_loss: 104.964432\n",
      "epoch: 21200, train_loss: 46.912169, test_loss: 105.372131\n",
      "epoch: 21300, train_loss: 44.947348, test_loss: 105.058380\n",
      "epoch: 21400, train_loss: 47.077435, test_loss: 104.891884\n",
      "epoch: 21500, train_loss: 47.598797, test_loss: 105.022072\n",
      "epoch: 21600, train_loss: 48.874628, test_loss: 104.673393\n",
      "epoch: 21700, train_loss: 46.381012, test_loss: 104.885849\n",
      "epoch: 21800, train_loss: 46.283657, test_loss: 105.050949\n",
      "epoch: 21900, train_loss: 46.812653, test_loss: 105.256866\n",
      "epoch: 22000, train_loss: 46.986347, test_loss: 105.435898\n",
      "epoch: 22100, train_loss: 44.913369, test_loss: 105.311371\n",
      "epoch: 22200, train_loss: 46.603371, test_loss: 105.007896\n",
      "epoch: 22300, train_loss: 47.427027, test_loss: 105.350342\n",
      "epoch: 22400, train_loss: 45.276778, test_loss: 105.034531\n",
      "epoch: 22500, train_loss: 46.950014, test_loss: 105.338531\n",
      "epoch: 22600, train_loss: 47.059624, test_loss: 105.209755\n",
      "epoch: 22700, train_loss: 47.339020, test_loss: 104.760223\n",
      "epoch: 22800, train_loss: 46.794538, test_loss: 104.523216\n",
      "epoch: 22900, train_loss: 46.287144, test_loss: 105.245354\n",
      "epoch: 23000, train_loss: 47.674017, test_loss: 105.235031\n",
      "epoch: 23100, train_loss: 46.157381, test_loss: 105.542999\n",
      "epoch: 23200, train_loss: 46.721281, test_loss: 105.429993\n",
      "epoch: 23300, train_loss: 45.823154, test_loss: 105.262077\n",
      "epoch: 23400, train_loss: 45.233561, test_loss: 105.314201\n",
      "epoch: 23500, train_loss: 46.121513, test_loss: 104.775475\n",
      "epoch: 23600, train_loss: 45.462765, test_loss: 104.821846\n",
      "epoch: 23700, train_loss: 45.308611, test_loss: 104.881889\n",
      "epoch: 23800, train_loss: 46.008106, test_loss: 105.374191\n",
      "epoch: 23900, train_loss: 45.138882, test_loss: 104.959587\n",
      "epoch: 24000, train_loss: 44.698633, test_loss: 105.069000\n",
      "epoch: 24100, train_loss: 44.867256, test_loss: 105.035309\n",
      "epoch: 24200, train_loss: 43.995891, test_loss: 104.526970\n",
      "epoch: 24300, train_loss: 45.623451, test_loss: 105.202721\n",
      "epoch: 24400, train_loss: 45.247528, test_loss: 104.836273\n",
      "epoch: 24500, train_loss: 45.664968, test_loss: 104.936111\n",
      "epoch: 24600, train_loss: 46.055176, test_loss: 105.156235\n",
      "epoch: 24700, train_loss: 46.347679, test_loss: 104.775650\n",
      "epoch: 24800, train_loss: 45.650429, test_loss: 105.151840\n",
      "epoch: 24900, train_loss: 44.514986, test_loss: 105.507141\n",
      "epoch: 25000, train_loss: 45.859352, test_loss: 105.442253\n",
      "epoch: 25100, train_loss: 46.180702, test_loss: 105.225029\n",
      "epoch: 25200, train_loss: 44.996412, test_loss: 105.388298\n",
      "epoch: 25300, train_loss: 45.912683, test_loss: 105.412971\n",
      "epoch: 25400, train_loss: 46.361794, test_loss: 104.553734\n",
      "epoch: 25500, train_loss: 47.026176, test_loss: 105.127274\n",
      "epoch: 25600, train_loss: 45.896492, test_loss: 105.038414\n",
      "epoch: 25700, train_loss: 44.810764, test_loss: 104.742340\n",
      "epoch: 25800, train_loss: 45.389795, test_loss: 104.893837\n",
      "epoch: 25900, train_loss: 45.189178, test_loss: 105.480637\n",
      "epoch: 26000, train_loss: 47.048509, test_loss: 104.745575\n",
      "epoch: 26100, train_loss: 46.604591, test_loss: 105.237831\n",
      "epoch: 26200, train_loss: 45.416798, test_loss: 104.567535\n",
      "epoch: 26300, train_loss: 45.161413, test_loss: 104.925545\n",
      "epoch: 26400, train_loss: 44.130717, test_loss: 104.884468\n",
      "epoch: 26500, train_loss: 44.323160, test_loss: 104.981934\n",
      "epoch: 26600, train_loss: 45.127430, test_loss: 105.011154\n",
      "epoch: 26700, train_loss: 46.706799, test_loss: 104.700699\n",
      "epoch: 26800, train_loss: 45.240019, test_loss: 105.002617\n",
      "epoch: 26900, train_loss: 45.129955, test_loss: 105.116890\n",
      "epoch: 27000, train_loss: 46.048332, test_loss: 105.290665\n",
      "epoch: 27100, train_loss: 43.951801, test_loss: 105.239311\n",
      "epoch: 27200, train_loss: 46.009232, test_loss: 105.135101\n",
      "epoch: 27300, train_loss: 45.078197, test_loss: 105.108223\n",
      "epoch: 27400, train_loss: 45.553513, test_loss: 105.172638\n",
      "epoch: 27500, train_loss: 44.620205, test_loss: 104.505356\n",
      "epoch: 27600, train_loss: 43.837924, test_loss: 104.634819\n",
      "epoch: 27700, train_loss: 45.389250, test_loss: 104.458611\n",
      "epoch: 27800, train_loss: 44.334639, test_loss: 105.163460\n",
      "epoch: 27900, train_loss: 45.292364, test_loss: 104.958481\n",
      "epoch: 28000, train_loss: 46.148520, test_loss: 104.763283\n",
      "epoch: 28100, train_loss: 44.651480, test_loss: 104.999168\n",
      "epoch: 28200, train_loss: 45.146650, test_loss: 104.932541\n",
      "epoch: 28300, train_loss: 45.789818, test_loss: 104.929771\n",
      "epoch: 28400, train_loss: 44.088661, test_loss: 104.873466\n",
      "epoch: 28500, train_loss: 44.922806, test_loss: 104.513260\n",
      "epoch: 28600, train_loss: 44.464754, test_loss: 104.641518\n",
      "epoch: 28700, train_loss: 45.080454, test_loss: 105.596130\n",
      "epoch: 28800, train_loss: 44.640141, test_loss: 105.458969\n",
      "epoch: 28900, train_loss: 44.268221, test_loss: 105.346931\n",
      "epoch: 29000, train_loss: 44.913677, test_loss: 105.967285\n",
      "epoch: 29100, train_loss: 45.806053, test_loss: 106.258293\n",
      "epoch: 29200, train_loss: 44.449343, test_loss: 105.813187\n",
      "epoch: 29300, train_loss: 44.934790, test_loss: 106.441025\n",
      "epoch: 29400, train_loss: 44.223270, test_loss: 106.028221\n",
      "epoch: 29500, train_loss: 45.143082, test_loss: 106.194672\n",
      "epoch: 29600, train_loss: 44.757555, test_loss: 106.199013\n",
      "epoch: 29700, train_loss: 45.000208, test_loss: 106.031685\n",
      "epoch: 29800, train_loss: 45.246452, test_loss: 106.674782\n",
      "epoch: 29900, train_loss: 45.283197, test_loss: 106.667717\n",
      "epoch: 30000, train_loss: 43.409479, test_loss: 106.477036\n",
      "epoch: 30100, train_loss: 45.709700, test_loss: 106.219185\n",
      "epoch: 30200, train_loss: 44.702394, test_loss: 106.933693\n",
      "epoch: 30300, train_loss: 45.388653, test_loss: 107.314240\n",
      "epoch: 30400, train_loss: 45.117279, test_loss: 106.544144\n",
      "epoch: 30500, train_loss: 44.554161, test_loss: 106.751114\n",
      "epoch: 30600, train_loss: 45.082705, test_loss: 107.015602\n",
      "epoch: 30700, train_loss: 46.803021, test_loss: 107.312836\n",
      "epoch: 30800, train_loss: 43.683304, test_loss: 106.821693\n",
      "epoch: 30900, train_loss: 44.191788, test_loss: 106.570984\n",
      "epoch: 31000, train_loss: 45.141607, test_loss: 106.602707\n",
      "epoch: 31100, train_loss: 44.877205, test_loss: 106.772934\n",
      "epoch: 31200, train_loss: 43.770064, test_loss: 107.232788\n",
      "epoch: 31300, train_loss: 44.342625, test_loss: 107.163803\n",
      "epoch: 31400, train_loss: 44.573195, test_loss: 107.297546\n",
      "epoch: 31500, train_loss: 44.420143, test_loss: 106.953049\n",
      "epoch: 31600, train_loss: 44.577915, test_loss: 106.934601\n",
      "epoch: 31700, train_loss: 43.711597, test_loss: 106.757080\n",
      "epoch: 31800, train_loss: 44.901695, test_loss: 106.703812\n",
      "epoch: 31900, train_loss: 44.467793, test_loss: 107.073830\n",
      "epoch: 32000, train_loss: 43.998123, test_loss: 107.104362\n",
      "epoch: 32100, train_loss: 46.434658, test_loss: 107.019547\n",
      "epoch: 32200, train_loss: 44.196571, test_loss: 107.160393\n",
      "epoch: 32300, train_loss: 44.694765, test_loss: 106.945129\n",
      "epoch: 32400, train_loss: 43.391630, test_loss: 107.050240\n",
      "epoch: 32500, train_loss: 45.412439, test_loss: 106.724663\n",
      "epoch: 32600, train_loss: 44.837690, test_loss: 106.863159\n",
      "epoch: 32700, train_loss: 43.162951, test_loss: 107.474190\n",
      "epoch: 32800, train_loss: 43.970535, test_loss: 107.306778\n",
      "epoch: 32900, train_loss: 43.317093, test_loss: 107.216934\n",
      "epoch: 33000, train_loss: 44.523100, test_loss: 107.011047\n",
      "epoch: 33100, train_loss: 45.140682, test_loss: 106.786064\n",
      "epoch: 33200, train_loss: 45.462511, test_loss: 108.074417\n",
      "epoch: 33300, train_loss: 44.761818, test_loss: 107.313492\n",
      "epoch: 33400, train_loss: 44.044462, test_loss: 107.161919\n",
      "epoch: 33500, train_loss: 44.589956, test_loss: 107.009346\n",
      "epoch: 33600, train_loss: 43.290956, test_loss: 106.810425\n",
      "epoch: 33700, train_loss: 43.000053, test_loss: 106.988716\n",
      "epoch: 33800, train_loss: 44.613247, test_loss: 106.938629\n",
      "epoch: 33900, train_loss: 42.650539, test_loss: 107.730064\n",
      "epoch: 34000, train_loss: 42.844447, test_loss: 107.125710\n",
      "epoch: 34100, train_loss: 43.128666, test_loss: 107.344421\n",
      "epoch: 34200, train_loss: 43.765993, test_loss: 107.459450\n",
      "epoch: 34300, train_loss: 45.512759, test_loss: 106.978462\n",
      "epoch: 34400, train_loss: 42.831455, test_loss: 107.329185\n",
      "epoch: 34500, train_loss: 43.796099, test_loss: 107.577652\n",
      "epoch: 34600, train_loss: 44.119122, test_loss: 107.572403\n",
      "epoch: 34700, train_loss: 42.899527, test_loss: 106.856514\n",
      "epoch: 34800, train_loss: 44.159428, test_loss: 107.645386\n",
      "epoch: 34900, train_loss: 43.352896, test_loss: 107.793755\n",
      "epoch: 35000, train_loss: 44.502590, test_loss: 107.728783\n",
      "epoch: 35100, train_loss: 45.483489, test_loss: 107.686150\n",
      "epoch: 35200, train_loss: 44.288782, test_loss: 107.745934\n",
      "epoch: 35300, train_loss: 44.581139, test_loss: 107.104103\n",
      "epoch: 35400, train_loss: 43.404955, test_loss: 107.539719\n",
      "epoch: 35500, train_loss: 44.308840, test_loss: 107.264679\n",
      "epoch: 35600, train_loss: 43.977432, test_loss: 107.415161\n",
      "epoch: 35700, train_loss: 44.143589, test_loss: 107.390862\n",
      "epoch: 35800, train_loss: 44.069517, test_loss: 107.460129\n",
      "epoch: 35900, train_loss: 43.885376, test_loss: 107.663429\n",
      "epoch: 36000, train_loss: 43.445848, test_loss: 107.720818\n",
      "epoch: 36100, train_loss: 44.328110, test_loss: 108.080116\n",
      "epoch: 36200, train_loss: 44.540812, test_loss: 107.895378\n",
      "epoch: 36300, train_loss: 43.661131, test_loss: 107.700882\n",
      "epoch: 36400, train_loss: 42.998228, test_loss: 107.516335\n",
      "epoch: 36500, train_loss: 42.499974, test_loss: 107.496216\n",
      "epoch: 36600, train_loss: 44.353609, test_loss: 107.549217\n",
      "epoch: 36700, train_loss: 43.615677, test_loss: 107.354225\n",
      "epoch: 36800, train_loss: 43.091784, test_loss: 108.273636\n",
      "epoch: 36900, train_loss: 45.388278, test_loss: 108.046257\n",
      "epoch: 37000, train_loss: 42.280309, test_loss: 107.649483\n",
      "epoch: 37100, train_loss: 43.385138, test_loss: 107.956650\n",
      "epoch: 37200, train_loss: 43.999609, test_loss: 107.850273\n",
      "epoch: 37300, train_loss: 42.259165, test_loss: 107.761139\n",
      "epoch: 37400, train_loss: 43.253790, test_loss: 108.250137\n",
      "epoch: 37500, train_loss: 42.838345, test_loss: 107.696388\n",
      "epoch: 37600, train_loss: 43.737768, test_loss: 107.732498\n",
      "epoch: 37700, train_loss: 44.612202, test_loss: 107.702873\n",
      "epoch: 37800, train_loss: 44.178131, test_loss: 107.627792\n",
      "epoch: 37900, train_loss: 44.093563, test_loss: 108.006447\n",
      "epoch: 38000, train_loss: 42.372747, test_loss: 107.877579\n",
      "epoch: 38100, train_loss: 42.009625, test_loss: 106.904022\n",
      "epoch: 38200, train_loss: 42.572596, test_loss: 107.574524\n",
      "epoch: 38300, train_loss: 42.250603, test_loss: 107.828804\n",
      "epoch: 38400, train_loss: 44.005451, test_loss: 107.442490\n",
      "epoch: 38500, train_loss: 43.576216, test_loss: 107.041451\n",
      "epoch: 38600, train_loss: 42.952477, test_loss: 106.849174\n",
      "epoch: 38700, train_loss: 43.053793, test_loss: 107.052170\n",
      "epoch: 38800, train_loss: 43.151934, test_loss: 107.155411\n",
      "epoch: 38900, train_loss: 42.804232, test_loss: 106.962944\n",
      "epoch: 39000, train_loss: 43.456266, test_loss: 106.982857\n",
      "epoch: 39100, train_loss: 44.005369, test_loss: 107.027809\n",
      "epoch: 39200, train_loss: 41.895236, test_loss: 106.457336\n",
      "epoch: 39300, train_loss: 43.304951, test_loss: 106.948715\n",
      "epoch: 39400, train_loss: 43.380325, test_loss: 107.161674\n",
      "epoch: 39500, train_loss: 43.873947, test_loss: 106.826607\n",
      "epoch: 39600, train_loss: 44.311653, test_loss: 106.324776\n",
      "epoch: 39700, train_loss: 42.418676, test_loss: 106.077179\n",
      "epoch: 39800, train_loss: 44.374975, test_loss: 106.197601\n",
      "epoch: 39900, train_loss: 43.408119, test_loss: 106.686180\n",
      "epoch: 40000, train_loss: 43.765909, test_loss: 106.550575\n",
      "epoch: 40100, train_loss: 44.453310, test_loss: 106.309837\n",
      "epoch: 40200, train_loss: 42.367426, test_loss: 106.340836\n",
      "epoch: 40300, train_loss: 42.089561, test_loss: 106.261101\n",
      "epoch: 40400, train_loss: 43.006706, test_loss: 105.861420\n",
      "epoch: 40500, train_loss: 43.144993, test_loss: 106.188866\n",
      "epoch: 40600, train_loss: 42.534327, test_loss: 105.955116\n",
      "epoch: 40700, train_loss: 42.675201, test_loss: 106.216614\n",
      "epoch: 40800, train_loss: 43.002214, test_loss: 105.877998\n",
      "epoch: 40900, train_loss: 43.870275, test_loss: 105.674286\n",
      "epoch: 41000, train_loss: 43.354410, test_loss: 105.795715\n",
      "epoch: 41100, train_loss: 42.535980, test_loss: 105.599792\n",
      "epoch: 41200, train_loss: 43.699102, test_loss: 105.317947\n",
      "epoch: 41300, train_loss: 42.902464, test_loss: 105.639740\n",
      "epoch: 41400, train_loss: 43.688684, test_loss: 105.362923\n",
      "epoch: 41500, train_loss: 42.777967, test_loss: 105.197723\n",
      "epoch: 41600, train_loss: 43.666594, test_loss: 105.262978\n",
      "epoch: 41700, train_loss: 42.258200, test_loss: 105.543633\n",
      "epoch: 41800, train_loss: 42.925940, test_loss: 105.368431\n",
      "epoch: 41900, train_loss: 43.356077, test_loss: 104.973145\n",
      "epoch: 42000, train_loss: 42.509890, test_loss: 105.661873\n",
      "epoch: 42100, train_loss: 42.196712, test_loss: 105.304573\n",
      "epoch: 42200, train_loss: 42.835598, test_loss: 105.472336\n",
      "epoch: 42300, train_loss: 44.181487, test_loss: 105.149254\n",
      "epoch: 42400, train_loss: 43.663645, test_loss: 105.205643\n",
      "epoch: 42500, train_loss: 43.161594, test_loss: 105.156387\n",
      "epoch: 42600, train_loss: 43.539587, test_loss: 105.234634\n",
      "epoch: 42700, train_loss: 41.777207, test_loss: 105.174370\n",
      "epoch: 42800, train_loss: 43.934628, test_loss: 104.903267\n",
      "epoch: 42900, train_loss: 42.051260, test_loss: 105.353088\n",
      "epoch: 43000, train_loss: 42.287895, test_loss: 104.741425\n",
      "epoch: 43100, train_loss: 42.588572, test_loss: 104.777229\n",
      "epoch: 43200, train_loss: 43.491444, test_loss: 105.254715\n",
      "epoch: 43300, train_loss: 43.356947, test_loss: 105.617188\n",
      "epoch: 43400, train_loss: 42.728737, test_loss: 104.868378\n",
      "epoch: 43500, train_loss: 42.256313, test_loss: 104.899567\n",
      "epoch: 43600, train_loss: 42.588470, test_loss: 104.669113\n",
      "epoch: 43700, train_loss: 42.445820, test_loss: 104.689453\n",
      "epoch: 43800, train_loss: 42.754740, test_loss: 104.948586\n",
      "epoch: 43900, train_loss: 42.002839, test_loss: 104.373230\n",
      "epoch: 44000, train_loss: 43.669239, test_loss: 104.699776\n",
      "epoch: 44100, train_loss: 42.653761, test_loss: 105.161194\n",
      "epoch: 44200, train_loss: 42.387671, test_loss: 104.966171\n",
      "epoch: 44300, train_loss: 43.956896, test_loss: 104.627869\n",
      "epoch: 44400, train_loss: 42.816778, test_loss: 105.082199\n",
      "epoch: 44500, train_loss: 43.960020, test_loss: 105.078743\n",
      "epoch: 44600, train_loss: 42.066902, test_loss: 104.587952\n",
      "epoch: 44700, train_loss: 43.271706, test_loss: 104.132263\n",
      "epoch: 44800, train_loss: 42.661499, test_loss: 104.657112\n",
      "epoch: 44900, train_loss: 42.837772, test_loss: 104.784683\n",
      "epoch: 45000, train_loss: 42.493109, test_loss: 105.168327\n",
      "epoch: 45100, train_loss: 42.506422, test_loss: 105.004822\n",
      "epoch: 45200, train_loss: 42.245317, test_loss: 105.155708\n",
      "epoch: 45300, train_loss: 45.158737, test_loss: 104.727402\n",
      "epoch: 45400, train_loss: 43.274464, test_loss: 104.201942\n",
      "epoch: 45500, train_loss: 43.398380, test_loss: 104.590691\n",
      "epoch: 45600, train_loss: 42.155245, test_loss: 104.835312\n",
      "epoch: 45700, train_loss: 43.774187, test_loss: 104.434891\n",
      "epoch: 45800, train_loss: 42.168783, test_loss: 104.331932\n",
      "epoch: 45900, train_loss: 42.439949, test_loss: 104.404312\n",
      "epoch: 46000, train_loss: 42.988661, test_loss: 104.550896\n",
      "epoch: 46100, train_loss: 42.091717, test_loss: 104.668541\n",
      "epoch: 46200, train_loss: 42.799160, test_loss: 104.693275\n",
      "epoch: 46300, train_loss: 42.171415, test_loss: 104.649139\n",
      "epoch: 46400, train_loss: 42.742079, test_loss: 104.380844\n",
      "epoch: 46500, train_loss: 42.709232, test_loss: 104.853630\n",
      "epoch: 46600, train_loss: 41.481637, test_loss: 104.562698\n",
      "epoch: 46700, train_loss: 43.518311, test_loss: 104.814857\n",
      "epoch: 46800, train_loss: 42.239653, test_loss: 104.939781\n",
      "epoch: 46900, train_loss: 44.073478, test_loss: 104.612984\n",
      "epoch: 47000, train_loss: 42.912912, test_loss: 104.802399\n",
      "epoch: 47100, train_loss: 42.446217, test_loss: 104.617973\n",
      "epoch: 47200, train_loss: 41.923374, test_loss: 104.774284\n",
      "epoch: 47300, train_loss: 43.854198, test_loss: 104.972107\n",
      "epoch: 47400, train_loss: 42.492001, test_loss: 104.780258\n",
      "epoch: 47500, train_loss: 42.547640, test_loss: 104.894989\n",
      "epoch: 47600, train_loss: 41.711603, test_loss: 104.813492\n",
      "epoch: 47700, train_loss: 43.579636, test_loss: 104.744095\n",
      "epoch: 47800, train_loss: 43.203245, test_loss: 104.719742\n",
      "epoch: 47900, train_loss: 42.467342, test_loss: 104.521263\n",
      "epoch: 48000, train_loss: 42.633516, test_loss: 104.522392\n",
      "epoch: 48100, train_loss: 42.753963, test_loss: 105.371475\n",
      "epoch: 48200, train_loss: 42.090496, test_loss: 104.715851\n",
      "epoch: 48300, train_loss: 42.177774, test_loss: 105.071190\n",
      "epoch: 48400, train_loss: 42.208958, test_loss: 105.360039\n",
      "epoch: 48500, train_loss: 41.678139, test_loss: 104.614182\n",
      "epoch: 48600, train_loss: 41.358189, test_loss: 104.735847\n",
      "epoch: 48700, train_loss: 42.025082, test_loss: 104.729774\n",
      "epoch: 48800, train_loss: 41.885496, test_loss: 104.463264\n",
      "epoch: 48900, train_loss: 43.392322, test_loss: 104.961594\n",
      "epoch: 49000, train_loss: 41.100972, test_loss: 104.302971\n",
      "epoch: 49100, train_loss: 41.019540, test_loss: 104.547249\n",
      "epoch: 49200, train_loss: 42.487621, test_loss: 104.471176\n",
      "epoch: 49300, train_loss: 42.552647, test_loss: 104.777481\n",
      "epoch: 49400, train_loss: 40.945875, test_loss: 104.587410\n",
      "epoch: 49500, train_loss: 42.963551, test_loss: 104.685455\n",
      "epoch: 49600, train_loss: 41.865101, test_loss: 104.135910\n",
      "epoch: 49700, train_loss: 42.572004, test_loss: 104.356041\n",
      "epoch: 49800, train_loss: 41.606802, test_loss: 104.652748\n",
      "epoch: 49900, train_loss: 41.400648, test_loss: 103.908340\n",
      "epoch: 50000, train_loss: 42.051291, test_loss: 104.286728\n",
      "epoch: 50100, train_loss: 43.244648, test_loss: 104.350288\n",
      "epoch: 50200, train_loss: 42.540224, test_loss: 104.590958\n",
      "epoch: 50300, train_loss: 42.473619, test_loss: 104.936920\n",
      "epoch: 50400, train_loss: 41.587881, test_loss: 104.167747\n",
      "epoch: 50500, train_loss: 42.122370, test_loss: 104.002190\n",
      "epoch: 50600, train_loss: 42.752172, test_loss: 104.004333\n",
      "epoch: 50700, train_loss: 41.859367, test_loss: 103.920380\n",
      "epoch: 50800, train_loss: 42.104345, test_loss: 104.083015\n",
      "epoch: 50900, train_loss: 42.795851, test_loss: 103.985199\n",
      "epoch: 51000, train_loss: 42.842232, test_loss: 104.190376\n",
      "epoch: 51100, train_loss: 42.755842, test_loss: 103.797142\n",
      "epoch: 51200, train_loss: 42.479837, test_loss: 104.370743\n",
      "epoch: 51300, train_loss: 41.306705, test_loss: 103.462112\n",
      "epoch: 51400, train_loss: 41.625530, test_loss: 103.762352\n",
      "epoch: 51500, train_loss: 42.764534, test_loss: 103.913574\n",
      "epoch: 51600, train_loss: 41.276834, test_loss: 103.626198\n",
      "epoch: 51700, train_loss: 40.497336, test_loss: 103.411644\n",
      "epoch: 51800, train_loss: 43.284369, test_loss: 103.851227\n",
      "epoch: 51900, train_loss: 42.050329, test_loss: 103.609718\n",
      "epoch: 52000, train_loss: 42.549311, test_loss: 104.495468\n",
      "epoch: 52100, train_loss: 42.003946, test_loss: 103.624138\n",
      "epoch: 52200, train_loss: 42.106094, test_loss: 103.235703\n",
      "epoch: 52300, train_loss: 42.810995, test_loss: 103.349533\n",
      "epoch: 52400, train_loss: 41.275719, test_loss: 103.320580\n",
      "epoch: 52500, train_loss: 43.263290, test_loss: 103.416504\n",
      "epoch: 52600, train_loss: 42.182655, test_loss: 103.183502\n",
      "epoch: 52700, train_loss: 41.551260, test_loss: 103.991570\n",
      "epoch: 52800, train_loss: 41.614464, test_loss: 103.535095\n",
      "epoch: 52900, train_loss: 41.686399, test_loss: 103.334244\n",
      "epoch: 53000, train_loss: 42.331181, test_loss: 102.939163\n",
      "epoch: 53100, train_loss: 41.515333, test_loss: 103.423157\n",
      "epoch: 53200, train_loss: 43.078016, test_loss: 103.022064\n",
      "epoch: 53300, train_loss: 41.590988, test_loss: 103.030052\n",
      "epoch: 53400, train_loss: 42.025349, test_loss: 103.277916\n",
      "epoch: 53500, train_loss: 42.286812, test_loss: 103.021111\n",
      "epoch: 53600, train_loss: 41.752861, test_loss: 103.167336\n",
      "epoch: 53700, train_loss: 41.718306, test_loss: 103.187958\n",
      "epoch: 53800, train_loss: 41.406599, test_loss: 103.660324\n",
      "epoch: 53900, train_loss: 40.950942, test_loss: 103.082993\n",
      "epoch: 54000, train_loss: 42.226044, test_loss: 103.092621\n",
      "epoch: 54100, train_loss: 42.144354, test_loss: 103.020897\n",
      "epoch: 54200, train_loss: 41.419786, test_loss: 103.171852\n",
      "epoch: 54300, train_loss: 41.781195, test_loss: 103.366585\n",
      "epoch: 54400, train_loss: 41.960526, test_loss: 103.470955\n",
      "epoch: 54500, train_loss: 40.854759, test_loss: 103.229881\n",
      "epoch: 54600, train_loss: 41.434481, test_loss: 102.719658\n",
      "epoch: 54700, train_loss: 41.524000, test_loss: 102.607979\n",
      "epoch: 54800, train_loss: 43.397276, test_loss: 102.914642\n",
      "epoch: 54900, train_loss: 41.737253, test_loss: 102.830383\n",
      "epoch: 55000, train_loss: 42.966101, test_loss: 102.618065\n",
      "epoch: 55100, train_loss: 43.858377, test_loss: 103.152344\n",
      "epoch: 55200, train_loss: 42.515326, test_loss: 102.333511\n",
      "epoch: 55300, train_loss: 42.459503, test_loss: 103.491364\n",
      "epoch: 55400, train_loss: 42.534285, test_loss: 102.430763\n",
      "epoch: 55500, train_loss: 43.493915, test_loss: 103.275208\n",
      "epoch: 55600, train_loss: 40.108684, test_loss: 103.311600\n",
      "epoch: 55700, train_loss: 40.781992, test_loss: 102.478058\n",
      "epoch: 55800, train_loss: 41.178259, test_loss: 102.987633\n",
      "epoch: 55900, train_loss: 41.945724, test_loss: 102.340775\n",
      "epoch: 56000, train_loss: 42.367235, test_loss: 102.660980\n",
      "epoch: 56100, train_loss: 41.949448, test_loss: 102.814438\n",
      "epoch: 56200, train_loss: 41.468388, test_loss: 102.809898\n",
      "epoch: 56300, train_loss: 41.561577, test_loss: 102.816238\n",
      "epoch: 56400, train_loss: 43.012342, test_loss: 103.653419\n",
      "epoch: 56500, train_loss: 41.063240, test_loss: 102.658760\n",
      "epoch: 56600, train_loss: 42.829674, test_loss: 103.302498\n",
      "epoch: 56700, train_loss: 41.026949, test_loss: 102.410645\n",
      "epoch: 56800, train_loss: 42.074726, test_loss: 102.962486\n",
      "epoch: 56900, train_loss: 41.687836, test_loss: 102.877151\n",
      "epoch: 57000, train_loss: 42.377893, test_loss: 103.228836\n",
      "epoch: 57100, train_loss: 41.354219, test_loss: 102.986473\n",
      "epoch: 57200, train_loss: 43.594905, test_loss: 102.794762\n",
      "epoch: 57300, train_loss: 43.580683, test_loss: 102.960403\n",
      "epoch: 57400, train_loss: 41.025969, test_loss: 102.504105\n",
      "epoch: 57500, train_loss: 42.002790, test_loss: 102.869041\n",
      "epoch: 57600, train_loss: 42.804238, test_loss: 102.503876\n",
      "epoch: 57700, train_loss: 42.785080, test_loss: 102.502510\n",
      "epoch: 57800, train_loss: 41.777472, test_loss: 102.325516\n",
      "epoch: 57900, train_loss: 40.971525, test_loss: 102.358704\n",
      "epoch: 58000, train_loss: 42.204336, test_loss: 102.833611\n",
      "epoch: 58100, train_loss: 41.549620, test_loss: 102.675880\n",
      "epoch: 58200, train_loss: 41.484211, test_loss: 102.928276\n",
      "epoch: 58300, train_loss: 40.898985, test_loss: 102.734138\n",
      "epoch: 58400, train_loss: 42.076664, test_loss: 102.959259\n",
      "epoch: 58500, train_loss: 41.382803, test_loss: 102.704872\n",
      "epoch: 58600, train_loss: 40.945597, test_loss: 102.962959\n",
      "epoch: 58700, train_loss: 41.226034, test_loss: 102.817116\n",
      "epoch: 58800, train_loss: 40.368142, test_loss: 102.664818\n",
      "epoch: 58900, train_loss: 40.725289, test_loss: 102.838890\n",
      "epoch: 59000, train_loss: 40.905407, test_loss: 102.806183\n",
      "epoch: 59100, train_loss: 41.436348, test_loss: 102.859703\n",
      "epoch: 59200, train_loss: 40.623970, test_loss: 102.925880\n",
      "epoch: 59300, train_loss: 39.864546, test_loss: 102.538681\n",
      "epoch: 59400, train_loss: 40.781143, test_loss: 102.670609\n",
      "epoch: 59500, train_loss: 41.972797, test_loss: 102.036369\n",
      "epoch: 59600, train_loss: 42.031992, test_loss: 102.521484\n",
      "epoch: 59700, train_loss: 41.149065, test_loss: 102.624504\n",
      "epoch: 59800, train_loss: 41.865664, test_loss: 102.052673\n",
      "epoch: 59900, train_loss: 41.054640, test_loss: 102.841698\n",
      "epoch: 60000, train_loss: 42.138231, test_loss: 102.900337\n",
      "epoch: 60100, train_loss: 42.153074, test_loss: 102.449081\n",
      "epoch: 60200, train_loss: 41.478045, test_loss: 102.811424\n",
      "epoch: 60300, train_loss: 40.837870, test_loss: 101.933044\n",
      "epoch: 60400, train_loss: 42.648960, test_loss: 102.647629\n",
      "epoch: 60500, train_loss: 41.819849, test_loss: 102.757332\n",
      "epoch: 60600, train_loss: 40.640005, test_loss: 102.170753\n",
      "epoch: 60700, train_loss: 41.948021, test_loss: 102.302078\n",
      "epoch: 60800, train_loss: 42.682032, test_loss: 102.582100\n",
      "epoch: 60900, train_loss: 41.779387, test_loss: 102.576172\n",
      "epoch: 61000, train_loss: 42.487343, test_loss: 102.325706\n",
      "epoch: 61100, train_loss: 42.905060, test_loss: 101.781059\n",
      "epoch: 61200, train_loss: 40.871643, test_loss: 102.397408\n",
      "epoch: 61300, train_loss: 40.848246, test_loss: 102.442329\n",
      "epoch: 61400, train_loss: 40.939125, test_loss: 102.307373\n",
      "epoch: 61500, train_loss: 40.525309, test_loss: 102.071342\n",
      "epoch: 61600, train_loss: 42.175583, test_loss: 102.325417\n",
      "epoch: 61700, train_loss: 41.164326, test_loss: 101.909172\n",
      "epoch: 61800, train_loss: 40.528400, test_loss: 101.853355\n",
      "epoch: 61900, train_loss: 41.466883, test_loss: 101.921989\n",
      "epoch: 62000, train_loss: 41.629005, test_loss: 102.082314\n",
      "epoch: 62100, train_loss: 41.033110, test_loss: 101.727875\n",
      "epoch: 62200, train_loss: 41.345699, test_loss: 102.333954\n",
      "epoch: 62300, train_loss: 41.037376, test_loss: 101.662788\n",
      "epoch: 62400, train_loss: 41.888666, test_loss: 102.025620\n",
      "epoch: 62500, train_loss: 42.469684, test_loss: 101.889534\n",
      "epoch: 62600, train_loss: 40.101499, test_loss: 102.149147\n",
      "epoch: 62700, train_loss: 40.955006, test_loss: 101.674614\n",
      "epoch: 62800, train_loss: 40.835625, test_loss: 101.810387\n",
      "epoch: 62900, train_loss: 42.030416, test_loss: 102.172501\n",
      "epoch: 63000, train_loss: 42.139715, test_loss: 101.640701\n",
      "epoch: 63100, train_loss: 40.952892, test_loss: 101.698845\n",
      "epoch: 63200, train_loss: 41.822403, test_loss: 101.476814\n",
      "epoch: 63300, train_loss: 40.479046, test_loss: 101.749077\n",
      "epoch: 63400, train_loss: 40.954178, test_loss: 101.577690\n",
      "epoch: 63500, train_loss: 40.759920, test_loss: 101.628838\n",
      "epoch: 63600, train_loss: 39.894919, test_loss: 101.923538\n",
      "epoch: 63700, train_loss: 41.361179, test_loss: 100.996887\n",
      "epoch: 63800, train_loss: 39.992035, test_loss: 101.957283\n",
      "epoch: 63900, train_loss: 40.265512, test_loss: 101.875710\n",
      "epoch: 64000, train_loss: 41.505152, test_loss: 102.160126\n",
      "epoch: 64100, train_loss: 40.447968, test_loss: 101.480118\n",
      "epoch: 64200, train_loss: 40.414436, test_loss: 101.646500\n",
      "epoch: 64300, train_loss: 41.106133, test_loss: 101.399422\n",
      "epoch: 64400, train_loss: 41.849874, test_loss: 102.256996\n",
      "epoch: 64500, train_loss: 40.113617, test_loss: 101.207230\n",
      "epoch: 64600, train_loss: 40.203917, test_loss: 101.576797\n",
      "epoch: 64700, train_loss: 40.503939, test_loss: 101.193939\n",
      "epoch: 64800, train_loss: 41.881111, test_loss: 101.860146\n",
      "epoch: 64900, train_loss: 42.257140, test_loss: 101.945244\n",
      "epoch: 65000, train_loss: 40.572968, test_loss: 101.577454\n",
      "epoch: 65100, train_loss: 40.621443, test_loss: 101.371521\n",
      "epoch: 65200, train_loss: 40.770576, test_loss: 101.630341\n",
      "epoch: 65300, train_loss: 41.121620, test_loss: 101.631973\n",
      "epoch: 65400, train_loss: 41.470137, test_loss: 101.703598\n",
      "epoch: 65500, train_loss: 40.484367, test_loss: 102.049973\n",
      "epoch: 65600, train_loss: 40.326124, test_loss: 101.704285\n",
      "epoch: 65700, train_loss: 41.398020, test_loss: 101.586830\n",
      "epoch: 65800, train_loss: 40.681549, test_loss: 101.474251\n",
      "epoch: 65900, train_loss: 40.266138, test_loss: 101.320198\n",
      "epoch: 66000, train_loss: 40.724644, test_loss: 101.475960\n",
      "epoch: 66100, train_loss: 41.499210, test_loss: 101.803780\n",
      "epoch: 66200, train_loss: 40.237924, test_loss: 101.258621\n",
      "epoch: 66300, train_loss: 39.889611, test_loss: 101.688850\n",
      "epoch: 66400, train_loss: 41.083649, test_loss: 101.112000\n",
      "epoch: 66500, train_loss: 40.282225, test_loss: 100.926460\n",
      "epoch: 66600, train_loss: 40.890205, test_loss: 101.804131\n",
      "epoch: 66700, train_loss: 40.178165, test_loss: 101.379097\n",
      "epoch: 66800, train_loss: 41.415985, test_loss: 101.495201\n",
      "epoch: 66900, train_loss: 40.659082, test_loss: 101.874359\n",
      "epoch: 67000, train_loss: 40.200938, test_loss: 101.305862\n",
      "epoch: 67100, train_loss: 41.300205, test_loss: 101.318832\n",
      "epoch: 67200, train_loss: 39.739573, test_loss: 101.799149\n",
      "epoch: 67300, train_loss: 39.892627, test_loss: 101.262558\n",
      "epoch: 67400, train_loss: 40.075235, test_loss: 101.395271\n",
      "epoch: 67500, train_loss: 40.774633, test_loss: 101.150490\n",
      "epoch: 67600, train_loss: 39.650124, test_loss: 101.294449\n",
      "epoch: 67700, train_loss: 40.307459, test_loss: 101.352455\n",
      "epoch: 67800, train_loss: 40.250292, test_loss: 101.062614\n",
      "epoch: 67900, train_loss: 41.133883, test_loss: 101.185829\n",
      "epoch: 68000, train_loss: 41.529226, test_loss: 101.573914\n",
      "epoch: 68100, train_loss: 40.108984, test_loss: 101.035248\n",
      "epoch: 68200, train_loss: 40.581100, test_loss: 100.863182\n",
      "epoch: 68300, train_loss: 42.036611, test_loss: 100.651100\n",
      "epoch: 68400, train_loss: 40.049156, test_loss: 100.929283\n",
      "epoch: 68500, train_loss: 41.828619, test_loss: 101.293640\n",
      "epoch: 68600, train_loss: 40.324450, test_loss: 100.921646\n",
      "epoch: 68700, train_loss: 42.280244, test_loss: 101.580048\n",
      "epoch: 68800, train_loss: 40.764116, test_loss: 101.292160\n",
      "epoch: 68900, train_loss: 40.871611, test_loss: 101.271980\n",
      "epoch: 69000, train_loss: 39.962029, test_loss: 100.927872\n",
      "epoch: 69100, train_loss: 41.236006, test_loss: 101.264542\n",
      "epoch: 69200, train_loss: 40.218828, test_loss: 100.996605\n",
      "epoch: 69300, train_loss: 40.380552, test_loss: 100.938957\n",
      "epoch: 69400, train_loss: 39.681826, test_loss: 101.479492\n",
      "epoch: 69500, train_loss: 41.789039, test_loss: 101.334343\n",
      "epoch: 69600, train_loss: 40.459051, test_loss: 101.902847\n",
      "epoch: 69700, train_loss: 41.549719, test_loss: 101.663841\n",
      "epoch: 69800, train_loss: 40.029543, test_loss: 101.535919\n",
      "epoch: 69900, train_loss: 39.638673, test_loss: 101.127594\n",
      "epoch: 70000, train_loss: 40.959101, test_loss: 101.280067\n",
      "epoch: 70100, train_loss: 41.351372, test_loss: 101.256889\n",
      "epoch: 70200, train_loss: 40.892361, test_loss: 100.779800\n",
      "epoch: 70300, train_loss: 40.914305, test_loss: 101.048943\n",
      "epoch: 70400, train_loss: 41.261908, test_loss: 100.505219\n",
      "epoch: 70500, train_loss: 40.292931, test_loss: 101.215584\n",
      "epoch: 70600, train_loss: 41.225145, test_loss: 100.958359\n",
      "epoch: 70700, train_loss: 39.800139, test_loss: 101.269508\n",
      "epoch: 70800, train_loss: 40.707361, test_loss: 100.854630\n",
      "epoch: 70900, train_loss: 39.258591, test_loss: 100.987946\n",
      "epoch: 71000, train_loss: 40.855309, test_loss: 101.553040\n",
      "epoch: 71100, train_loss: 42.021002, test_loss: 101.209854\n",
      "epoch: 71200, train_loss: 42.412907, test_loss: 101.384743\n",
      "epoch: 71300, train_loss: 39.821315, test_loss: 101.308647\n",
      "epoch: 71400, train_loss: 40.720705, test_loss: 101.287430\n",
      "epoch: 71500, train_loss: 39.930204, test_loss: 101.288437\n",
      "epoch: 71600, train_loss: 39.431437, test_loss: 101.402931\n",
      "epoch: 71700, train_loss: 40.137474, test_loss: 101.241737\n",
      "epoch: 71800, train_loss: 40.853558, test_loss: 100.982994\n",
      "epoch: 71900, train_loss: 40.466263, test_loss: 101.440903\n",
      "epoch: 72000, train_loss: 40.267084, test_loss: 101.307838\n",
      "epoch: 72100, train_loss: 39.396609, test_loss: 101.497375\n",
      "epoch: 72200, train_loss: 40.634241, test_loss: 100.863899\n",
      "epoch: 72300, train_loss: 41.458838, test_loss: 101.037041\n",
      "epoch: 72400, train_loss: 40.427523, test_loss: 100.845711\n",
      "epoch: 72500, train_loss: 39.235135, test_loss: 100.948715\n",
      "epoch: 72600, train_loss: 39.942236, test_loss: 100.883385\n",
      "epoch: 72700, train_loss: 40.309599, test_loss: 100.964790\n",
      "epoch: 72800, train_loss: 40.005625, test_loss: 101.562210\n",
      "epoch: 72900, train_loss: 39.448240, test_loss: 101.345062\n",
      "epoch: 73000, train_loss: 42.251310, test_loss: 101.276184\n",
      "epoch: 73100, train_loss: 40.309246, test_loss: 101.256248\n",
      "epoch: 73200, train_loss: 40.920885, test_loss: 101.435272\n",
      "epoch: 73300, train_loss: 40.911093, test_loss: 101.814133\n",
      "epoch: 73400, train_loss: 40.092710, test_loss: 101.278015\n",
      "epoch: 73500, train_loss: 39.784601, test_loss: 101.645538\n",
      "epoch: 73600, train_loss: 40.405678, test_loss: 101.593452\n",
      "epoch: 73700, train_loss: 40.810581, test_loss: 101.222794\n",
      "epoch: 73800, train_loss: 39.945675, test_loss: 101.213348\n",
      "epoch: 73900, train_loss: 40.410505, test_loss: 101.763367\n",
      "epoch: 74000, train_loss: 39.781786, test_loss: 101.898628\n",
      "epoch: 74100, train_loss: 42.273903, test_loss: 101.430038\n",
      "epoch: 74200, train_loss: 39.832733, test_loss: 101.827011\n",
      "epoch: 74300, train_loss: 40.924713, test_loss: 101.801537\n",
      "epoch: 74400, train_loss: 40.382978, test_loss: 101.748787\n",
      "epoch: 74500, train_loss: 40.297121, test_loss: 101.802513\n",
      "epoch: 74600, train_loss: 39.741837, test_loss: 102.270859\n",
      "epoch: 74700, train_loss: 40.279114, test_loss: 102.055634\n",
      "epoch: 74800, train_loss: 40.851084, test_loss: 102.094124\n",
      "epoch: 74900, train_loss: 40.578779, test_loss: 102.073784\n",
      "epoch: 75000, train_loss: 39.863247, test_loss: 101.632828\n",
      "epoch: 75100, train_loss: 39.525797, test_loss: 101.900124\n",
      "epoch: 75200, train_loss: 40.460491, test_loss: 101.789192\n",
      "epoch: 75300, train_loss: 39.503411, test_loss: 102.102211\n",
      "epoch: 75400, train_loss: 41.069754, test_loss: 102.014320\n",
      "epoch: 75500, train_loss: 40.603363, test_loss: 101.689690\n",
      "epoch: 75600, train_loss: 40.381069, test_loss: 102.122368\n",
      "epoch: 75700, train_loss: 40.921103, test_loss: 101.753342\n",
      "epoch: 75800, train_loss: 39.829678, test_loss: 101.220284\n",
      "epoch: 75900, train_loss: 38.836360, test_loss: 101.670258\n",
      "epoch: 76000, train_loss: 40.664017, test_loss: 101.516022\n",
      "epoch: 76100, train_loss: 41.083250, test_loss: 101.688667\n",
      "epoch: 76200, train_loss: 38.719780, test_loss: 101.641762\n",
      "epoch: 76300, train_loss: 40.034296, test_loss: 101.869110\n",
      "epoch: 76400, train_loss: 39.005563, test_loss: 101.165558\n",
      "epoch: 76500, train_loss: 40.378765, test_loss: 101.515167\n",
      "epoch: 76600, train_loss: 39.235069, test_loss: 101.605522\n",
      "epoch: 76700, train_loss: 40.265327, test_loss: 101.378349\n",
      "epoch: 76800, train_loss: 41.321825, test_loss: 101.791107\n",
      "epoch: 76900, train_loss: 39.563454, test_loss: 101.628113\n",
      "epoch: 77000, train_loss: 39.950512, test_loss: 101.339996\n",
      "epoch: 77100, train_loss: 40.050694, test_loss: 101.103889\n",
      "epoch: 77200, train_loss: 40.316195, test_loss: 101.699745\n",
      "epoch: 77300, train_loss: 39.665779, test_loss: 101.251862\n",
      "epoch: 77400, train_loss: 39.883400, test_loss: 100.805664\n",
      "epoch: 77500, train_loss: 39.506800, test_loss: 101.677734\n",
      "epoch: 77600, train_loss: 39.430761, test_loss: 101.191711\n",
      "epoch: 77700, train_loss: 39.307661, test_loss: 101.522591\n",
      "epoch: 77800, train_loss: 40.914770, test_loss: 101.544746\n",
      "epoch: 77900, train_loss: 39.767405, test_loss: 101.181564\n",
      "epoch: 78000, train_loss: 41.164984, test_loss: 101.836777\n",
      "epoch: 78100, train_loss: 40.169521, test_loss: 100.714134\n",
      "epoch: 78200, train_loss: 40.374146, test_loss: 100.758766\n",
      "epoch: 78300, train_loss: 40.252966, test_loss: 101.108681\n",
      "epoch: 78400, train_loss: 39.469019, test_loss: 101.092186\n",
      "epoch: 78500, train_loss: 39.794365, test_loss: 100.665421\n",
      "epoch: 78600, train_loss: 40.453537, test_loss: 100.988228\n",
      "epoch: 78700, train_loss: 39.145489, test_loss: 101.285469\n",
      "epoch: 78800, train_loss: 39.686964, test_loss: 100.789230\n",
      "epoch: 78900, train_loss: 39.894583, test_loss: 101.060432\n",
      "epoch: 79000, train_loss: 41.080867, test_loss: 100.552223\n",
      "epoch: 79100, train_loss: 41.271139, test_loss: 100.922935\n",
      "epoch: 79200, train_loss: 40.099932, test_loss: 100.989204\n",
      "epoch: 79300, train_loss: 38.850479, test_loss: 100.982254\n",
      "epoch: 79400, train_loss: 41.188707, test_loss: 100.956223\n",
      "epoch: 79500, train_loss: 40.298195, test_loss: 100.580093\n",
      "epoch: 79600, train_loss: 39.665653, test_loss: 100.503990\n",
      "epoch: 79700, train_loss: 40.132147, test_loss: 100.482925\n",
      "epoch: 79800, train_loss: 39.888380, test_loss: 100.722908\n",
      "epoch: 79900, train_loss: 40.892996, test_loss: 100.807938\n",
      "epoch: 80000, train_loss: 39.519904, test_loss: 100.269814\n",
      "epoch: 80100, train_loss: 40.732723, test_loss: 100.595032\n",
      "epoch: 80200, train_loss: 38.171514, test_loss: 100.281624\n",
      "epoch: 80300, train_loss: 40.423521, test_loss: 100.421425\n",
      "epoch: 80400, train_loss: 40.821630, test_loss: 100.031136\n",
      "epoch: 80500, train_loss: 39.924026, test_loss: 99.758568\n",
      "epoch: 80600, train_loss: 40.325745, test_loss: 100.777611\n",
      "epoch: 80700, train_loss: 40.193359, test_loss: 100.496452\n",
      "epoch: 80800, train_loss: 39.904062, test_loss: 100.584854\n",
      "epoch: 80900, train_loss: 40.197014, test_loss: 100.897064\n",
      "epoch: 81000, train_loss: 40.994473, test_loss: 100.416733\n",
      "epoch: 81100, train_loss: 39.790253, test_loss: 100.598640\n",
      "epoch: 81200, train_loss: 40.305235, test_loss: 100.649918\n",
      "epoch: 81300, train_loss: 39.623003, test_loss: 100.267578\n",
      "epoch: 81400, train_loss: 40.301168, test_loss: 100.410126\n",
      "epoch: 81500, train_loss: 39.121475, test_loss: 100.332314\n",
      "epoch: 81600, train_loss: 40.436676, test_loss: 99.671082\n",
      "epoch: 81700, train_loss: 39.721941, test_loss: 100.234879\n",
      "epoch: 81800, train_loss: 39.218990, test_loss: 100.292648\n",
      "epoch: 81900, train_loss: 39.528923, test_loss: 100.073822\n",
      "epoch: 82000, train_loss: 40.449270, test_loss: 100.325569\n",
      "epoch: 82100, train_loss: 40.275846, test_loss: 100.025902\n",
      "epoch: 82200, train_loss: 39.184462, test_loss: 99.924370\n",
      "epoch: 82300, train_loss: 40.566152, test_loss: 99.779633\n",
      "epoch: 82400, train_loss: 39.981461, test_loss: 100.168243\n",
      "epoch: 82500, train_loss: 39.185490, test_loss: 100.019203\n",
      "epoch: 82600, train_loss: 38.832816, test_loss: 99.514252\n",
      "epoch: 82700, train_loss: 40.096882, test_loss: 99.805336\n",
      "epoch: 82800, train_loss: 40.758299, test_loss: 99.714203\n",
      "epoch: 82900, train_loss: 39.786066, test_loss: 99.514755\n",
      "epoch: 83000, train_loss: 39.632875, test_loss: 99.719460\n",
      "epoch: 83100, train_loss: 39.459373, test_loss: 100.228973\n",
      "epoch: 83200, train_loss: 40.241222, test_loss: 100.066948\n",
      "epoch: 83300, train_loss: 40.725409, test_loss: 99.960136\n",
      "epoch: 83400, train_loss: 40.343092, test_loss: 99.767258\n",
      "epoch: 83500, train_loss: 39.297924, test_loss: 99.763504\n",
      "epoch: 83600, train_loss: 39.866190, test_loss: 99.479347\n",
      "epoch: 83700, train_loss: 38.652538, test_loss: 99.537956\n",
      "epoch: 83800, train_loss: 39.679590, test_loss: 99.338333\n",
      "epoch: 83900, train_loss: 40.072302, test_loss: 99.619492\n",
      "epoch: 84000, train_loss: 39.110219, test_loss: 99.651726\n",
      "epoch: 84100, train_loss: 39.852144, test_loss: 99.555000\n",
      "epoch: 84200, train_loss: 39.770304, test_loss: 99.810432\n",
      "epoch: 84300, train_loss: 39.423923, test_loss: 99.317665\n",
      "epoch: 84400, train_loss: 40.532547, test_loss: 99.307632\n",
      "epoch: 84500, train_loss: 39.431646, test_loss: 99.533745\n",
      "epoch: 84600, train_loss: 39.791651, test_loss: 99.200630\n",
      "epoch: 84700, train_loss: 40.295345, test_loss: 99.161972\n",
      "epoch: 84800, train_loss: 40.916792, test_loss: 99.767166\n",
      "epoch: 84900, train_loss: 39.843117, test_loss: 99.515785\n",
      "epoch: 85000, train_loss: 39.874523, test_loss: 99.972626\n",
      "epoch: 85100, train_loss: 38.846026, test_loss: 99.468277\n",
      "epoch: 85200, train_loss: 39.007452, test_loss: 99.312347\n",
      "epoch: 85300, train_loss: 39.716228, test_loss: 99.282600\n",
      "epoch: 85400, train_loss: 38.938996, test_loss: 99.539635\n",
      "epoch: 85500, train_loss: 39.814026, test_loss: 99.406105\n",
      "epoch: 85600, train_loss: 38.984928, test_loss: 98.978584\n",
      "epoch: 85700, train_loss: 39.208118, test_loss: 98.761368\n",
      "epoch: 85800, train_loss: 39.227293, test_loss: 99.615868\n",
      "epoch: 85900, train_loss: 39.394337, test_loss: 99.046364\n",
      "epoch: 86000, train_loss: 39.405254, test_loss: 99.076797\n",
      "epoch: 86100, train_loss: 39.025301, test_loss: 98.947342\n",
      "epoch: 86200, train_loss: 38.292472, test_loss: 99.376015\n",
      "epoch: 86300, train_loss: 39.319117, test_loss: 99.093651\n",
      "epoch: 86400, train_loss: 38.381413, test_loss: 98.844574\n",
      "epoch: 86500, train_loss: 38.666438, test_loss: 99.548210\n",
      "epoch: 86600, train_loss: 40.098242, test_loss: 98.915352\n",
      "epoch: 86700, train_loss: 38.271673, test_loss: 99.001106\n",
      "epoch: 86800, train_loss: 40.247656, test_loss: 98.874611\n",
      "epoch: 86900, train_loss: 38.835116, test_loss: 98.645172\n",
      "epoch: 87000, train_loss: 38.902366, test_loss: 98.604187\n",
      "epoch: 87100, train_loss: 39.647676, test_loss: 98.550301\n",
      "epoch: 87200, train_loss: 38.820095, test_loss: 99.473778\n",
      "epoch: 87300, train_loss: 40.473927, test_loss: 99.337502\n",
      "epoch: 87400, train_loss: 39.395473, test_loss: 98.730316\n",
      "epoch: 87500, train_loss: 39.640329, test_loss: 98.493629\n",
      "epoch: 87600, train_loss: 39.854021, test_loss: 98.611168\n",
      "epoch: 87700, train_loss: 40.514759, test_loss: 98.865456\n",
      "epoch: 87800, train_loss: 40.258477, test_loss: 98.587585\n",
      "epoch: 87900, train_loss: 39.990421, test_loss: 98.327454\n",
      "epoch: 88000, train_loss: 39.936100, test_loss: 98.987991\n",
      "epoch: 88100, train_loss: 39.906324, test_loss: 99.129555\n",
      "epoch: 88200, train_loss: 39.808353, test_loss: 99.289192\n",
      "epoch: 88300, train_loss: 39.893131, test_loss: 99.224754\n",
      "epoch: 88400, train_loss: 38.247930, test_loss: 98.704826\n",
      "epoch: 88500, train_loss: 40.317595, test_loss: 98.974304\n",
      "epoch: 88600, train_loss: 38.415978, test_loss: 98.522377\n",
      "epoch: 88700, train_loss: 37.777723, test_loss: 98.683739\n",
      "epoch: 88800, train_loss: 40.456031, test_loss: 98.208664\n",
      "epoch: 88900, train_loss: 39.126610, test_loss: 98.474792\n",
      "epoch: 89000, train_loss: 40.959400, test_loss: 98.765556\n",
      "epoch: 89100, train_loss: 39.808138, test_loss: 98.526550\n",
      "epoch: 89200, train_loss: 40.588343, test_loss: 98.511734\n",
      "epoch: 89300, train_loss: 39.069855, test_loss: 98.705872\n",
      "epoch: 89400, train_loss: 39.537645, test_loss: 98.351189\n",
      "epoch: 89500, train_loss: 39.123587, test_loss: 98.190971\n",
      "epoch: 89600, train_loss: 39.477243, test_loss: 98.543999\n",
      "epoch: 89700, train_loss: 39.316389, test_loss: 98.926842\n",
      "epoch: 89800, train_loss: 39.505314, test_loss: 98.206078\n",
      "epoch: 89900, train_loss: 38.722069, test_loss: 98.271385\n",
      "epoch: 90000, train_loss: 39.701744, test_loss: 98.143623\n",
      "epoch: 90100, train_loss: 38.454117, test_loss: 98.463631\n",
      "epoch: 90200, train_loss: 38.841982, test_loss: 98.662041\n",
      "epoch: 90300, train_loss: 38.581691, test_loss: 98.638115\n",
      "epoch: 90400, train_loss: 37.740282, test_loss: 97.976028\n",
      "epoch: 90500, train_loss: 40.289722, test_loss: 98.500092\n",
      "epoch: 90600, train_loss: 38.708561, test_loss: 97.832588\n",
      "epoch: 90700, train_loss: 39.390015, test_loss: 98.206596\n",
      "epoch: 90800, train_loss: 38.516123, test_loss: 98.328888\n",
      "epoch: 90900, train_loss: 39.401909, test_loss: 98.340874\n",
      "epoch: 91000, train_loss: 39.657928, test_loss: 97.702568\n",
      "epoch: 91100, train_loss: 39.017481, test_loss: 98.047615\n",
      "epoch: 91200, train_loss: 38.458396, test_loss: 98.515045\n",
      "epoch: 91300, train_loss: 39.153368, test_loss: 97.657753\n",
      "epoch: 91400, train_loss: 40.057236, test_loss: 97.635391\n",
      "epoch: 91500, train_loss: 38.765051, test_loss: 97.710114\n",
      "epoch: 91600, train_loss: 39.388216, test_loss: 98.106171\n",
      "epoch: 91700, train_loss: 39.548752, test_loss: 97.833565\n",
      "epoch: 91800, train_loss: 38.921150, test_loss: 97.243332\n",
      "epoch: 91900, train_loss: 39.329126, test_loss: 97.895355\n",
      "epoch: 92000, train_loss: 39.013226, test_loss: 98.029045\n",
      "epoch: 92100, train_loss: 39.446501, test_loss: 98.062126\n",
      "epoch: 92200, train_loss: 39.009556, test_loss: 98.093719\n",
      "epoch: 92300, train_loss: 39.631805, test_loss: 97.609016\n",
      "epoch: 92400, train_loss: 39.292776, test_loss: 97.655495\n",
      "epoch: 92500, train_loss: 37.882852, test_loss: 97.872101\n",
      "epoch: 92600, train_loss: 39.272560, test_loss: 97.845398\n",
      "epoch: 92700, train_loss: 38.963799, test_loss: 97.704628\n",
      "epoch: 92800, train_loss: 38.918291, test_loss: 97.794258\n",
      "epoch: 92900, train_loss: 39.815187, test_loss: 97.881348\n",
      "epoch: 93000, train_loss: 39.452166, test_loss: 97.937233\n",
      "epoch: 93100, train_loss: 39.944650, test_loss: 98.113434\n",
      "epoch: 93200, train_loss: 38.274675, test_loss: 97.873215\n",
      "epoch: 93300, train_loss: 38.143864, test_loss: 97.461708\n",
      "epoch: 93400, train_loss: 38.491314, test_loss: 97.946198\n",
      "epoch: 93500, train_loss: 39.696697, test_loss: 98.051216\n",
      "epoch: 93600, train_loss: 39.002842, test_loss: 97.810219\n",
      "epoch: 93700, train_loss: 40.155062, test_loss: 97.716881\n",
      "epoch: 93800, train_loss: 39.375486, test_loss: 98.061432\n",
      "epoch: 93900, train_loss: 38.702999, test_loss: 97.077248\n",
      "epoch: 94000, train_loss: 38.304916, test_loss: 97.602310\n",
      "epoch: 94100, train_loss: 37.857020, test_loss: 97.534256\n",
      "epoch: 94200, train_loss: 38.553532, test_loss: 97.275558\n",
      "epoch: 94300, train_loss: 39.488533, test_loss: 97.990654\n",
      "epoch: 94400, train_loss: 38.339499, test_loss: 97.779549\n",
      "epoch: 94500, train_loss: 37.654994, test_loss: 97.197845\n",
      "epoch: 94600, train_loss: 38.798098, test_loss: 97.808365\n",
      "epoch: 94700, train_loss: 38.536268, test_loss: 97.990623\n",
      "epoch: 94800, train_loss: 38.201240, test_loss: 97.908073\n",
      "epoch: 94900, train_loss: 39.841831, test_loss: 97.554626\n",
      "epoch: 95000, train_loss: 39.722992, test_loss: 97.655487\n",
      "epoch: 95100, train_loss: 38.708916, test_loss: 97.561302\n",
      "epoch: 95200, train_loss: 40.354307, test_loss: 97.411949\n",
      "epoch: 95300, train_loss: 39.627079, test_loss: 97.710243\n",
      "epoch: 95400, train_loss: 38.178134, test_loss: 97.418655\n",
      "epoch: 95500, train_loss: 39.300028, test_loss: 98.091682\n",
      "epoch: 95600, train_loss: 38.719244, test_loss: 97.844749\n",
      "epoch: 95700, train_loss: 40.590262, test_loss: 98.083122\n",
      "epoch: 95800, train_loss: 37.927931, test_loss: 97.705078\n",
      "epoch: 95900, train_loss: 39.264639, test_loss: 97.865738\n",
      "epoch: 96000, train_loss: 38.538191, test_loss: 97.739494\n",
      "epoch: 96100, train_loss: 39.546850, test_loss: 97.783310\n",
      "epoch: 96200, train_loss: 39.027372, test_loss: 97.258865\n",
      "epoch: 96300, train_loss: 38.056006, test_loss: 97.728439\n",
      "epoch: 96400, train_loss: 38.286612, test_loss: 97.714760\n",
      "epoch: 96500, train_loss: 39.349066, test_loss: 97.173912\n",
      "epoch: 96600, train_loss: 38.852053, test_loss: 97.430779\n",
      "epoch: 96700, train_loss: 37.712664, test_loss: 97.393608\n",
      "epoch: 96800, train_loss: 37.659555, test_loss: 97.723732\n",
      "epoch: 96900, train_loss: 37.587376, test_loss: 97.038727\n",
      "epoch: 97000, train_loss: 39.110935, test_loss: 98.038811\n",
      "epoch: 97100, train_loss: 39.382708, test_loss: 97.714020\n",
      "epoch: 97200, train_loss: 38.969521, test_loss: 97.939865\n",
      "epoch: 97300, train_loss: 39.130533, test_loss: 97.831917\n",
      "epoch: 97400, train_loss: 38.608229, test_loss: 97.576439\n",
      "epoch: 97500, train_loss: 38.127853, test_loss: 97.841911\n",
      "epoch: 97600, train_loss: 37.488929, test_loss: 97.481308\n",
      "epoch: 97700, train_loss: 37.833748, test_loss: 97.824951\n",
      "epoch: 97800, train_loss: 38.683765, test_loss: 97.806709\n",
      "epoch: 97900, train_loss: 37.796244, test_loss: 97.903488\n",
      "epoch: 98000, train_loss: 38.569304, test_loss: 97.653831\n",
      "epoch: 98100, train_loss: 39.043350, test_loss: 98.132027\n",
      "epoch: 98200, train_loss: 37.624090, test_loss: 97.382881\n",
      "epoch: 98300, train_loss: 38.148907, test_loss: 97.607643\n",
      "epoch: 98400, train_loss: 38.971485, test_loss: 98.136360\n",
      "epoch: 98500, train_loss: 39.144724, test_loss: 98.002899\n",
      "epoch: 98600, train_loss: 39.779401, test_loss: 98.136986\n",
      "epoch: 98700, train_loss: 37.753788, test_loss: 97.580505\n",
      "epoch: 98800, train_loss: 38.290251, test_loss: 98.331070\n",
      "epoch: 98900, train_loss: 39.502279, test_loss: 98.382713\n",
      "epoch: 99000, train_loss: 39.127029, test_loss: 98.053619\n",
      "epoch: 99100, train_loss: 39.104415, test_loss: 98.251480\n",
      "epoch: 99200, train_loss: 38.709789, test_loss: 98.104927\n",
      "epoch: 99300, train_loss: 38.502974, test_loss: 98.006813\n",
      "epoch: 99400, train_loss: 38.516750, test_loss: 98.344376\n",
      "epoch: 99500, train_loss: 39.102150, test_loss: 98.199959\n",
      "epoch: 99600, train_loss: 38.828609, test_loss: 98.081200\n",
      "epoch: 99700, train_loss: 37.396956, test_loss: 98.251244\n",
      "epoch: 99800, train_loss: 38.527605, test_loss: 98.327393\n",
      "epoch: 99900, train_loss: 36.897854, test_loss: 98.131699\n"
     ]
    }
   ],
   "source": [
    "min_test_loss = np.inf\n",
    "\n",
    "for epoch in range(100000):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (x, y) in enumerate(dataloader_train):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        for i, (x, y) in enumerate(dataloader_test):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "        save_model = False\n",
    "        if test_loss < min_test_loss:\n",
    "            min_test_loss = test_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            save_model = True\n",
    "\n",
    "        if save_model:\n",
    "            print('epoch: {}, train_loss: {:.6f}, test_loss: {:.6f} (Saved)'.format(epoch, train_loss, test_loss))\n",
    "        else:\n",
    "            print('epoch: {}, train_loss: {:.6f}, test_loss: {:.6f}'.format(epoch, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX path: /home/icar/icar-ng-data/model/pixel2cm_model.onnx\n",
      "Saving ONNX model: /home/icar/icar-ng-data/model/pixel2cm_model.onnx\n",
      "Exported graph: graph(%onnx::Sub_0 : Float(1, 2, strides=[2, 1], requires_grad=0, device=cuda:0),\n",
      "      %fc1.weight : Float(4, 2, strides=[2, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc1.bias : Float(4, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc2.weight : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc2.bias : Float(20, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc3.weight : Float(80, 20, strides=[20, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc3.bias : Float(80, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc4.weight : Float(20, 80, strides=[80, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc4.bias : Float(20, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc5.weight : Float(4, 20, strides=[20, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc5.bias : Float(4, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc6.weight : Float(2, 4, strides=[4, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc6.bias : Float(2, strides=[1], requires_grad=1, device=cuda:0)):\n",
      "  %/Constant_output_0 : Float(2, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=  36  204 [ CUDAFloatType{2} ], onnx_name=\"/Constant\"](), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_290733/1725647797.py:16:0\n",
      "  %/Sub_output_0 : Float(1, 2, strides=[2, 1], requires_grad=0, device=cuda:0) = onnx::Sub[onnx_name=\"/Sub\"](%onnx::Sub_0, %/Constant_output_0), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_290733/1725647797.py:16:0\n",
      "  %/Constant_1_output_0 : Float(2, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value= 1236   488 [ CUDAFloatType{2} ], onnx_name=\"/Constant_1\"](), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_290733/1725647797.py:16:0\n",
      "  %/Div_output_0 : Float(1, 2, strides=[2, 1], requires_grad=0, device=cuda:0) = onnx::Div[onnx_name=\"/Div\"](%/Sub_output_0, %/Constant_1_output_0), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_290733/1725647797.py:16:0\n",
      "  %/fc1/Gemm_output_0 : Float(1, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc1/Gemm\"](%/Div_output_0, %fc1.weight, %fc1.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc1 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Tanh_output_0 : Float(1, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Tanh[onnx_name=\"/Tanh\"](%/fc1/Gemm_output_0), scope: __main__.MultiLayerPerceptron:: # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:1971:0\n",
      "  %/fc2/Gemm_output_0 : Float(1, 20, strides=[20, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc2/Gemm\"](%/Tanh_output_0, %fc2.weight, %fc2.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc2 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Tanh_1_output_0 : Float(1, 20, strides=[20, 1], requires_grad=1, device=cuda:0) = onnx::Tanh[onnx_name=\"/Tanh_1\"](%/fc2/Gemm_output_0), scope: __main__.MultiLayerPerceptron:: # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:1971:0\n",
      "  %/fc3/Gemm_output_0 : Float(1, 80, strides=[80, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc3/Gemm\"](%/Tanh_1_output_0, %fc3.weight, %fc3.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc3 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Relu_output_0 : Float(1, 80, strides=[80, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/Relu\"](%/fc3/Gemm_output_0), scope: __main__.MultiLayerPerceptron:: # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/fc4/Gemm_output_0 : Float(1, 20, strides=[20, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc4/Gemm\"](%/Relu_output_0, %fc4.weight, %fc4.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc4 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Relu_1_output_0 : Float(1, 20, strides=[20, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/Relu_1\"](%/fc4/Gemm_output_0), scope: __main__.MultiLayerPerceptron:: # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/fc5/Gemm_output_0 : Float(1, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc5/Gemm\"](%/Relu_1_output_0, %fc5.weight, %fc5.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc5 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/fc6/Gemm_output_0 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc6/Gemm\"](%/fc5/Gemm_output_0, %fc6.weight, %fc6.bias), scope: __main__.MultiLayerPerceptron::/torch.nn.modules.linear.Linear::fc6 # /home/icar/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Constant_2_output_0 : Float(2, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value= 1200.0000  1514.1685 [ CUDAFloatType{2} ], onnx_name=\"/Constant_2\"](), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_290733/1725647797.py:23:0\n",
      "  %/Mul_output_0 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cuda:0) = onnx::Mul[onnx_name=\"/Mul\"](%/fc6/Gemm_output_0, %/Constant_2_output_0), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_290733/1725647797.py:23:0\n",
      "  %/Constant_3_output_0 : Float(2, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value= 0.0000 -848.5281 [ CUDAFloatType{2} ], onnx_name=\"/Constant_3\"](), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_290733/1725647797.py:23:0\n",
      "  %30 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cuda:0) = onnx::Add[onnx_name=\"/Add\"](%/Mul_output_0, %/Constant_3_output_0), scope: __main__.MultiLayerPerceptron:: # /tmp/ipykernel_290733/1725647797.py:23:0\n",
      "  return (%30)\n",
      "\n",
      "Saved ONNX model: /home/icar/icar-ng-data/model/pixel2cm_model.onnx\n"
     ]
    }
   ],
   "source": [
    "onnx_path = os.path.join(model_directory, 'pixel2cm_model.onnx')\n",
    "print('ONNX path: {}'.format(onnx_path))\n",
    "\n",
    "try:\n",
    "    print('Saving ONNX model: {}'.format(onnx_path))\n",
    "    torch.onnx.export(model, torch.randn(1, 2).to(device), onnx_path, verbose=True)\n",
    "    print('Saved ONNX model: {}'.format(onnx_path))\n",
    "except BaseException as e:\n",
    "    print('Failed to save ONNX model: {}'.format(onnx_path))\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "tensor([[1258.,  430.],\n",
      "        [  64.,  230.],\n",
      "        [ 642.,  390.],\n",
      "        [ 986.,  272.],\n",
      "        [ 354.,  236.],\n",
      "        [ 582.,  268.],\n",
      "        [ 736.,  224.],\n",
      "        [ 888.,  386.],\n",
      "        [ 276.,  398.],\n",
      "        [1040.,  522.],\n",
      "        [  30.,  362.],\n",
      "        [1164.,  342.],\n",
      "        [ 410.,  270.],\n",
      "        [1180.,  244.],\n",
      "        [ 542.,  228.],\n",
      "        [ 286.,  332.],\n",
      "        [1064.,  278.],\n",
      "        [1132.,  286.],\n",
      "        [1144.,  520.],\n",
      "        [ 872.,  442.],\n",
      "        [ 874.,  594.],\n",
      "        [ 340.,  448.],\n",
      "        [ 818.,  262.],\n",
      "        [  90.,  690.],\n",
      "        [ 640.,  598.],\n",
      "        [ 642.,  534.],\n",
      "        [ 536.,  206.],\n",
      "        [1032.,  208.],\n",
      "        [1268.,  376.]], device='cuda:0')\n",
      "y\n",
      "tensor([[ 100.0000, -200.0000],\n",
      "        [ 848.5281,  848.5281],\n",
      "        [ 150.0000,    0.0000],\n",
      "        [ 416.0251, -277.3501],\n",
      "        [ 715.5417,  357.7709],\n",
      "        [ 450.0000,   50.0000],\n",
      "        [ 789.1151, -131.5192],\n",
      "        [ 150.0000, -100.0000],\n",
      "        [ 150.0000,  150.0000],\n",
      "        [  50.0000, -100.0000],\n",
      "        [ 200.0000,  300.0000],\n",
      "        [ 200.0000, -250.0000],\n",
      "        [ 450.0000,  200.0000],\n",
      "        [ 565.6854, -565.6854],\n",
      "        [ 789.1151,  131.5192],\n",
      "        [ 250.0000,  200.0000],\n",
      "        [ 350.0000, -300.0000],\n",
      "        [ 353.5534, -353.5534],\n",
      "        [  50.0000, -125.0000],\n",
      "        [ 100.0000,  -75.0000],\n",
      "        [  25.0000,  -50.0000],\n",
      "        [ 100.0000,  100.0000],\n",
      "        [ 474.3416, -158.1139],\n",
      "        [   0.0000,  100.0000],\n",
      "        [  25.0000,    0.0000],\n",
      "        [  50.0000,    0.0000],\n",
      "        [1183.6727,  197.2788],\n",
      "        [ 998.4603, -665.6403],\n",
      "        [ 150.0000, -250.0000]], device='cuda:0')\n",
      "y_pred\n",
      "tensor([[ 1.0025e+02, -2.0477e+02],\n",
      "        [ 8.2541e+02,  8.2138e+02],\n",
      "        [ 1.4926e+02,  5.4932e-03],\n",
      "        [ 3.9377e+02, -2.6410e+02],\n",
      "        [ 7.3312e+02,  3.7606e+02],\n",
      "        [ 4.5221e+02,  5.0722e+01],\n",
      "        [ 7.9151e+02, -1.4299e+02],\n",
      "        [ 1.4862e+02, -9.8084e+01],\n",
      "        [ 1.4710e+02,  1.4361e+02],\n",
      "        [ 4.9799e+01, -1.0051e+02],\n",
      "        [ 2.0542e+02,  3.0051e+02],\n",
      "        [ 2.0139e+02, -2.5111e+02],\n",
      "        [ 4.6283e+02,  2.0196e+02],\n",
      "        [ 5.5944e+02, -5.4413e+02],\n",
      "        [ 7.8733e+02,  1.3936e+02],\n",
      "        [ 2.5234e+02,  2.0098e+02],\n",
      "        [ 3.6366e+02, -3.0812e+02],\n",
      "        [ 3.2796e+02, -3.3871e+02],\n",
      "        [ 4.9457e+01, -1.2601e+02],\n",
      "        [ 9.7762e+01, -7.3623e+01],\n",
      "        [ 2.3645e+01, -4.8462e+01],\n",
      "        [ 1.0131e+02,  1.0120e+02],\n",
      "        [ 4.5136e+02, -1.5177e+02],\n",
      "        [-1.4828e+00,  9.7463e+01],\n",
      "        [ 2.3989e+01, -1.6269e+00],\n",
      "        [ 4.8444e+01,  9.7131e-01],\n",
      "        [ 1.1909e+03,  1.9699e+02],\n",
      "        [ 1.0065e+03, -6.4947e+02],\n",
      "        [ 1.5378e+02, -2.5297e+02]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "y - y_pred\n",
      "tensor([[-2.5366e-01,  4.7711e+00],\n",
      "        [ 2.3123e+01,  2.7145e+01],\n",
      "        [ 7.4205e-01, -5.4932e-03],\n",
      "        [ 2.2255e+01, -1.3249e+01],\n",
      "        [-1.7574e+01, -1.8288e+01],\n",
      "        [-2.2098e+00, -7.2247e-01],\n",
      "        [-2.3901e+00,  1.1471e+01],\n",
      "        [ 1.3830e+00, -1.9162e+00],\n",
      "        [ 2.8956e+00,  6.3876e+00],\n",
      "        [ 2.0141e-01,  5.0525e-01],\n",
      "        [-5.4188e+00, -5.0751e-01],\n",
      "        [-1.3946e+00,  1.1111e+00],\n",
      "        [-1.2829e+01, -1.9609e+00],\n",
      "        [ 6.2465e+00, -2.1557e+01],\n",
      "        [ 1.7845e+00, -7.8410e+00],\n",
      "        [-2.3448e+00, -9.7833e-01],\n",
      "        [-1.3662e+01,  8.1175e+00],\n",
      "        [ 2.5597e+01, -1.4842e+01],\n",
      "        [ 5.4325e-01,  1.0120e+00],\n",
      "        [ 2.2382e+00, -1.3765e+00],\n",
      "        [ 1.3555e+00, -1.5381e+00],\n",
      "        [-1.3147e+00, -1.2045e+00],\n",
      "        [ 2.2984e+01, -6.3401e+00],\n",
      "        [ 1.4828e+00,  2.5375e+00],\n",
      "        [ 1.0110e+00,  1.6269e+00],\n",
      "        [ 1.5555e+00, -9.7131e-01],\n",
      "        [-7.2214e+00,  2.8738e-01],\n",
      "        [-8.0817e+00, -1.6172e+01],\n",
      "        [-3.7825e+00,  2.9734e+00]], device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, (x, y) in enumerate(dataloader_test):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    print('x\\n{}'.format(x))\n",
    "    print('y\\n{}'.format(y))\n",
    "    print('y_pred\\n{}'.format(y_pred))\n",
    "    print('y - y_pred\\n{}'.format(y - y_pred))\n",
    "    \n",
    "    break\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
